{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is an attempt to learn by building and training an LLM from Scratch  "
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.029803Z",
     "start_time": "2025-01-27T20:21:55.189331Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import urllib.request\n",
    "    \n",
    "    \n",
    "\n",
    "# Check which GPU if any is available\n",
    "# torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     x: Tensor = torch.ones(1, device=device)\n",
    "#     print(f\"x = {x} using 'cuda:0' backend\")\n",
    "#     \n",
    "# elif \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x: Tensor = torch.ones(1, device=device)\n",
    "    print(f\"x = {x} using {device} backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # x: Tensor = torch.ones(1, device=device)\n",
    " \n",
    "print(device)\n",
    "\n",
    "def get_some_text():\n",
    "    # Now lets load the text data\n",
    "    bookUrl = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"  # Download a text (book)\n",
    "    filepath = \"../data/the-verdict.txt\"\n",
    "    # print(file_path)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        urllib.request.urlretrieve(bookUrl, filepath)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        rawtext = f.read()\n",
    "        \n",
    "    print(\"Total characters in the story: \", len(rawtext))\n",
    "    print(\"Total Lines in raw text: \", rawtext.count(\"\\n\"))\n",
    "    return rawtext\n",
    "\n",
    "raw_text = get_some_text()\n",
    "print(\"Some text: \", raw_text[:49])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using mps backend\n",
      "mps\n",
      "Total characters in the story:  20479\n",
      "Total Lines in raw text:  164\n",
      "Some text:  I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2c7227e79afbcad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.035015Z",
     "start_time": "2025-01-27T20:21:56.031893Z"
    }
   },
   "source": [
    "# Now we have to tokenize the text. The best way to do that is to use a pre-build tokennizer, but first we will try some \n",
    "# basic python regular expressions to do the same things\n",
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "#\n",
    "print(len(preprocessed))\n",
    "print(preprocessed[:30])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b9dc98b584bc6d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.038318Z",
     "start_time": "2025-01-27T20:21:56.035755Z"
    }
   },
   "source": [
    "# Now we need to generate token IDs\n",
    "# Now let us create a list of all unique tokens and sort them alphabetically to determine the vocabulary size\n",
    "all_uniq_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_uniq_words)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "\n",
    "# Now that we know the vocabulary size, lets enumerate and assign some numbers to them\n",
    "vocab = {token:integer for integer,token in enumerate(all_uniq_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1130\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b49e9060996c9f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.041987Z",
     "start_time": "2025-01-27T20:21:56.039102Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV1 import SimpleTokenizerV1\n",
    "\n",
    "# Now we want to apply this vocabulary to convert new text to generate token id\n",
    "# When we want to convert the outputs of an LLM from numbers back into text, we need a way to turn token IDs into text. \n",
    "# For this, we can create an inverse version of the vocabulary that maps token IDs back to the corresponding text tokens.\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted you know,\" \n",
    "        Mrs Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 1126, 596, 5, 1, 67, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted you know,\" Mrs Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "92b6519fe1741db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.045794Z",
     "start_time": "2025-01-27T20:21:56.043586Z"
    }
   },
   "source": [
    "all_tokens = sorted(list(set(preprocessed))) # Make preprocessed a list so we can extend it\n",
    "all_tokens.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
    "# redo the vocab population\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d03ae607c2d20268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.048441Z",
     "start_time": "2025-01-27T20:21:56.046482Z"
    }
   },
   "source": [
    "# Print the last 5 vocab items\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|unk|>', 1130)\n",
      "('<|endoftext|>', 1131)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "dcdf224cd056d26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.051381Z",
     "start_time": "2025-01-27T20:21:56.049012Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV2 import SimpleTokenizerV2\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984, 722, 988, 1130, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e4e4738351ee6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.062133Z",
     "start_time": "2025-01-27T20:21:56.051898Z"
    }
   },
   "source": [
    "### Byte Pair Encoding \n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"Tiktoken version: \", version(\"tiktoken\"))\n",
    "#print(\"Tiktoken version: \", tiktoken.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ac57b0bafdc676f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.225918Z",
     "start_time": "2025-01-27T20:21:56.062884Z"
    }
   },
   "source": [
    "#### This is the tokenizer using the GPT2 tokenization model\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Encoded: {integers}\")\n",
    "strings = tokenizer.decode(integers)\n",
    "print(f\"Decoded: {strings}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Decoded: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2a6a5225d4fab946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.228512Z",
     "start_time": "2025-01-27T20:21:56.226607Z"
    }
   },
   "source": [
    "print(tokenizer.encode(\"Akwirw ier\"))\n",
    "print(tokenizer.decode(tokenizer.encode(\"Akwirw ier\")))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1ab2edd9fb1ca03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.232635Z",
     "start_time": "2025-01-27T20:21:56.229005Z"
    }
   },
   "source": [
    "# Let's now do Data Sampling with a sliding window\n",
    "# 1. Let's tokenize the entire story with BPE tokenizer first\n",
    "\n",
    "encoded_text = tokenizer.encode(raw_text)\n",
    "print(len(encoded_text))\n",
    "enc_sample = encoded_text[50:]\n",
    "\n",
    "# Now Let's start by defining x and y where x has input tokens and y the output tokens shifted by 1\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "# print(f\"x: {x}\")\n",
    "# print(f\"y:      {y}\")\n",
    "\n",
    "\n",
    "#####\n",
    "# Next word prediction tasks can now be created by \n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    # print(f\"context input: {context} --> desired prediction: {desired}\")\n",
    "    # Now we create the input output target pairs\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "62094a4513e01008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.234545Z",
     "start_time": "2025-01-27T20:21:56.233153Z"
    }
   },
   "source": [
    "# from Dataloader import Dataloader\n",
    "# \n",
    "# dataloader = Dataloader(batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "# dataloader = dataloader.get_instance(file_path, text_enc='utf-8', mode='r')\n",
    "# if dataloader is not None:\n",
    "#     data_iter = iter(dataloader)\n",
    "#     inputs, targets = next(data_iter)\n",
    "#     print(\"Loaded text data...\\n\")\n",
    "#     print(\"Inputs: \\n\", inputs)\n",
    "#     print(\"\\nTargets: \\n\", targets)\n",
    "# else: \n",
    "#     print(\"Failed loading \", dataloader)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "fa0c4b5f389cdc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.383444Z",
     "start_time": "2025-01-27T20:21:56.235005Z"
    }
   },
   "source": [
    "import torch.nn\n",
    "from src.chapter02.Dataloader import Dataloader\n",
    "from src.chapter02.GPTDatasetV1 import GPTDatasetV1\n",
    "file_path = \"../data/the-verdict.txt\"\n",
    "\n",
    "####\n",
    "# Finally we need to create the embeddings for the tokens\n",
    "# If we have a batch size of 8 with 4 tokens each it'll be an 8 x 4 x 256 tensor\n",
    "max_length = 4  \n",
    "max_length = 4  \n",
    "\n",
    "mydataloader = Dataloader(batch_size=8, max_length=max_length, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "dataloader = mydataloader.create_dataloader_v1(txt=raw_text)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "# print(\"Input Token IDs:\\n\", inputs)\n",
    "# print(\"Input tensor shape: \", inputs.shape) \n",
    "\n",
    "# Now since self-attentions are position agnostic, we should add some positional data.\n",
    "# Absolute and relative positional data can be added. So let's create embeddings with say 256 dimensions\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "# context_length = 1024\n",
    "\n",
    "## Now lets embed the input tensors\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token embeddings shape: \", token_embeddings.shape) #8x4x256\n",
    "\n",
    "\n",
    "# For a GPT model’s absolute position embedding approach, we just need to create another embedding \n",
    "# layer that has the same embedding dimension as the token_embedding_ layer:\n",
    "context_length = max_length     #context is length of positions we care about for attention\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embeddings Shape: \", pos_embeddings.shape) # 4x256\n",
    "#\n",
    "# Add the positional embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Position Merged Input Embeddings Shape: \", input_embeddings.shape)\n",
    "#\n",
    "# Now lets look at the dataloader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    token_embeddings = token_embedding_layer(inputs)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "    break\n",
    "#\n",
    "print(\"Batch Embeddings Shape: \", input_embeddings.shape)\n",
    "    \n",
    "print(\"Input tensor \", x)\n",
    "print(\"Target tensor\", y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape:  torch.Size([8, 4, 256])\n",
      "Positional Embeddings Shape:  torch.Size([4, 256])\n",
      "Position Merged Input Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Batch Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Input tensor  [290, 4920, 2241, 287]\n",
      "Target tensor [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "95c2c3a6eb3eea50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.389212Z",
     "start_time": "2025-01-27T20:21:56.386014Z"
    }
   },
   "source": [
    "# Chapter 3 - Attention\n",
    "#\n",
    "import torch\n",
    "\n",
    "# In self-attention our goal is to calculate context vector z(i) for each \n",
    "# element x(i) of the input sequence. Consider the following input sequence \n",
    "#\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "# inputs.to(device)\n",
    "print(\"Input sequence shape: \", inputs.shape)\n",
    "# \n",
    "# Now calculate weights for attention\n",
    "# Assume query is the second word \"journey\" or inputs[1] \n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "print(f\"Query is the 2nd word 'journey': {query}\")\n",
    "#\n",
    "attention_scores_2 = torch.empty(inputs.shape[0])\n",
    "# attention_scores_2.to(device)\n",
    "for idx, x_i in enumerate(inputs):\n",
    "    attention_scores_2[idx] = torch.dot(x_i, query)\n",
    "#    print(f\"Sequence Element [{idx}], attention_score: {attention_scores_2}\")\n",
    "print(f\"Final value of attention_score_2: {attention_scores_2}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape:  torch.Size([6, 3])\n",
      "Query is the 2nd word 'journey': tensor([0.5500, 0.8700, 0.6600])\n",
      "Final value of attention_score_2: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "53ede1deb7d5678e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.394810Z",
     "start_time": "2025-01-27T20:21:56.389793Z"
    }
   },
   "source": [
    "\n",
    "## Note: For all elements if we were to calculate attention it'd be a O(n^2) operation\n",
    "# NOW we normalize the attention weights, so they sum up to 1\n",
    "attention_weights_2_tmp = attention_scores_2 / attention_scores_2.sum()\n",
    "# attention_weights_2_tmp.to(device)\n",
    "print(\"Normalized attention weights:\", attention_weights_2_tmp)\n",
    "print(\"Sum of attention weights:\", attention_weights_2_tmp.sum())\n",
    "\n",
    "## Generally we normalize using the softmax to do the normalization\n",
    "\n",
    "# # define a softmax function\n",
    "def softmax_naive(tensor_x):\n",
    "    return torch.exp(tensor_x) / torch.exp(tensor_x).sum(dim=0, keepdim=True)\n",
    "# \n",
    "\n",
    "attention_scores_2_naive = softmax_naive(attention_scores_2)\n",
    "# attention_scores_2_naive.to(device)\n",
    "\n",
    "print(\"Attention weights naive:\", attention_scores_2_naive)\n",
    "print (\"Naive Sum: \", attention_scores_2_naive.sum())\n",
    "# \n",
    "# Generally we normalize using the torch.softmax() to do the normalization\n",
    "# Softmax ensures its always positive and always adds up to 1\n",
    "#\n",
    "attention_weights_2_torch_softmax = torch.softmax(attention_scores_2, dim=0)\n",
    "# attention_weights_2_torch_softmax.to(device)\n",
    "print(\"Attention weights torch softmax:\", attention_weights_2_torch_softmax)\n",
    "# print(\"Attention weights torch softmax Sum: \", attention_weights_2_torch_softmax.sum())\n",
    "\n",
    "# Now that we have calculated the normalized attention weights, we are ready for the final step.\n",
    "# Calculate the context vector z(2) by multiplying the embedded input tokens x(i), \n",
    "# with the corresponding normalized attention weights and then summing the resultant vectors\n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "#\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "# context_vec_2.to(device)\n",
    "#\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += (attention_weights_2_torch_softmax[i] * x_i)\n",
    "print(\"Context vector z2: \", context_vec_2)\n",
    "\n",
    "#\n",
    "# Now in similar fashion lets calculate attention scores for all the input sequences \n",
    "attention_scores = torch.empty(inputs.shape[0],inputs.shape[0])\n",
    "# attention_scores.to(device)\n",
    "print(\"\\nAttention Scores matrix shape: \", attention_scores.shape)\n",
    "#\n",
    "# Using for loops\n",
    "#\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attention_scores[i, j] = torch.dot(x_i, x_j)\n",
    "# #\n",
    "#print(attention_scores)\n",
    "#\n",
    "# Using matrix multiplication we can do it faster\n",
    "#\n",
    "attention_scores_m = inputs @ inputs.T\n",
    "# attention_scores_m.to(device)\n",
    "#print(\"Normalized attention scores \\n\", attention_scores_m)\n",
    "\n",
    "# Just as before lets normalize the rows, so they sum up to 1\n",
    "# NOTE: Here dim = -1 means we are applying the softmax along the last dimension of the attention_scores_m tensor\n",
    "#\n",
    "attention_weights = torch.softmax(attention_scores_m, dim=-1)\n",
    "# attention_weights.to(device)\n",
    "#print(\"Normalized ATTENTION weights \\n\", attention_weights)\n",
    "# print(\"Softmax Sums:\\n\", attention_weights.sum(dim=-1))\n",
    "\n",
    "# FINAL STEP\n",
    "# Now let's calculate the context vectors for all the input by multiplying the input with attention weights\n",
    "all_context_vectors = attention_weights @ inputs # Matrix multiplication\n",
    "# all_context_vectors.to(device)\n",
    "#print(\"Context vector for the entire sequence\\n\", all_context_vectors)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum of attention weights: tensor(1.0000)\n",
      "Attention weights naive: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Naive Sum:  tensor(1.)\n",
      "Attention weights torch softmax: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Context vector z2:  tensor([0.4419, 0.6515, 0.5683])\n",
      "\n",
      "Attention Scores matrix shape:  torch.Size([6, 6])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "fa980b537b01e646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.401113Z",
     "start_time": "2025-01-27T20:21:56.395376Z"
    }
   },
   "source": [
    "\n",
    "###\n",
    "### 3.4.1 Using weighted matrix\n",
    "###\n",
    "#\n",
    "# Computing the attention weights step by step\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "x_2 = inputs[1]\n",
    "# x_2.to(device)\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(\"x_2: \", x_2)\n",
    "# Now let's initialize 3 weighted matrices Wq, Wk and Wv\n",
    "# Setting requires_grad = False, to reduce clutter, but for model training this should be set to True\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "#\n",
    "# Next we compute the query, key and value vectors\n",
    "# Note the output is a 2 dimenstional vector because we set dout to 2\n",
    "#\n",
    "# W_query.to(device)\n",
    "# W_key.to(device)\n",
    "# W_value.to(device)\n",
    "#\n",
    "# Now the dot product with the input\n",
    "#\n",
    "query_2 = x_2 @ W_query\n",
    "key_2   = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "#\n",
    "# query_2.to(device)\n",
    "# key_2.to(device)\n",
    "# value_2.to(device)\n",
    "#\n",
    "print(\"Query 2: \", query_2)\n",
    "print(\"Key 2:   \", key_2)\n",
    "print(\"Value 2: \", value_2)\n",
    "#\n",
    "print(\"\\n\")\n",
    "#\n",
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "# keys.to(device)\n",
    "# values.to(device)\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "\n",
    "keys_2 = keys[1]\n",
    "\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "# attn_score_22.to(device)\n",
    "# attn_score_22 = query_2 @ keys_2\n",
    "print(\"Attention (dot) score 22:\", attn_score_22)\n",
    "\n",
    "# Generalizing across all inputs\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "# attn_scores_2.to(device)\n",
    "print(\"Attention \\\\@ Scores 2: \", attn_scores_2)\n",
    "# Check the second element is same as previously calculated attention score\n",
    "#\n",
    "# We compute the attention weights by scaling the attention scores and using the softmax function. \n",
    "# However, now we scale the attention scores by dividing them by the square root of the embedding \n",
    "# dimension of the keys\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1]**0.5, dim=-1)\n",
    "# attn_weights_2.to(device)\n",
    "print(\"attn_weights_2: \", attn_weights_2)\n",
    "\n",
    "# The reason for the normalization by square root of embedding dimension size is to improve the training performance by avoiding small gradients. \n",
    "# For instance, when scaling up the embedding dimension, which is typically > 1,000 for GPT-like LLMs, large dot products can result in \n",
    "# very small gradients during backpropagation (due to the softmax function applied to them). \n",
    "# As dot products increase, the softmax function behaves more like a step function, resulting in gradients nearing zero. \n",
    "# These small gradients can drastically slow down learning or cause training to stagnate.\n",
    "#\n",
    "# The scaling by the square root of the embedding dimension is the reason why this self-attention mechanism is also called scaled-dot product attention.\n",
    "# Similar to when we computed the context vector as a weighted sum over the input vectors \n",
    "# we now compute the context vector as a weighted sum over the value vectors. \n",
    "# Here, the attention weights serve as a weighting factor that weighs the respective importance of each value vector\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "# context_vec_2.to(device)\n",
    "print(\"context_vec_2: \", context_vec_2)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2:  tensor([0.5500, 0.8700, 0.6600])\n",
      "Query 2:  tensor([0.4306, 1.4551])\n",
      "Key 2:    tensor([0.4433, 1.1419])\n",
      "Value 2:  tensor([0.3951, 1.0037])\n",
      "\n",
      "\n",
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "Attention (dot) score 22: tensor(1.8524)\n",
      "Attention \\@ Scores 2:  tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "attn_weights_2:  tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "context_vec_2:  tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "2ca52ea3a908fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.410053Z",
     "start_time": "2025-01-27T20:21:56.401905Z"
    }
   },
   "source": [
    "from src.chapter03.SelfAttention_v2 import SelfAttention_v2\n",
    "\n",
    "torch.manual_seed(789)\n",
    "self_attn_v2 = SelfAttention_v2(d_in, d_out)\n",
    "#print(\"Context vectors from SelfAtten_v2: \\n\", self_attn_v2(inputs))\n",
    "\n",
    "# Note since the input contains 6 embedding vectors, the output also has 6 rows of context vectors\n",
    "\n",
    "\n",
    "# Causal Attention \n",
    "# First we apply softmax to the attention scores then mask with 0 above the diagonal and then normalize the rows to 1\n",
    "#\n",
    "queries = self_attn_v2.W_query(inputs)\n",
    "# queries.to(device)\n",
    "\n",
    "keys = self_attn_v2.W_key(inputs)\n",
    "# keys.to(device)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "# attn_scores.to(device)\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "# attn_weights.to(device)\n",
    "#print(\"Attention Wrights: \\n\",attn_weights)\n",
    "\n",
    "# Now mask the values above diagonal as 0 using the tril() function\n",
    "#\n",
    "context_length = attn_scores.shape[0]\n",
    "#\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "#print(\"Mask Simple: \\n\", mask_simple)\n",
    "#\n",
    "# Now simply multiply them to prevent the look ahead \n",
    "#\n",
    "masked_attention_weights = attn_weights * mask_simple\n",
    "# masked_attention_weights.to(device)\n",
    "#print(\"Masked attention weights: \\n\", masked_attention_weights)\n",
    "\n",
    "#\n",
    "# Now re-normalize to make sure rows add up to 1. To do this we divide each element by sum of each row\n",
    "#\n",
    "row_sums = masked_attention_weights.sum(dim=-1, keepdim=True)\n",
    "#print(\"row_sums: \\n\", row_sums)\n",
    "masked_simple_norm = masked_attention_weights / row_sums\n",
    "print(\"Masked & re-normalized weights: \\n\", masked_simple_norm)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using 'mps:0' backend\n",
      "Masked & re-normalized weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f3a442b3d9b7413a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.414455Z",
     "start_time": "2025-01-27T20:21:56.410987Z"
    }
   },
   "source": [
    "# A more efficient way to obtain masked attention weights is to mask the attention scores with \n",
    "# negative infinity before applying softmax function. (e^negative infinity -> 0)\n",
    "# We can implement this masking by replacing values above the diagonal with 1 and then replacing them \n",
    "# with negative infinity\n",
    "#\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "# mask.to(device)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "# masked.to(device)\n",
    "print(\"Masked attention weights: \\n\", masked)\n",
    "#\n",
    "# Now apply the softmax function \n",
    "#\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\"Softmax'd Attention weights: \\n\", attn_weights)\n",
    "\n",
    "# Now we can use these modified attention weights to calculate the context vector\n",
    "#\n",
    "context_vec = attn_weights @ values\n",
    "print(\"context_vec: \\n\", context_vec)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: \n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "Softmax'd Attention weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "context_vec: \n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.2795, 0.9361],\n",
      "        [0.3133, 0.9508],\n",
      "        [0.2994, 0.8595],\n",
      "        [0.2702, 0.7554],\n",
      "        [0.2772, 0.7618]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "d6b38e5f420f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.418842Z",
     "start_time": "2025-01-27T20:21:56.415312Z"
    }
   },
   "source": [
    "# Masking additional weights with dropout\n",
    "# Drop out in the attention mechanism is applied at 2 specific times: \n",
    "# 1. After calculating the attention weights\n",
    "# 2. After applying the attention weights to value vectors\n",
    "# Here we will apply the dropout mask after computing the attention weights\n",
    "#\n",
    "# Lets use a dropout rate of 50% meaning half the attention weights will be masked out. \n",
    "# Normally it's a much lower rate like 0.1 or 0.2\n",
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))\n",
    "#\n",
    "# Since we are applying 50% dropout, to compensate for reduction in active elements\n",
    "# we are going to scale up the values of remaining elements by a factor of 1/0.5 = 2\n",
    "# This scaling is crucial to maintain the balance of the attention weights\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "print(\"Dropped out attention weights: \\n\", dropout(attn_weights))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "Dropped out attention weights: \n",
      " tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "50701dd69a456857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.422783Z",
     "start_time": "2025-01-27T20:21:56.419411Z"
    }
   },
   "source": [
    "from src.chapter03.CausalAttention import CausalAttention\n",
    "\n",
    "# Let’s ensure that the code can handle batches consisting of more than one input so that \n",
    "# the CausalAttention class supports the batch outputs produced by the data loader\n",
    "# To simulate batch input lets duplicate the input text\n",
    "#\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "# batch.to(device)\n",
    "print(\"batch: \\n\", batch.shape)\n",
    "# print(batch)\n",
    "#\n",
    "# We can now use the CausalAttention class as follows\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_layer = batch.shape[1]\n",
    "causal_attn = CausalAttention(d_in, d_out, context_length, 0.0, False)\n",
    "context_vecs = causal_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: \n",
      " torch.Size([2, 6, 3])\n",
      "context_vecs: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9d8058957dc253b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.427194Z",
     "start_time": "2025-01-27T20:21:56.423294Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttentionWrapper import MultiHeadAttentionWrapper\n",
    "\n",
    "# Multi Head Attention\n",
    "# Now if we use the MultiHeadAttentionWrapper class with two attention heads, and CausalAttention \n",
    "# output dimension d_out = 2, we get a 4 dimensional context vector (d_out * num_heads = 4).\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3, 2\n",
    "multi_head_attn = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0, num_heads=2, qkv_bias=False)\n",
    "context_vecs = multi_head_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs)\n",
    "print(\"context_vecs.shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs: \n",
      " tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: \n",
      " torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "8dfa9b39ec1db8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.429422Z",
     "start_time": "2025-01-27T20:21:56.427878Z"
    }
   },
   "source": [
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device('mps')\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print(x)\n",
    "# else:\n",
    "#     print(\"mps not available\")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "f20088921d8113c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.434025Z",
     "start_time": "2025-01-27T20:21:56.430191Z"
    }
   },
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "# print(a.transpose(2, 3))\n",
    "# a.to(device)\n",
    "\n",
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)\n",
    "\n",
    "print(f\"Batched: \\n{a @ a.transpose(2, 3)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n",
      "Batched: \n",
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "df6a05dfc13ebbe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.438373Z",
     "start_time": "2025-01-27T20:21:56.434662Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "print(\"Batch Shape: \\n\", batch.shape)\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"Context vector shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: \n",
      " torch.Size([2, 6, 3])\n",
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "Context vector shape: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "3f958161a85ca549",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Chapter 4: Implementing GPT from Scratch to generate text\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:56.441110Z",
     "start_time": "2025-01-27T20:21:56.439231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}"
   ],
   "id": "16f34621162871e9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "5ac1cbf145ad6daf",
   "metadata": {},
   "source": [
    "## Here is the proposed architecture and order of implementation\n",
    "![image](../data/4-3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "75010152b67235a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.074962Z",
     "start_time": "2025-01-27T20:21:56.441713Z"
    }
   },
   "source": [
    "from src.chapter04.DummyGPTModel import DummyGPTModel\n",
    "import tiktoken\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "#\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.clear()\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)).to(device))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)).to(device))\n",
    "batch = torch.stack(batch, dim=0).to(device)\n",
    "batch.to(device)\n",
    "print(\"Input Batch: \\n\", batch)\n",
    "print(\"Input batch shape: \\n\", batch.shape)\n",
    "#\n",
    "# Next, we initialize a new 124-million-parameter DummyGPTModel instance \n",
    "# and feed it the tokenized batch\n",
    "#\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "logits = model(batch)\n",
    "print(\"Output shape: \\n\", logits.shape)\n",
    "#print(logits)\n",
    "#                      \n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Batch: \n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Input batch shape: \n",
      " torch.Size([2, 4])\n",
      "Output shape: \n",
      " torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "c06060ecd0f8f8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.080458Z",
     "start_time": "2025-01-27T20:21:57.075633Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Let’s now implement LAYER Normalization to improve the stability and efficiency of the training.\n",
    "# The main idea behind LAYER Normalization is to adjust the activations (outputs) of a deep\n",
    "# neural network layer to have a mean of 0 and a variance of 1\n",
    "#\n",
    "# This adjustment speeds up the convergence.\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "#\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Layer: \\n\",out)\n",
    "#\n",
    "# The NN Layer contains the non-linear activation ReLU which 0's out the negative values\n",
    "# \n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Variance: \", var)\n",
    "print(\"\\n\")\n",
    "#\n",
    "# Next, let’s apply layer normalization to the layer outputs we obtained earlier. \n",
    "# The operation consists of subtracting the mean and dividing by the square root \n",
    "# of the variance (also known as the standard deviation):\n",
    "#\n",
    "eps = 1e-5\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "# Dim = -1 indicates statistics along the last dimention\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Normalized Layer Outputs: \\n\", out_norm)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: \n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n",
      "\n",
      "\n",
      "Normalized Layer Outputs: \n",
      " tensor([[6.1585e-01, 1.4126e+00, -8.7188e-01, 5.8723e-01, -8.7188e-01, -8.7188e-01],\n",
      "        [-1.8865e-02, 1.1211e-01, -1.0876e+00, 1.5173e+00, 5.6474e-01, -1.0876e+00]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000e+00],\n",
      "        [1.0000e+00]], grad_fn=<VarBackward0>)\n",
      "-------------------------\n",
      "\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "a39e430a037896f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.083760Z",
     "start_time": "2025-01-27T20:21:57.080926Z"
    }
   },
   "source": [
    "from src.chapter04.LayerNorm import LayerNorm\n",
    "\n",
    "# Previously we used unbiased = False in our variance calculation. This doesn't \n",
    "# apply Bessel's correction where divisor is n-1 instead of n. But this is \n",
    "# compatible with GPT-2\n",
    "\n",
    "ln = LayerNorm(emb_dim = 5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "3130c2c83093ee01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.392436Z",
     "start_time": "2025-01-27T20:21:57.084287Z"
    }
   },
   "source": [
    "# Let us see how the GELU (Gaussian Error Linear Unit) stacks up against \n",
    "# # RELU (REctified Linear Unit)\n",
    "from src.chapter04.GELU import GELU\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "e496e641f9044a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.412156Z",
     "start_time": "2025-01-27T20:21:57.393119Z"
    }
   },
   "source": [
    "from src.chapter04.SimpleFeedForward import SimpleFeedForward\n",
    "\n",
    "# As we can see the smoothness of the GELU can lead to better optimization properties during training\n",
    "# as it allows more nuanced finer adjustments to models parameters. In contrast, RELU has a sharp corner\n",
    "# that can make adjustments difficult for very deep networks.\n",
    "#\n",
    "# Next we look at implementing a feed forward network with GELU activations\n",
    "# See SimpleFeedForward.py\n",
    "#\n",
    "sff = SimpleFeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = sff(x)\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "98a59bc5db854fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.418708Z",
     "start_time": "2025-01-27T20:21:57.413246Z"
    }
   },
   "source": [
    "from src.chapter04.ExampleDeepNeuralNetwork import ExampleDeepNeuralNetwork\n",
    "\n",
    "# Next we implement Shortcut Connections\n",
    "# Each layer will be initialized such that it accepts an example with three input \n",
    "# values and returns three output values.\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "# model.to(device)\n",
    "\n",
    "# Next lets print the gradients\n",
    "def print_gradients(nnmodel, input_x):\n",
    "    output = nnmodel(input_x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    loss.backward()\n",
    "    for name, param in nnmodel.named_parameters():\n",
    "        # print(name, \" = \", param)\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "#\n",
    "# Now Lets use this function to print the gradients calculated by loss.backward()\n",
    "print_gradients(model_without_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "4bfdfab7cb5bcc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.432497Z",
     "start_time": "2025-01-27T20:21:57.419472Z"
    }
   },
   "source": [
    "# As you can see above gradients become tiny aka Vanishing from Layer4 to Layer1\n",
    "# Let’s now instantiate a model with skip connections and see how it compares:\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "# model.to(device)\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a229081ed60e29b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.434575Z",
     "start_time": "2025-01-27T20:21:57.433240Z"
    }
   },
   "source": [
    "# Note here the gradient doesn't approach a vanishingly small value during backprop.\n",
    "# In conclusion, shortcut connections are important for overcoming the limitations posed \n",
    "# by the vanishing gradient problem in deep neural networks."
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "2df6d339f0570629",
   "metadata": {},
   "source": [
    "#### Next, we’ll connect all the previously covered concepts (layer normalization, GELU activations, feed forward module, and shortcut connections) in a transformer  block, which is the final building block we need to code the GPT architecture.\n",
    "\n",
    "![image](../data/transformer_wiring.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd526dd3047ba477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:57.476155Z",
     "start_time": "2025-01-27T20:21:57.435033Z"
    }
   },
   "source": [
    "# See TransformerBlock.py for the basic sequence and feedforward details\n",
    "from src.chapter04.TransformerBlock import TransformerBlock\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "tr_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "out = tr_block(x)\n",
    "#\n",
    "print(\"Input Shape:  \", x.shape)\n",
    "print(\"Output Shape: \", out.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:   torch.Size([2, 4, 768])\n",
      "Output Shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "8c3e76bf70259f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.572315Z",
     "start_time": "2025-01-27T20:21:57.476876Z"
    }
   },
   "source": [
    "from src.chapter04.GPTModel import GPTModel \n",
    "\n",
    "# Let us wire up the actual GPT Model we wrote now\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "print(\"Input batch: \", batch)\n",
    "out = model(batch)\n",
    "print(\"Output shape: \", out.shape)\n",
    "# print(\"Out: \\n\", out)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Output shape:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "af55c75851ac7e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.575372Z",
     "start_time": "2025-01-27T20:21:58.573082Z"
    }
   },
   "source": [
    "# Note above the output tensor has the shape [2, 4, 50257], since we passed in two input texts (the two sentences) \n",
    "# with four tokens each. The last dimension, 50257, corresponds to the vocabulary size of the tokenizer.\n",
    "#\n",
    "# To capture the total number of Parameters for a model use numel parameter value\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "ba624b8ce1a7e0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "1a31524b0cdc6ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.577645Z",
     "start_time": "2025-01-27T20:21:58.575956Z"
    }
   },
   "source": [
    "# Weight Tying: The model reuses weights from the token embedding layer in its output layer\n",
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
    "# As we can see both shapes are same"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "197e0a5f1199aada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.583185Z",
     "start_time": "2025-01-27T20:21:58.580713Z"
    }
   },
   "source": [
    "# The token embedding and output layers are very large due to the 50,257 rows in the tokenizer’s vocabulary. \n",
    "# If we remove the output layer parameter count from the total GPT-2 model count :\n",
    "total_params_gptmodel = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of trainable parameters considering weight tying: \"\n",
    "      f\"{total_params_gptmodel:,}\")\n",
    "\n",
    "# Memory Requirement\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "82b6b3cc8d05feb4",
   "metadata": {},
   "source": [
    "# Generating text \n",
    "#### We will now write code to generate text from the predicted tensors by the GPTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da3f91bddda842d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.706259Z",
     "start_time": "2025-01-27T20:21:58.583707Z"
    }
   },
   "source": [
    "def generate_text_simple(input_model, tokenids, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        token_cond = tokenids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = input_model(token_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probabs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probabs, dim=-1, keepdim=True)\n",
    "        tokenids = torch.cat((tokenids, next_token), dim=1)\n",
    "\n",
    "        return tokenids\n",
    "#    \n",
    "#  Try it with a sample sentence  \n",
    "#    \n",
    "start_context = \"Hello, I am \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "#\n",
    "encoded_tensor = torch.tensor(encoded).to(device).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape: \", encoded_tensor.shape)\n",
    "#\n",
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716, 220]\n",
      "encoded_tensor.shape:  torch.Size([1, 5])\n",
      "Output: tensor([[15496,    11,   314,   716,   220, 24464]], device='mps:0')\n",
      "Output length: 6\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "ab7699859ab25da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:58.709333Z",
     "start_time": "2025-01-27T20:21:58.706993Z"
    }
   },
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am opia\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "7397b4b87caf10c6",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on unlabeled data\n",
    "#### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "id": "62d971c360d51b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:59.695177Z",
     "start_time": "2025-01-27T20:21:58.714136Z"
    }
   },
   "source": [
    "GPT_CONFIG_124M_2 = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(torch.device(\"mps\"))\n",
    "model.eval()\n",
    "\n",
    "# Utility function\n",
    "def text_to_token_ids(txt, tokenizr):\n",
    "    encoded_txt = tokenizr.encode(txt, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tnsr = torch.tensor(encoded_txt).to(device).unsqueeze(0)\n",
    "    return encoded_tnsr\n",
    "\n",
    "# Utility function\n",
    "def token_ids_to_text(tokenids, tokenizr):\n",
    "    flat = tokenids.squeeze(0)\n",
    "    return tokenizr.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Ae\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "21d8324b6eace0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:59.877376Z",
     "start_time": "2025-01-27T20:21:59.695785Z"
    }
   },
   "source": [
    "# How to calculate loss and relatively randomize next word prediction\n",
    "#\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]]).to(device)   #  \"I really like\"]\n",
    "#\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]).to(device)  #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(f\"probas: {probas.shape}\")\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 2: \", target_probas_2)\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token, \n",
    "# which involves increasing its probability relative to other tokens. \n",
    "\n",
    "# Loss of probabilities for the two batches are\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log probabilities for both batches are: \\n\", log_probas)\n",
    "\n",
    "# Next, we combine the log probabilities into a single score by computing \n",
    "# the average\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(f\"Average log probability: {avg_log_probas}\")\n",
    "\n",
    "# However, in deep learning, the common practice isn’t to push the average log probability \n",
    "# up to 0 but rather to bring the negative average log probability down to 0. The negative \n",
    "# average log probability is simply the average log probability multiplied by –1\n",
    "neg_avg_log_probabs = avg_log_probas * -1\n",
    "print(f\"Negative of average log probability: {neg_avg_log_probabs}\")\n",
    "\n",
    "# In deep learning, the term for turning this negative value, –10.7940, into 10.7940, \n",
    "# is known as the cross entropy loss.\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probas: torch.Size([2, 3, 50257])\n",
      "Token IDs: tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]], device='mps:0')\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n",
      "Softmax scores for Text 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05], device='mps:0')\n",
      "Softmax scores for Text 2:  tensor([4.2794e-05, 1.6248e-05, 1.1586e-05], device='mps:0')\n",
      "Log probabilities for both batches are: \n",
      " tensor([-1.0660e+01, -1.0794e+01, -1.1353e+01, -1.0059e+01, -1.1028e+01, -1.1366e+01],\n",
      "       device='mps:0')\n",
      "Average log probability: -10.876513481140137\n",
      "Negative of average log probability: 10.876513481140137\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "2e39970739c5f593",
   "metadata": {},
   "source": [
    "#### NOTE: Our goal during training is to get the average log probability as close to 0 as possible by updating the model’s weights"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0465f554d8c18b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:21:59.893778Z",
     "start_time": "2025-01-27T20:21:59.878040Z"
    }
   },
   "source": [
    "print(\"Logits shape:\", logits.shape) # batch size, num of tokens, vocab size\n",
    "print(\"Targets shape:\", targets.shape) # batch size, num of tokens\n",
    "\n",
    "# For the cross_entropy loss function in PyTorch, we want to flatten these \n",
    "# tensors by combining them over the batch dimension:\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "# Now we can call CE from torch to calculate the loss\n",
    "celoss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(f\"Cross Entropy loss: {celoss}\")\n",
    "\n",
    "# Perplexity measures how well the probability distribution predicted by the model \n",
    "# matches the actual distribution of the words in the dataset. Similar to the loss, \n",
    "# a lower perplexity means the model predictions are closer to the actual distribution.\n",
    "perplexity = torch.exp(celoss)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross Entropy loss: 10.876513481140137\n",
      "Perplexity: 52918.7734375\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "9d0758479b082989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:00.386337Z",
     "start_time": "2025-01-27T20:21:59.894459Z"
    }
   },
   "source": [
    "from src.chapter02.Dataloader import Dataloader\n",
    "\n",
    "# To implement the data splitting and loading, we first define a train_ratio \n",
    "# to use 90% of the data for training and the remaining 10% as validation data \n",
    "# for model evaluation during training\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(train_data)\n",
    "# print(\"Created train_loader...\")\n",
    "val_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(val_data)\n",
    "# print(\"Created val_loader...\")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "# Calculate batch loss    \n",
    "def calculate_batch_loss(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)      \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "# Calculate loss across batches\n",
    "def calculate_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calculate_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calculate_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# A convenience function that we use to track whether the model improves during the training. \n",
    "# The generate_and_print_sample() function takes a text snippet (start_context) as input, \n",
    "# converts it into token IDs, and feeds it to the LLM to generate a text sample \n",
    "# using the generate_text_simple function\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            input_model=model, \n",
    "            tokenids=encoded,\n",
    "            max_new_tokens=50, \n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# \n",
    "# Now we implement the model training flow \n",
    "#\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calculate_batch_loss(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Training loss: 10.988501760694716\n",
      "Validation loss: 10.990342140197754\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "9f203bec3d737b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:55.408111Z",
     "start_time": "2025-01-27T20:22:00.386971Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M_2)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),\n",
    "    lr=0.0004, \n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 8\n",
    "# \n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs, eval_freq=5, eval_iter=5, start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.847, Val loss 10.813\n",
      "Ep 1 (Step 000005): Train loss 10.536, Val loss 10.618\n",
      "Every effort moves youucked\n",
      "Ep 2 (Step 000010): Train loss 9.487, Val loss 9.629\n",
      "Ep 2 (Step 000015): Train loss 8.373, Val loss 8.572\n",
      "Every effort moves you--\n",
      "Ep 3 (Step 000020): Train loss 7.176, Val loss 7.471\n",
      "Ep 3 (Step 000025): Train loss 6.333, Val loss 6.823\n",
      "Every effort moves you--\n",
      "Ep 4 (Step 000030): Train loss 6.116, Val loss 6.669\n",
      "Ep 4 (Step 000035): Train loss 6.099, Val loss 6.714\n",
      "Every effort moves you,\n",
      "Ep 5 (Step 000040): Train loss 6.021, Val loss 6.737\n",
      "Every effort moves you \n",
      "Ep 6 (Step 000045): Train loss 6.075, Val loss 6.770\n",
      "Ep 6 (Step 000050): Train loss 6.045, Val loss 6.790\n",
      "Every effort moves you,\n",
      "Ep 7 (Step 000055): Train loss 6.064, Val loss 6.814\n",
      "Ep 7 (Step 000060): Train loss 6.020, Val loss 6.826\n",
      "Every effort moves you,\n",
      "Ep 8 (Step 000065): Train loss 5.969, Val loss 6.817\n",
      "Ep 8 (Step 000070): Train loss 6.031, Val loss 6.829\n",
      "Every effort moves you,\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "f525a5e6aafe03d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:55.511620Z",
     "start_time": "2025-01-27T20:22:55.408816Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "acfc02f2040cd8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:57.247074Z",
     "start_time": "2025-01-27T20:22:55.512168Z"
    }
   },
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Now lets look at Temperature Scaling\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "# Assume the model generates the following logits \n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "\n",
    "# We now generally do an argmax of the probabilities \n",
    "probas = torch.softmax(next_token_logits, dim=0).to(device)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(f\"Next token (argmax): {inverse_vocab[next_token_id]}\")\n",
    "#\n",
    "# But we can try replacing argmax with multinomial and get a sampling\n",
    "#\n",
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(f\"Next token (multinomial): {inverse_vocab[next_token_id]}\")\n",
    "# \n",
    "# Let's see if multinomial can produce any other probabilites\n",
    "def print_sampled_tokens(probabs):\n",
    "    torch.manual_seed(123)\n",
    "    # Multinomial Sampling of probabilities instead of max\n",
    "    samples = [torch.multinomial(probabs, num_samples=1).item() for _ in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(samples).to(device))\n",
    "    for cnt, freq in enumerate(sampled_ids):\n",
    "        print(f\"Sampled Freq. {freq} : {inverse_vocab[cnt]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you,\n",
      "Next token (argmax): forward\n",
      "Next token (multinomial): forward\n",
      "Sampled Freq. 72 : closer\n",
      "Sampled Freq. 2 : every\n",
      "Sampled Freq. 0 : effort\n",
      "Sampled Freq. 575 : forward\n",
      "Sampled Freq. 2 : inches\n",
      "Sampled Freq. 0 : moves\n",
      "Sampled Freq. 0 : pizza\n",
      "Sampled Freq. 343 : toward\n",
      "Sampled Freq. 6 : you\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "2edb9cac7f426800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:57.305730Z",
     "start_time": "2025-01-27T20:22:57.247850Z"
    }
   },
   "source": [
    "# We can further control the distribution by a technique called temperature scaling\n",
    "# meaning dividing the logits with a >0 number\n",
    "def softmax_with_temperature(logits, temperature, dim):\n",
    "    scaled_logits = logits / temperature\n",
    "    scaled_probs =  torch.softmax(scaled_logits, dim=dim)\n",
    "    return scaled_probs\n",
    "\n",
    "# Let's check that out\n",
    "temperatures = [1, .01, 5]\n",
    "next_token_logits = Tensor.cpu(next_token_logits)\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, float(T), 0) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.5\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, \n",
    "                   scaled_probas[i], \n",
    "                   bar_width, \n",
    "                   label=f'Temperature = {T}'\n",
    "    )\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Words')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "48c5d9214db5c7e3",
   "metadata": {},
   "source": [
    "## Top K sampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "af408748892d4b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:22:59.024513Z",
     "start_time": "2025-01-27T20:22:57.306712Z"
    }
   },
   "source": [
    "# Previously we implemented a probabilistic sampling approach coupled with \n",
    "# temperature scaling to increase the diversity of the outputs.  This method \n",
    "# allows for the exploring of less likely but potentially more interesting and \n",
    "# creative paths in the generation process.\n",
    "#\n",
    "# Top-k sampling, when combined with probabilistic sampling and temperature \n",
    "# scaling, can improve the text generation results.\n",
    "#\n",
    "# Here we can restrict the sampled tokens to the top-k most likely tokens \n",
    "# and exclude all other tokens from the selection process by masking their \n",
    "# probability scores\n",
    "\n",
    "top_k = 3\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# \n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top Logits: \", top_logits)\n",
    "print(\"Top Positions: \", top_pos)\n",
    "print(f\"Next token logits: {next_token_logits}\")\n",
    "\n",
    "# Pytorch WHERE function to set the logit values of tokens that are below the lowest \n",
    "# logit value within our top-three selection to negative infinity (-inf)\n",
    "#\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New Logits: \", new_logits)\n",
    "\n",
    "# Now apply the softmax\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(f\"top k probabilities: {topk_probas}\")\n",
    "# \n",
    "# We can now apply the temperature scaling and multinomial function for probabilistic \n",
    "# sampling to select the next token among these three non-zero probability scores to \n",
    "# generate the next token with more diversity.\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    print(\"Entering generate()..\")\n",
    "    # print(idx.shape)\n",
    "    for i in range(max_new_tokens):\n",
    "        # print(f\"idx: [{i}]: {idx}\")\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        #     \n",
    "        logits = logits[:, -1, :] # ([1, 50257])\n",
    "        # print(logits.shape)\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1] # Less than the lowest value of top k\n",
    "            # Now mark the minvals with -inf, so softmax becomes 0\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            probs = softmax_with_temperature(logits, temperature, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "        else: \n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        \n",
    "        #     logits = logits / temperature\n",
    "        #     probs = torch.softmax(logits, dim=-1)\n",
    "        #     idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        # Next word\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "    return idx\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions:  tensor([3, 7, 0])\n",
      "Next token logits: tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "New Logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "top k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
      "Entering generate()..\n",
      "Output text:\n",
      " Every effort moves you in the to the't was, had his a my\n",
      " of it a\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:23:01.873118Z",
     "start_time": "2025-01-27T20:22:59.025275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.save(model.state_dict(), f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\")\n",
    "MODEL_PATH = f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\"\n",
    "# \n",
    "torch.save(\n",
    "    {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    MODEL_PATH\n",
    ")\n",
    "# "
   ],
   "id": "7e164cfeef1f9707",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:23:03.475657Z",
     "start_time": "2025-01-27T20:23:01.873819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model back\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "# \n",
    "model = GPTModel(GPT_CONFIG_124M_2)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# \n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                             lr=GPT_CONFIG_124M_2[\"lr\"], \n",
    "                             weight_decay=GPT_CONFIG_124M_2[\"weight_decay\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# \n",
    "model.eval()"
   ],
   "id": "d0a3f72c8cebc09d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sff): SimpleFeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T20:23:03.478054Z",
     "start_time": "2025-01-27T20:23:03.476609Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f6108362246432af",
   "outputs": [],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
