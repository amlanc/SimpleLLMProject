{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is an attempt to learn by building and training an LLM from Scratch  "
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:47.833541Z",
     "start_time": "2025-01-30T23:57:47.731016Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import urllib.request\n",
    "    \n",
    "# Check which GPU if any is available\n",
    "# torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     x: Tensor = torch.ones(1, device=device)\n",
    "#     print(f\"x = {x} using 'cuda:0' backend\")\n",
    "#     \n",
    "# elif \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x: Tensor = torch.ones(1, device=device)\n",
    "    print(f\"x = {x} using {device} backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # x: Tensor = torch.ones(1, device=device)\n",
    " \n",
    "print(device)\n",
    "\n",
    "def get_some_text():\n",
    "    # Now lets load the text data\n",
    "    bookUrl = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"  # Download a text (book)\n",
    "    filepath = \"../data/the-verdict.txt\"\n",
    "    # print(file_path)\n",
    "    if not os.path.exists(filepath):\n",
    "        urllib.request.urlretrieve(bookUrl, filepath)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        rawtext = f.read()\n",
    "        \n",
    "    print(\"Total characters in the story: \", len(rawtext))\n",
    "    print(\"Total Lines in raw text: \", rawtext.count(\"\\n\"))\n",
    "    return rawtext\n",
    "\n",
    "raw_text = get_some_text()\n",
    "print(\"Some text: \", raw_text[:49])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using mps backend\n",
      "mps\n",
      "Total characters in the story:  20479\n",
      "Total Lines in raw text:  164\n",
      "Some text:  I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2c7227e79afbcad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.043057Z",
     "start_time": "2025-01-30T23:57:48.039315Z"
    }
   },
   "source": [
    "# Now we have to tokenize the text. The best way to do that is to use a pre-build tokennizer, but first we will try some \n",
    "# basic python regular expressions to do the same things\n",
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "#\n",
    "print(len(preprocessed))\n",
    "print(preprocessed[:30])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b9dc98b584bc6d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.088453Z",
     "start_time": "2025-01-30T23:57:48.085155Z"
    }
   },
   "source": [
    "# Now we need to generate token IDs\n",
    "# Now let us create a list of all unique tokens and sort them alphabetically to determine the vocabulary size\n",
    "all_uniq_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_uniq_words)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "\n",
    "# Now that we know the vocabulary size, lets enumerate and assign some numbers to them\n",
    "vocab = {token:integer for integer,token in enumerate(all_uniq_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1130\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b49e9060996c9f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.158544Z",
     "start_time": "2025-01-30T23:57:48.155304Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV1 import SimpleTokenizerV1\n",
    "\n",
    "# Now we want to apply this vocabulary to convert new text to generate token id\n",
    "# When we want to convert the outputs of an LLM from numbers back into text, we need a way to turn token IDs into text. \n",
    "# For this, we can create an inverse version of the vocabulary that maps token IDs back to the corresponding text tokens.\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted you know,\" \n",
    "        Mrs Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 1126, 596, 5, 1, 67, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted you know,\" Mrs Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "92b6519fe1741db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.202606Z",
     "start_time": "2025-01-30T23:57:48.200039Z"
    }
   },
   "source": [
    "all_tokens = sorted(list(set(preprocessed))) # Make preprocessed a list so we can extend it\n",
    "all_tokens.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
    "# redo the vocab population\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "d03ae607c2d20268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.254761Z",
     "start_time": "2025-01-30T23:57:48.252691Z"
    }
   },
   "source": [
    "# Print the last 5 vocab items\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|unk|>', 1130)\n",
      "('<|endoftext|>', 1131)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "dcdf224cd056d26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.301543Z",
     "start_time": "2025-01-30T23:57:48.298396Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV2 import SimpleTokenizerV2\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984, 722, 988, 1130, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e4e4738351ee6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.343568Z",
     "start_time": "2025-01-30T23:57:48.332693Z"
    }
   },
   "source": [
    "### Byte Pair Encoding \n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"Tiktoken version: \", version(\"tiktoken\"))\n",
    "#print(\"Tiktoken version: \", tiktoken.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ac57b0bafdc676f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.550239Z",
     "start_time": "2025-01-30T23:57:48.381130Z"
    }
   },
   "source": [
    "#### This is the tokenizer using the GPT2 tokenization model\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Encoded: {integers}\")\n",
    "strings = tokenizer.decode(integers)\n",
    "print(f\"Decoded: {strings}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Decoded: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "2a6a5225d4fab946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.554612Z",
     "start_time": "2025-01-30T23:57:48.552266Z"
    }
   },
   "source": [
    "print(tokenizer.encode(\"Akwirw ier\"))\n",
    "print(tokenizer.decode(tokenizer.encode(\"Akwirw ier\")))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "1ab2edd9fb1ca03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.559801Z",
     "start_time": "2025-01-30T23:57:48.555459Z"
    }
   },
   "source": [
    "# Let's now do Data Sampling with a sliding window\n",
    "# 1. Let's tokenize the entire story with BPE tokenizer first\n",
    "\n",
    "encoded_text = tokenizer.encode(raw_text)\n",
    "print(len(encoded_text))\n",
    "enc_sample = encoded_text[50:]\n",
    "\n",
    "# Now Let's start by defining x and y where x has input tokens and y the output tokens shifted by 1\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "# print(f\"x: {x}\")\n",
    "# print(f\"y:      {y}\")\n",
    "\n",
    "\n",
    "#####\n",
    "# Next word prediction tasks can now be created by \n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    # print(f\"context input: {context} --> desired prediction: {desired}\")\n",
    "    # Now we create the input output target pairs\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "62094a4513e01008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.563621Z",
     "start_time": "2025-01-30T23:57:48.561537Z"
    }
   },
   "source": [
    "# from Dataloader import Dataloader\n",
    "# \n",
    "# dataloader = Dataloader(batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "# dataloader = dataloader.get_instance(file_path, text_enc='utf-8', mode='r')\n",
    "# if dataloader is not None:\n",
    "#     data_iter = iter(dataloader)\n",
    "#     inputs, targets = next(data_iter)\n",
    "#     print(\"Loaded text data...\\n\")\n",
    "#     print(\"Inputs: \\n\", inputs)\n",
    "#     print(\"\\nTargets: \\n\", targets)\n",
    "# else: \n",
    "#     print(\"Failed loading \", dataloader)\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "fa0c4b5f389cdc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.714042Z",
     "start_time": "2025-01-30T23:57:48.564549Z"
    }
   },
   "source": [
    "import torch.nn\n",
    "from src.chapter02.Dataloader import Dataloader\n",
    "file_path = \"../data/the-verdict.txt\"\n",
    "\n",
    "####\n",
    "# Finally we need to create the embeddings for the tokens\n",
    "# If we have a batch size of 8 with 4 tokens each it'll be an 8 x 4 x 256 tensor\n",
    "max_length = 4  \n",
    "\n",
    "mydataloader = Dataloader(batch_size=8, max_length=max_length, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "dataloader = mydataloader.create_dataloader_v1(txt=raw_text)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "# print(\"Input Token IDs:\\n\", inputs)\n",
    "# print(\"Input tensor shape: \", inputs.shape) \n",
    "\n",
    "# Now since self-attentions are position agnostic, we should add some positional data.\n",
    "# Absolute and relative positional data can be added. So let's create embeddings with say 256 dimensions\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "# context_length = 1024\n",
    "\n",
    "## Now lets embed the input tensors\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token embeddings shape: \", token_embeddings.shape) #8x4x256\n",
    "\n",
    "\n",
    "# For a GPT model’s absolute position embedding approach, we just need to create another embedding \n",
    "# layer that has the same embedding dimension as the token_embedding_ layer:\n",
    "context_length = max_length     #context is length of positions we care about for attention\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embeddings Shape: \", pos_embeddings.shape) # 4x256\n",
    "#\n",
    "# Add the positional embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Position Merged Input Embeddings Shape: \", input_embeddings.shape)\n",
    "#\n",
    "# Now lets look at the dataloader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    token_embeddings = token_embedding_layer(inputs)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "    break\n",
    "#\n",
    "print(\"Batch Embeddings Shape: \", input_embeddings.shape)\n",
    "    \n",
    "print(\"Input tensor \", x)\n",
    "print(\"Target tensor\", y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape:  torch.Size([8, 4, 256])\n",
      "Positional Embeddings Shape:  torch.Size([4, 256])\n",
      "Position Merged Input Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Batch Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Input tensor  [290, 4920, 2241, 287]\n",
      "Target tensor [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "95c2c3a6eb3eea50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.718513Z",
     "start_time": "2025-01-30T23:57:48.714914Z"
    }
   },
   "source": [
    "# Chapter 3 - Attention\n",
    "#\n",
    "import torch\n",
    "\n",
    "# In self-attention our goal is to calculate context vector z(i) for each \n",
    "# element x(i) of the input sequence. Consider the following input sequence \n",
    "#\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "# inputs.to(device)\n",
    "print(\"Input sequence shape: \", inputs.shape)\n",
    "# \n",
    "# Now calculate weights for attention\n",
    "# Assume query is the second word \"journey\" or inputs[1] \n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "print(f\"Query is the 2nd word 'journey': {query}\")\n",
    "#\n",
    "attention_scores_2 = torch.empty(inputs.shape[0])\n",
    "# attention_scores_2.to(device)\n",
    "for idx, x_i in enumerate(inputs):\n",
    "    attention_scores_2[idx] = torch.dot(x_i, query)\n",
    "#    print(f\"Sequence Element [{idx}], attention_score: {attention_scores_2}\")\n",
    "print(f\"Final value of attention_score_2: {attention_scores_2}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape:  torch.Size([6, 3])\n",
      "Query is the 2nd word 'journey': tensor([0.5500, 0.8700, 0.6600])\n",
      "Final value of attention_score_2: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "53ede1deb7d5678e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.725125Z",
     "start_time": "2025-01-30T23:57:48.719983Z"
    }
   },
   "source": [
    "\n",
    "## Note: For all elements if we were to calculate attention it'd be a O(n^2) operation\n",
    "# NOW we normalize the attention weights, so they sum up to 1\n",
    "attention_weights_2_tmp = attention_scores_2 / attention_scores_2.sum()\n",
    "# attention_weights_2_tmp.to(device)\n",
    "print(\"Normalized attention weights:\", attention_weights_2_tmp)\n",
    "print(\"Sum of attention weights:\", attention_weights_2_tmp.sum())\n",
    "\n",
    "## Generally we normalize using the softmax to do the normalization\n",
    "\n",
    "# # define a softmax function\n",
    "def softmax_naive(tensor_x):\n",
    "    return torch.exp(tensor_x) / torch.exp(tensor_x).sum(dim=0, keepdim=True)\n",
    "# \n",
    "\n",
    "attention_scores_2_naive = softmax_naive(attention_scores_2)\n",
    "# attention_scores_2_naive.to(device)\n",
    "\n",
    "print(\"Attention weights naive:\", attention_scores_2_naive)\n",
    "print (\"Naive Sum: \", attention_scores_2_naive.sum())\n",
    "# \n",
    "# Generally we normalize using the torch.softmax() to do the normalization\n",
    "# Softmax ensures its always positive and always adds up to 1\n",
    "#\n",
    "attention_weights_2_torch_softmax = torch.softmax(attention_scores_2, dim=0)\n",
    "# attention_weights_2_torch_softmax.to(device)\n",
    "print(\"Attention weights torch softmax:\", attention_weights_2_torch_softmax)\n",
    "# print(\"Attention weights torch softmax Sum: \", attention_weights_2_torch_softmax.sum())\n",
    "\n",
    "# Now that we have calculated the normalized attention weights, we are ready for the final step.\n",
    "# Calculate the context vector z(2) by multiplying the embedded input tokens x(i), \n",
    "# with the corresponding normalized attention weights and then summing the resultant vectors\n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "#\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "# context_vec_2.to(device)\n",
    "#\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += (attention_weights_2_torch_softmax[i] * x_i)\n",
    "print(\"Context vector z2: \", context_vec_2)\n",
    "\n",
    "#\n",
    "# Now in similar fashion lets calculate attention scores for all the input sequences \n",
    "attention_scores = torch.empty(inputs.shape[0],inputs.shape[0])\n",
    "# attention_scores.to(device)\n",
    "print(\"\\nAttention Scores matrix shape: \", attention_scores.shape)\n",
    "#\n",
    "# Using for loops\n",
    "#\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attention_scores[i, j] = torch.dot(x_i, x_j)\n",
    "# #\n",
    "#print(attention_scores)\n",
    "#\n",
    "# Using matrix multiplication we can do it faster\n",
    "#\n",
    "attention_scores_m = inputs @ inputs.T\n",
    "# attention_scores_m.to(device)\n",
    "#print(\"Normalized attention scores \\n\", attention_scores_m)\n",
    "\n",
    "# Just as before lets normalize the rows, so they sum up to 1\n",
    "# NOTE: Here dim = -1 means we are applying the softmax along the last dimension of the attention_scores_m tensor\n",
    "#\n",
    "attention_weights = torch.softmax(attention_scores_m, dim=-1)\n",
    "# attention_weights.to(device)\n",
    "#print(\"Normalized ATTENTION weights \\n\", attention_weights)\n",
    "# print(\"Softmax Sums:\\n\", attention_weights.sum(dim=-1))\n",
    "\n",
    "# FINAL STEP\n",
    "# Now let's calculate the context vectors for all the input by multiplying the input with attention weights\n",
    "all_context_vectors = attention_weights @ inputs # Matrix multiplication\n",
    "# all_context_vectors.to(device)\n",
    "#print(\"Context vector for the entire sequence\\n\", all_context_vectors)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum of attention weights: tensor(1.0000)\n",
      "Attention weights naive: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Naive Sum:  tensor(1.)\n",
      "Attention weights torch softmax: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Context vector z2:  tensor([0.4419, 0.6515, 0.5683])\n",
      "\n",
      "Attention Scores matrix shape:  torch.Size([6, 6])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "fa980b537b01e646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.731552Z",
     "start_time": "2025-01-30T23:57:48.725669Z"
    }
   },
   "source": [
    "\n",
    "###\n",
    "### 3.4.1 Using weighted matrix\n",
    "###\n",
    "#\n",
    "# Computing the attention weights step by step\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "x_2 = inputs[1]\n",
    "# x_2.to(device)\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(\"x_2: \", x_2)\n",
    "# Now let's initialize 3 weighted matrices Wq, Wk and Wv\n",
    "# Setting requires_grad = False, to reduce clutter, but for model training this should be set to True\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "#\n",
    "# Next we compute the query, key and value vectors\n",
    "# Note the output is a 2 dimenstional vector because we set dout to 2\n",
    "#\n",
    "# W_query.to(device)\n",
    "# W_key.to(device)\n",
    "# W_value.to(device)\n",
    "#\n",
    "# Now the dot product with the input\n",
    "#\n",
    "query_2 = x_2 @ W_query\n",
    "key_2   = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "#\n",
    "# query_2.to(device)\n",
    "# key_2.to(device)\n",
    "# value_2.to(device)\n",
    "#\n",
    "print(\"Query 2: \", query_2)\n",
    "print(\"Key 2:   \", key_2)\n",
    "print(\"Value 2: \", value_2)\n",
    "#\n",
    "print(\"\\n\")\n",
    "#\n",
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "# keys.to(device)\n",
    "# values.to(device)\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "\n",
    "keys_2 = keys[1]\n",
    "\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "# attn_score_22.to(device)\n",
    "# attn_score_22 = query_2 @ keys_2\n",
    "print(\"Attention (dot) score 22:\", attn_score_22)\n",
    "\n",
    "# Generalizing across all inputs\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "# attn_scores_2.to(device)\n",
    "print(\"Attention \\\\@ Scores 2: \", attn_scores_2)\n",
    "# Check the second element is same as previously calculated attention score\n",
    "#\n",
    "# We compute the attention weights by scaling the attention scores and using the softmax function. \n",
    "# However, now we scale the attention scores by dividing them by the square root of the embedding \n",
    "# dimension of the keys\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1]**0.5, dim=-1)\n",
    "# attn_weights_2.to(device)\n",
    "print(\"attn_weights_2: \", attn_weights_2)\n",
    "\n",
    "# The reason for the normalization by square root of embedding dimension size is to improve the training performance by avoiding small gradients. \n",
    "# For instance, when scaling up the embedding dimension, which is typically > 1,000 for GPT-like LLMs, large dot products can result in \n",
    "# very small gradients during backpropagation (due to the softmax function applied to them). \n",
    "# As dot products increase, the softmax function behaves more like a step function, resulting in gradients nearing zero. \n",
    "# These small gradients can drastically slow down learning or cause training to stagnate.\n",
    "#\n",
    "# The scaling by the square root of the embedding dimension is the reason why this self-attention mechanism is also called scaled-dot product attention.\n",
    "# Similar to when we computed the context vector as a weighted sum over the input vectors \n",
    "# we now compute the context vector as a weighted sum over the value vectors. \n",
    "# Here, the attention weights serve as a weighting factor that weighs the respective importance of each value vector\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "# context_vec_2.to(device)\n",
    "print(\"context_vec_2: \", context_vec_2)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2:  tensor([0.5500, 0.8700, 0.6600])\n",
      "Query 2:  tensor([0.4306, 1.4551])\n",
      "Key 2:    tensor([0.4433, 1.1419])\n",
      "Value 2:  tensor([0.3951, 1.0037])\n",
      "\n",
      "\n",
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "Attention (dot) score 22: tensor(1.8524)\n",
      "Attention \\@ Scores 2:  tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "attn_weights_2:  tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "context_vec_2:  tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "2ca52ea3a908fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.739827Z",
     "start_time": "2025-01-30T23:57:48.732356Z"
    }
   },
   "source": [
    "from src.chapter03.SelfAttention_v2 import SelfAttention_v2\n",
    "\n",
    "torch.manual_seed(789)\n",
    "self_attn_v2 = SelfAttention_v2(d_in, d_out)\n",
    "#print(\"Context vectors from SelfAtten_v2: \\n\", self_attn_v2(inputs))\n",
    "\n",
    "# Note since the input contains 6 embedding vectors, the output also has 6 rows of context vectors\n",
    "\n",
    "\n",
    "# Causal Attention \n",
    "# First we apply softmax to the attention scores then mask with 0 above the diagonal and then normalize the rows to 1\n",
    "#\n",
    "queries = self_attn_v2.W_query(inputs)\n",
    "# queries.to(device)\n",
    "\n",
    "keys = self_attn_v2.W_key(inputs)\n",
    "# keys.to(device)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "# attn_scores.to(device)\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "# attn_weights.to(device)\n",
    "#print(\"Attention Wrights: \\n\",attn_weights)\n",
    "\n",
    "# Now mask the values above diagonal as 0 using the tril() function\n",
    "#\n",
    "context_length = attn_scores.shape[0]\n",
    "#\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "#print(\"Mask Simple: \\n\", mask_simple)\n",
    "#\n",
    "# Now simply multiply them to prevent the look ahead \n",
    "#\n",
    "masked_attention_weights = attn_weights * mask_simple\n",
    "# masked_attention_weights.to(device)\n",
    "#print(\"Masked attention weights: \\n\", masked_attention_weights)\n",
    "\n",
    "#\n",
    "# Now re-normalize to make sure rows add up to 1. To do this we divide each element by sum of each row\n",
    "#\n",
    "row_sums = masked_attention_weights.sum(dim=-1, keepdim=True)\n",
    "#print(\"row_sums: \\n\", row_sums)\n",
    "masked_simple_norm = masked_attention_weights / row_sums\n",
    "print(\"Masked & re-normalized weights: \\n\", masked_simple_norm)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using 'mps:0' backend\n",
      "Masked & re-normalized weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "f3a442b3d9b7413a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.744117Z",
     "start_time": "2025-01-30T23:57:48.740461Z"
    }
   },
   "source": [
    "# A more efficient way to obtain masked attention weights is to mask the attention scores with \n",
    "# negative infinity before applying softmax function. (e^negative infinity -> 0)\n",
    "# We can implement this masking by replacing values above the diagonal with 1 and then replacing them \n",
    "# with negative infinity\n",
    "#\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "# mask.to(device)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "# masked.to(device)\n",
    "print(\"Masked attention weights: \\n\", masked)\n",
    "#\n",
    "# Now apply the softmax function \n",
    "#\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\"Softmax'd Attention weights: \\n\", attn_weights)\n",
    "\n",
    "# Now we can use these modified attention weights to calculate the context vector\n",
    "#\n",
    "context_vec = attn_weights @ values\n",
    "print(\"context_vec: \\n\", context_vec)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: \n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "Softmax'd Attention weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "context_vec: \n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.2795, 0.9361],\n",
      "        [0.3133, 0.9508],\n",
      "        [0.2994, 0.8595],\n",
      "        [0.2702, 0.7554],\n",
      "        [0.2772, 0.7618]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "d6b38e5f420f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.748760Z",
     "start_time": "2025-01-30T23:57:48.744859Z"
    }
   },
   "source": [
    "# Masking additional weights with dropout\n",
    "# Drop out in the attention mechanism is applied at 2 specific times: \n",
    "# 1. After calculating the attention weights\n",
    "# 2. After applying the attention weights to value vectors\n",
    "# Here we will apply the dropout mask after computing the attention weights\n",
    "#\n",
    "# Lets use a dropout rate of 50% meaning half the attention weights will be masked out. \n",
    "# Normally it's a much lower rate like 0.1 or 0.2\n",
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))\n",
    "#\n",
    "# Since we are applying 50% dropout, to compensate for reduction in active elements\n",
    "# we are going to scale up the values of remaining elements by a factor of 1/0.5 = 2\n",
    "# This scaling is crucial to maintain the balance of the attention weights\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "print(\"Dropped out attention weights: \\n\", dropout(attn_weights))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "Dropped out attention weights: \n",
      " tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "50701dd69a456857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.753833Z",
     "start_time": "2025-01-30T23:57:48.750400Z"
    }
   },
   "source": [
    "from src.chapter03.CausalAttention import CausalAttention\n",
    "\n",
    "# Let’s ensure that the code can handle batches consisting of more than one input so that \n",
    "# the CausalAttention class supports the batch outputs produced by the data loader\n",
    "# To simulate batch input lets duplicate the input text\n",
    "#\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "# batch.to(device)\n",
    "print(\"batch: \\n\", batch.shape)\n",
    "# print(batch)\n",
    "#\n",
    "# We can now use the CausalAttention class as follows\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_layer = batch.shape[1]\n",
    "causal_attn = CausalAttention(d_in, d_out, context_length, 0.0, False)\n",
    "context_vecs = causal_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: \n",
      " torch.Size([2, 6, 3])\n",
      "context_vecs: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "9d8058957dc253b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.759043Z",
     "start_time": "2025-01-30T23:57:48.754629Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttentionWrapper import MultiHeadAttentionWrapper\n",
    "\n",
    "# Multi Head Attention\n",
    "# Now if we use the MultiHeadAttentionWrapper class with two attention heads, and CausalAttention \n",
    "# output dimension d_out = 2, we get a 4 dimensional context vector (d_out * num_heads = 4).\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3, 2\n",
    "multi_head_attn = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0, num_heads=2, qkv_bias=False)\n",
    "context_vecs = multi_head_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs)\n",
    "print(\"context_vecs.shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs: \n",
      " tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: \n",
      " torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "f20088921d8113c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.790707Z",
     "start_time": "2025-01-30T23:57:48.786466Z"
    }
   },
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "# print(a.transpose(2, 3))\n",
    "a.to(device)\n",
    "\n",
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)\n",
    "\n",
    "print(f\"Batched: \\n{a @ a.transpose(2, 3)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n",
      "Batched: \n",
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "df6a05dfc13ebbe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.887105Z",
     "start_time": "2025-01-30T23:57:48.882848Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "print(\"Batch Shape: \\n\", batch.shape)\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"Context vector shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: \n",
      " torch.Size([2, 6, 3])\n",
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "Context vector shape: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "3f958161a85ca549",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Chapter 4: Implementing GPT from Scratch to generate text\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:48.986030Z",
     "start_time": "2025-01-30T23:57:48.983923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}"
   ],
   "id": "16f34621162871e9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "5ac1cbf145ad6daf",
   "metadata": {},
   "source": [
    "## Here is the proposed architecture and order of implementation\n",
    "![image](../data/4-3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "75010152b67235a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:49.668238Z",
     "start_time": "2025-01-30T23:57:49.036992Z"
    }
   },
   "source": [
    "from src.chapter04.DummyGPTModel import DummyGPTModel\n",
    "import tiktoken\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "#\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.clear()\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)).to(device))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)).to(device))\n",
    "batch = torch.stack(batch, dim=0).to(device)\n",
    "batch.to(device)\n",
    "print(\"Input Batch: \\n\", batch)\n",
    "print(\"Input batch shape: \\n\", batch.shape)\n",
    "#\n",
    "# Next, we initialize a new 124-million-parameter DummyGPTModel instance \n",
    "# and feed it the tokenized batch\n",
    "#\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "logits = model(batch)\n",
    "print(\"Output shape: \\n\", logits.shape)\n",
    "#print(logits)\n",
    "#                      \n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Batch: \n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Input batch shape: \n",
      " torch.Size([2, 4])\n",
      "Output shape: \n",
      " torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "c06060ecd0f8f8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:49.674319Z",
     "start_time": "2025-01-30T23:57:49.669286Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Let’s now implement LAYER Normalization to improve the stability and efficiency of the training.\n",
    "# The main idea behind LAYER Normalization is to adjust the activations (outputs) of a deep\n",
    "# neural network layer to have a mean of 0 and a variance of 1\n",
    "#\n",
    "# This adjustment speeds up the convergence.\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "#\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Layer: \\n\",out)\n",
    "#\n",
    "# The NN Layer contains the non-linear activation ReLU which 0's out the negative values\n",
    "# \n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Variance: \", var)\n",
    "print(\"\\n\")\n",
    "#\n",
    "# Next, let’s apply layer normalization to the layer outputs we obtained earlier. \n",
    "# The operation consists of subtracting the mean and dividing by the square root \n",
    "# of the variance (also known as the standard deviation):\n",
    "#\n",
    "eps = 1e-5\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "# Dim = -1 indicates statistics along the last dimention\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Normalized Layer Outputs: \\n\", out_norm)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: \n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n",
      "\n",
      "\n",
      "Normalized Layer Outputs: \n",
      " tensor([[6.1585e-01, 1.4126e+00, -8.7188e-01, 5.8723e-01, -8.7188e-01, -8.7188e-01],\n",
      "        [-1.8865e-02, 1.1211e-01, -1.0876e+00, 1.5173e+00, 5.6474e-01, -1.0876e+00]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000e+00],\n",
      "        [1.0000e+00]], grad_fn=<VarBackward0>)\n",
      "-------------------------\n",
      "\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "a39e430a037896f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:49.677856Z",
     "start_time": "2025-01-30T23:57:49.674926Z"
    }
   },
   "source": [
    "from src.chapter04.LayerNorm import LayerNorm\n",
    "\n",
    "# Previously we used unbiased = False in our variance calculation. This doesn't \n",
    "# apply Bessel's correction where divisor is n-1 instead of n. But this is \n",
    "# compatible with GPT-2\n",
    "\n",
    "ln = LayerNorm(emb_dim = 5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "3130c2c83093ee01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.015788Z",
     "start_time": "2025-01-30T23:57:49.679177Z"
    }
   },
   "source": [
    "# Let us see how the GELU (Gaussian Error Linear Unit) stacks up against \n",
    "# # RELU (REctified Linear Unit)\n",
    "from src.chapter04.GELU import GELU\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "e496e641f9044a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.036755Z",
     "start_time": "2025-01-30T23:57:50.017093Z"
    }
   },
   "source": [
    "from src.chapter04.SimpleFeedForward import SimpleFeedForward\n",
    "\n",
    "# As we can see the smoothness of the GELU can lead to better optimization properties during training\n",
    "# as it allows more nuanced finer adjustments to models parameters. In contrast, RELU has a sharp corner\n",
    "# that can make adjustments difficult for very deep networks.\n",
    "#\n",
    "# Next we look at implementing a feed forward network with GELU activations\n",
    "# See SimpleFeedForward.py\n",
    "#\n",
    "sff = SimpleFeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = sff(x)\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "98a59bc5db854fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.046415Z",
     "start_time": "2025-01-30T23:57:50.037764Z"
    }
   },
   "source": [
    "from src.chapter04.ExampleDeepNeuralNetwork import ExampleDeepNeuralNetwork\n",
    "\n",
    "# Next we implement Shortcut Connections\n",
    "# Each layer will be initialized such that it accepts an example with three input \n",
    "# values and returns three output values.\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "# model.to(device)\n",
    "\n",
    "# Next lets print the gradients\n",
    "def print_gradients(nnmodel, input_x):\n",
    "    output = nnmodel(input_x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    loss.backward()\n",
    "    for name, param in nnmodel.named_parameters():\n",
    "        # print(name, \" = \", param)\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "#\n",
    "# Now Lets use this function to print the gradients calculated by loss.backward()\n",
    "print_gradients(model_without_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "4bfdfab7cb5bcc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.063141Z",
     "start_time": "2025-01-30T23:57:50.047358Z"
    }
   },
   "source": [
    "# As you can see above gradients become tiny aka Vanishing from Layer4 to Layer1\n",
    "# Let’s now instantiate a model with skip connections and see how it compares:\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "# model.to(device)\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a229081ed60e29b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.065567Z",
     "start_time": "2025-01-30T23:57:50.063832Z"
    }
   },
   "source": [
    "# Note here the gradient doesn't approach a vanishingly small value during backprop.\n",
    "# In conclusion, shortcut connections are important for overcoming the limitations posed \n",
    "# by the vanishing gradient problem in deep neural networks."
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "2df6d339f0570629",
   "metadata": {},
   "source": [
    "#### Next, we’ll connect all the previously covered concepts (layer normalization, GELU activations, feed forward module, and shortcut connections) in a transformer  block, which is the final building block we need to code the GPT architecture.\n",
    "\n",
    "![image](../data/transformer_wiring.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd526dd3047ba477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:50.121788Z",
     "start_time": "2025-01-30T23:57:50.066172Z"
    }
   },
   "source": [
    "# See TransformerBlock.py for the basic sequence and feedforward details\n",
    "from src.chapter04.TransformerBlock import TransformerBlock\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "tr_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "out = tr_block(x)\n",
    "#\n",
    "print(\"Input Shape:  \", x.shape)\n",
    "print(\"Output Shape: \", out.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:   torch.Size([2, 4, 768])\n",
      "Output Shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "8c3e76bf70259f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.573661Z",
     "start_time": "2025-01-30T23:57:50.124253Z"
    }
   },
   "source": [
    "from src.chapter04.GPTModel import GPTModel \n",
    "\n",
    "# Let us wire up the actual GPT Model we wrote now\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "print(\"Input batch: \", batch)\n",
    "out = model(batch)\n",
    "print(\"Output shape: \", out.shape)\n",
    "# print(\"Out: \\n\", out)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Output shape:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "af55c75851ac7e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.576702Z",
     "start_time": "2025-01-30T23:57:51.574342Z"
    }
   },
   "source": [
    "# Note above the output tensor has the shape [2, 4, 50257], since we passed in two input texts (the two sentences) \n",
    "# with four tokens each. The last dimension, 50257, corresponds to the vocabulary size of the tokenizer.\n",
    "#\n",
    "# To capture the total number of Parameters for a model use numel parameter value\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "ba624b8ce1a7e0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "1a31524b0cdc6ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.579319Z",
     "start_time": "2025-01-30T23:57:51.577473Z"
    }
   },
   "source": [
    "# Weight Tying: The model reuses weights from the token embedding layer in its output layer\n",
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
    "# As we can see both shapes are same"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "197e0a5f1199aada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.587459Z",
     "start_time": "2025-01-30T23:57:51.580133Z"
    }
   },
   "source": [
    "# The token embedding and output layers are very large due to the 50,257 rows in the tokenizer’s vocabulary. \n",
    "# If we remove the output layer parameter count from the total GPT-2 model count :\n",
    "total_params_gptmodel = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of trainable parameters considering weight tying: \"\n",
    "      f\"{total_params_gptmodel:,}\")\n",
    "\n",
    "# Memory Requirement\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "82b6b3cc8d05feb4",
   "metadata": {},
   "source": [
    "# Generating text \n",
    "#### We will now write code to generate text from the predicted tensors by the GPTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da3f91bddda842d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.715013Z",
     "start_time": "2025-01-30T23:57:51.589195Z"
    }
   },
   "source": [
    "def generate_text_simple(input_model, tokenids, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        token_cond = tokenids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = input_model(token_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probabs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probabs, dim=-1, keepdim=True)\n",
    "        tokenids = torch.cat((tokenids, next_token), dim=1)\n",
    "\n",
    "        return tokenids\n",
    "#    \n",
    "#  Try it with a sample sentence  \n",
    "#    \n",
    "start_context = \"Hello, I am \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "#\n",
    "encoded_tensor = torch.tensor(encoded).to(device).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape: \", encoded_tensor.shape)\n",
    "#\n",
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716, 220]\n",
      "encoded_tensor.shape:  torch.Size([1, 5])\n",
      "Output: tensor([[15496,    11,   314,   716,   220, 24464]], device='mps:0')\n",
      "Output length: 6\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "ab7699859ab25da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.718485Z",
     "start_time": "2025-01-30T23:57:51.715976Z"
    }
   },
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am opia\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "7397b4b87caf10c6",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on unlabeled data\n",
    "#### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "id": "21d8324b6eace0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:51.938060Z",
     "start_time": "2025-01-30T23:57:51.718974Z"
    }
   },
   "source": [
    "# How to calculate loss and relatively randomize next word prediction\n",
    "#\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]]).to(device)   #  \"I really like\"\n",
    "#\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]).to(device)  #  \" really like chocolate\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(f\"probas: {probas.shape}\")\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Utility function\n",
    "def text_to_token_ids(txt, tokenizr):\n",
    "    encoded_txt = tokenizr.encode(txt, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tnsr = torch.tensor(encoded_txt).to(device).unsqueeze(0)\n",
    "    return encoded_tnsr\n",
    "\n",
    "# Utility function\n",
    "def token_ids_to_text(tokenids, tokenizr):\n",
    "    flat = tokenids.squeeze(0)\n",
    "    return tokenizr.decode(flat.tolist())\n",
    "\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 2: \", target_probas_2)\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token, \n",
    "# which involves increasing its probability relative to other tokens. \n",
    "\n",
    "# Loss of probabilities for the two batches are\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log probabilities for both batches are: \\n\", log_probas)\n",
    "\n",
    "# Next, we combine the log probabilities into a single score by computing \n",
    "# the average\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(f\"Average log probability: {avg_log_probas}\")\n",
    "\n",
    "# However, in deep learning, the common practice isn’t to push the average log probability \n",
    "# up to 0 but rather to bring the negative average log probability down to 0. The negative \n",
    "# average log probability is simply the average log probability multiplied by –1\n",
    "neg_avg_log_probabs = avg_log_probas * -1\n",
    "print(f\"Negative of average log probability: {neg_avg_log_probabs}\")\n",
    "\n",
    "# In deep learning, the term for turning this negative value, –10.7940, into 10.7940, \n",
    "# is known as the cross entropy loss.\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probas: torch.Size([2, 3, 50257])\n",
      "Token IDs: tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]], device='mps:0')\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n",
      "Softmax scores for Text 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05], device='mps:0')\n",
      "Softmax scores for Text 2:  tensor([4.2794e-05, 1.6248e-05, 1.1586e-05], device='mps:0')\n",
      "Log probabilities for both batches are: \n",
      " tensor([-1.0660e+01, -1.0794e+01, -1.1353e+01, -1.0059e+01, -1.1028e+01, -1.1366e+01],\n",
      "       device='mps:0')\n",
      "Average log probability: -10.876513481140137\n",
      "Negative of average log probability: 10.876513481140137\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "2e39970739c5f593",
   "metadata": {},
   "source": [
    "#### NOTE: Our goal during training is to get the average log probability as close to 0 as possible by updating the model’s weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:53.027419Z",
     "start_time": "2025-01-30T23:57:51.939254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M_2 = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(torch.device(\"mps\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ],
   "id": "62d971c360d51b5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Ae\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "d0465f554d8c18b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:53.045565Z",
     "start_time": "2025-01-30T23:57:53.028395Z"
    }
   },
   "source": [
    "print(\"Logits shape:\", logits.shape) # batch size, num of tokens, vocab size\n",
    "print(\"Targets shape:\", targets.shape) # batch size, num of tokens\n",
    "\n",
    "# For the cross_entropy loss function in PyTorch, we want to flatten these \n",
    "# tensors by combining them over the batch dimension:\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "# Now we can call CE from torch to calculate the loss\n",
    "celoss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(f\"Cross Entropy loss: {celoss}\")\n",
    "\n",
    "# Perplexity measures how well the probability distribution predicted by the model \n",
    "# matches the actual distribution of the words in the dataset. Similar to the loss, \n",
    "# a lower perplexity means the model predictions are closer to the actual distribution.\n",
    "perplexity = torch.exp(celoss)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross Entropy loss: 10.876513481140137\n",
      "Perplexity: 52918.7734375\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "9d0758479b082989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:57:53.587597Z",
     "start_time": "2025-01-30T23:57:53.046330Z"
    }
   },
   "source": [
    "from src.chapter02.Dataloader import Dataloader\n",
    "import torch.nn.functional as F\n",
    "# To implement the data splitting and loading, we first define a train_ratio \n",
    "# to use 90% of the data for training and the remaining 10% as validation data \n",
    "# for model evaluation during training\n",
    "torch.manual_seed(123)\n",
    "# \n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n",
    "# \n",
    "train_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(train_data)\n",
    "# \n",
    "val_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(val_data)\n",
    "# \n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "# \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "#     \n",
    "# Calculate per batch loss \n",
    "# Use CrossEntropy\n",
    "# \n",
    "def calculate_batch_loss(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)      \n",
    "    batch_logits = model(input_batch)\n",
    "    batch_loss = F.cross_entropy(\n",
    "        batch_logits.flatten(0, 1), \n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    # batch_loss = F.nll_loss(\n",
    "    #     batch_logits.flatten(0, 1), \n",
    "    #     target_batch.flatten()\n",
    "    # )\n",
    "    return batch_loss\n",
    "\n",
    "# \n",
    "# Calculate loss across batches\n",
    "# \n",
    "def calculate_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for n, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if n < num_batches:\n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "# \n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "print(\"Default Training loss:\", train_loss)\n",
    "print(\"Default Validation loss:\", val_loss)\n",
    "# \n",
    "# Model Evaluation\n",
    "#   Calculate both training and validation losses and return\n",
    "#\n",
    "def evaluate_model(eval_model, training_loader, validn_loader, eval_device, eval_iter):\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "        training_loss = calculate_loss_loader(\n",
    "            training_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "        validn_loss = calculate_loss_loader(\n",
    "            validn_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "    eval_model.train()\n",
    "    return training_loss, validn_loss\n",
    "\n",
    "# A convenience function that we use to track whether the model improves during the training. \n",
    "# The generate_and_print_sample() function takes a text snippet (start_context) as input, \n",
    "# converts it into token IDs, and feeds it to the LLM to generate a text sample \n",
    "# using the generate_text_simple function\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            input_model=model, \n",
    "            tokenids=encoded,\n",
    "            max_new_tokens=50, \n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# \n",
    "# Now we implement the model training flow \n",
    "#\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    # \n",
    "    for epoch in range(num_epochs):\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            \n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Back propagation\n",
    "            # Optimizer step function with no closure supplied is below.\n",
    "            # A closure should clear the gradients, compute the loss, and return it.\n",
    "            # For example if it was a Conjugate Grad. optimization method \n",
    "            # We had to pass a closure. A closure is nothing but a function\n",
    "            # for input, target in dataset:\n",
    "            #    def closure():\n",
    "            #        optimizer.zero_grad()\n",
    "            #        output = model(input)\n",
    "            #        loss = loss_fn(output, target)\n",
    "            #        loss.backward()\n",
    "            #        return loss\n",
    "            #    optimizer.step(closure) \n",
    "            # \n",
    "            optimizer.step() \n",
    "            \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                trn_loss, validn_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(trn_loss)\n",
    "                val_losses.append(validn_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {trn_loss:.3f}, \"\n",
    "                      f\"Val loss {validn_loss:.3f}\"\n",
    "                )\n",
    "        # End inner for\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context) # After each epoch\n",
    "    # End outer for\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Default Training loss: 10.988501654730904\n",
      "Default Validation loss: 10.990342140197754\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "9f203bec3d737b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:08:30.551333Z",
     "start_time": "2025-01-31T00:08:30.546730Z"
    }
   },
   "source": [
    "#\n",
    "# Training Loop\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "model_file_path=\"../models/GPTModel.pth\"\n",
    "if not os.path.exists(model_file_path):\n",
    "    model = GPTModel(GPT_CONFIG_124M_2)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "         model.parameters(),\n",
    "        lr=0.0004, \n",
    "        weight_decay=0.1\n",
    "    )\n",
    "    num_epochs = 10\n",
    "    # \n",
    "    train_losses, val_losses, tokens_seen = (\n",
    "        train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                           num_epochs=num_epochs, eval_freq=5, eval_iter=5, \n",
    "                           start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    "                           )\n",
    "    )\n",
    "else:\n",
    "    print(f\"Model already exists\")\n",
    "    pass "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "f525a5e6aafe03d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:08:43.251995Z",
     "start_time": "2025-01-31T00:08:43.191329Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "acfc02f2040cd8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:10:31.765069Z",
     "start_time": "2025-01-31T00:10:29.974871Z"
    }
   },
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Now lets look at Temperature Scaling\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "# Assume the model generates the following logits \n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "\n",
    "# We now generally do an argmax of the probabilities \n",
    "probas = torch.softmax(next_token_logits, dim=0).to(device)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(f\"Next token (argmax): {inverse_vocab[next_token_id]}\")\n",
    "#\n",
    "# But we can try replacing argmax with multinomial and get a sampling\n",
    "#\n",
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(f\"Next token (multinomial): {inverse_vocab[next_token_id]}\")\n",
    "# \n",
    "# Let's see if multinomial can produce any other probabilites\n",
    "def print_sampled_tokens(probabs):\n",
    "    torch.manual_seed(123)\n",
    "    # Multinomial Sampling of probabilities instead of max\n",
    "    samples = [torch.multinomial(probabs, num_samples=1).item() for _ in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(samples).to(device))\n",
    "    for cnt, freq in enumerate(sampled_ids):\n",
    "        print(f\"Sampled Freq. {freq} : {inverse_vocab[cnt]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "Next token (argmax): forward\n",
      "Next token (multinomial): forward\n",
      "Sampled Freq. 72 : closer\n",
      "Sampled Freq. 2 : every\n",
      "Sampled Freq. 0 : effort\n",
      "Sampled Freq. 575 : forward\n",
      "Sampled Freq. 2 : inches\n",
      "Sampled Freq. 0 : moves\n",
      "Sampled Freq. 0 : pizza\n",
      "Sampled Freq. 343 : toward\n",
      "Sampled Freq. 6 : you\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "2edb9cac7f426800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:10:44.170688Z",
     "start_time": "2025-01-31T00:10:44.111018Z"
    }
   },
   "source": [
    "# We can further control the distribution by a technique called temperature scaling\n",
    "# meaning dividing the logits with a >0 number\n",
    "def softmax_with_temperature(logits, temperature, dim):\n",
    "    scaled_logits = logits / temperature\n",
    "    scaled_probs =  torch.softmax(scaled_logits, dim=dim)\n",
    "    return scaled_probs\n",
    "\n",
    "# Let's check that out\n",
    "temperatures = [1, .01, 5]\n",
    "next_token_logits: Tensor = Tensor.cpu(next_token_logits)\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, float(T), 0) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.5\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, \n",
    "                   scaled_probas[i], \n",
    "                   bar_width, \n",
    "                   label=f'Temperature = {T}'\n",
    "    )\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Words')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "48c5d9214db5c7e3",
   "metadata": {},
   "source": [
    "## Top K sampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "af408748892d4b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:10:58.161870Z",
     "start_time": "2025-01-31T00:10:57.552983Z"
    }
   },
   "source": [
    "# Previously we implemented a probabilistic sampling approach coupled with \n",
    "# temperature scaling to increase the diversity of the outputs.  This method \n",
    "# allows for the exploring of less likely but potentially more interesting and \n",
    "# creative paths in the generation process.\n",
    "#\n",
    "# Top-k sampling, when combined with probabilistic sampling and temperature \n",
    "# scaling, can improve the text generation results.\n",
    "#\n",
    "# Here we can restrict the sampled tokens to the top-k most likely tokens \n",
    "# and exclude all other tokens from the selection process by masking their \n",
    "# probability scores\n",
    "# \n",
    "top_k = 3\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# \n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top Logits: \", top_logits)\n",
    "print(\"Top Positions: \", top_pos)\n",
    "print(f\"Next token logits: {next_token_logits}\")\n",
    "\n",
    "# Pytorch WHERE function to set the logit values of tokens that are below the lowest \n",
    "# logit value within our top-three selection to negative infinity (-inf)\n",
    "#\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New Logits: \", new_logits)\n",
    "\n",
    "# Now apply the softmax\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(f\"top k probabilities: {topk_probas}\")\n",
    "# \n",
    "# We can now apply the temperature scaling and multinomial function for probabilistic \n",
    "# sampling to select the next token among these three non-zero probability scores to \n",
    "# GENERATE THE NEXT TOKEN with more diversity.\n",
    "# \n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k: int=None, eos_id=None):\n",
    "    # print(\"Entering generate()..\")\n",
    "    # print(idx.shape)\n",
    "    for i in range(max_new_tokens):\n",
    "        # print(f\"idx: [{i}]: {idx}\")\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        #     \n",
    "        logits = logits[:, -1, :] # ([1, 50257])\n",
    "        # print(logits.shape)\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val: Tensor = top_logits[:, -1] # Less than the lowest value of top k\n",
    "            # Now mark the minvals with -inf, so softmax becomes 0\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            probs = softmax_with_temperature(logits, temperature, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else: \n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # Next word\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions:  tensor([3, 7, 0])\n",
      "Next token logits: tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "New Logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "top k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
      "Output text:\n",
      " Every effort moves you circulation,\" was the one of her of his \".\"\n",
      "\n",
      "\"I\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:11:13.879564Z",
     "start_time": "2025-01-31T00:11:10.949551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.save(model.state_dict(), f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\")\n",
    "MODEL_PATH = f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\"\n",
    "# \n",
    "try:\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }, \n",
    "        MODEL_PATH\n",
    "    )\n",
    "    print(f\"Model saved at {MODEL_PATH}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Encountered exception : {e}\")\n",
    "    \n",
    "# "
   ],
   "id": "7e164cfeef1f9707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at /Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/GPTModel.pth\n",
      "\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:11:27.879573Z",
     "start_time": "2025-01-31T00:11:26.152638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model back\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device,weights_only=True)\n",
    "loaded_model = GPTModel(GPT_CONFIG_124M_2).to(device)\n",
    "try:\n",
    "    loaded_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer = torch.optim.AdamW(loaded_model.parameters(), \n",
    "                                 lr=GPT_CONFIG_124M_2[\"lr\"], \n",
    "                                 weight_decay=GPT_CONFIG_124M_2[\"weight_decay\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    print(f\"Model and Optimizer successfully loaded from \\n{MODEL_PATH}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Encountered exception : {e}\")\n",
    "    \n",
    "loaded_model.train()\n",
    "print(\"Model set to train mode\")"
   ],
   "id": "d0a3f72c8cebc09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Optimizer successfully loaded from \n",
      "/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/GPTModel.pth\n",
      "\n",
      "Model set to train mode\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:11:27.882082Z",
     "start_time": "2025-01-31T00:11:27.880343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try training the model a couple of times more\n",
    "# epochs = 2\n",
    "# train_ratio = 0.9\n",
    "# # \n",
    "# print(f\"Model is on {next(model.parameters()).device}\")  \n",
    "# train_losses, val_losses, tokens_seen = (\n",
    "#     train_model_simple(\n",
    "#         loaded_model, \n",
    "#         train_loader, \n",
    "#         val_loader, \n",
    "#         optimizer, \n",
    "#         device, \n",
    "#         num_epochs=epochs, \n",
    "#         eval_freq=5, \n",
    "#         eval_iter=5, \n",
    "#         start_context=\"Every effort moves you\", \n",
    "#         tokenizer=tokenizer\n",
    "#     )\n",
    "# )\n",
    "# epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "f6108362246432af",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### OpenAI also shares the weights of larger models: 355M, 774M, and 1558M \n",
    "![image](../data/model_arch_stack.png)\n",
    "\n"
   ],
   "id": "d38b09e853311dec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:11:42.623251Z",
     "start_time": "2025-01-31T00:11:40.528711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the downloaded GPT Data\n",
    "import urllib.request\n",
    "from src.chapter05.gpt_download import download_and_load_gpt2\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "settings, gpt_params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"../data/gpt2\")\n",
    "print(f\"\\nParams: {gpt_params.keys()}\")\n",
    "print(f\"Settings: {settings}\")\n",
    "print(f\"Token embedding layer weight tensor dimensions: {gpt_params[\"wte\"].shape}\")    \n"
   ],
   "id": "68e160927f07d23a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../data/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/vocab.bpe\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Token embedding layer weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:11:56.076512Z",
     "start_time": "2025-01-31T00:11:55.137445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# After loading the GPT-2 model weights into Python, we still need to transfer \n",
    "# them from the settings and params dictionaries into our GPTModel instance. \n",
    "# First, we create a dictionary that lists the differences between the \n",
    "# different GPT model sizes\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "model_name=\"gpt2-small (124M)\"\n",
    "# \n",
    "NEW_GPT_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_GPT_CONFIG.update({\"model_name\": model_name})\n",
    "# Update the value ex. {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "NEW_GPT_CONFIG.update(model_configs[model_name]) \n",
    "\n",
    "NEW_GPT_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_GPT_CONFIG.update({\"qkv_bias\": True})\n",
    "# \n",
    "print(f\"{model_name}: {model_configs[model_name]}\")\n",
    "print(\"NEW_GPT_CONFIG:\\n\"+\"\".join(f\"\\t{k}: {v}\\n\" for k, v in sorted(NEW_GPT_CONFIG.items())))\n",
    "# \n",
    "newgpt = GPTModel(NEW_GPT_CONFIG).to(device)\n",
    "newgpt.eval()\n",
    "# \n",
    "# Before we assign the loaded openai weights into the model, we will first define \n",
    "# a small assign utility function that checks whether two tensors or arrays \n",
    "# (left and right) have the same dimensions or shape and returns the right tensor \n",
    "# as trainable PyTorch parameters\n",
    "def assign(left: Tensor, right: Tensor) -> Tensor:\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch Left shape: {left.shape} Right shape: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right).to(device))\n",
    "# \n",
    "print(f\"Params: {gpt_params.keys()}\")\n",
    "# print(f\"Params: {gpt_params}\")\n",
    "print(f\"GPT Parameter Blocks Count: {len(gpt_params[\"blocks\"])}\")"
   ],
   "id": "ba48ffe795182755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-small (124M): {'emb_dim': 768, 'n_layers': 12, 'n_heads': 12}\n",
      "NEW_GPT_CONFIG:\n",
      "\tcontext_length: 1024\n",
      "\tdrop_rate: 0.1\n",
      "\temb_dim: 768\n",
      "\tlr: 0.0005\n",
      "\tmodel_name: gpt2-small (124M)\n",
      "\tn_heads: 12\n",
      "\tn_layers: 12\n",
      "\tqkv_bias: True\n",
      "\tvocab_size: 50257\n",
      "\tweight_decay: 0.1\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "GPT Parameter Blocks Count: 12\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:12:08.880327Z",
     "start_time": "2025-01-31T00:12:08.875023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Load OpenAI Weights into our GPTModel code\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].sff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].sff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    "
   ],
   "id": "dbc4d3fb2c383826",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:12:22.086261Z",
     "start_time": "2025-01-31T00:12:21.918870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now lets try to load the weights and see\n",
    "load_weights_into_gpt(newgpt, gpt_params)\n",
    "newgpt.to(device)\n",
    "print(\"Loaded weights into GPTModel..\")"
   ],
   "id": "c0eeef9e5cadf037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights into GPTModel\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:12:23.834910Z",
     "start_time": "2025-01-31T00:12:23.007517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now lets generate\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=newgpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_GPT_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "53993f0b2ef4021a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more efficient and efficient processes, like in the car's oil and gas operation,\" the study said. To see if that\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:59:40.003828Z",
     "start_time": "2025-01-30T23:59:40.002330Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "68541d175335de06",
   "outputs": [],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
