{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is an attempt to learn by building and training an LLM from Scratch\n",
    "## Chapter 01  "
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.605473Z",
     "start_time": "2025-02-10T00:26:58.716971Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import urllib.request\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check which GPU if any is available\n",
    "# torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     x: Tensor = torch.ones(1, device=device)\n",
    "#     print(f\"x = {x} using 'cuda:0' backend\")\n",
    "#     \n",
    "# elif \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x: Tensor = torch.ones(1, device=device)\n",
    "    print(f\"x = {x} using {device} backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # x: Tensor = torch.ones(1, device=device)\n",
    " \n",
    "print(\"Running on : \", device)\n",
    "\n",
    "def get_some_text():\n",
    "    # Download a text (book)\n",
    "    bookUrl = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"  \n",
    "    filepath = \"../data/the-verdict.txt\"\n",
    "    # print(file_path)\n",
    "    if not os.path.exists(filepath):\n",
    "        urllib.request.urlretrieve(bookUrl, filepath)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        rawtext = f.read()\n",
    "        \n",
    "    print(\"Total characters in the story: \", len(rawtext))\n",
    "    print(\"Total Lines in raw text: \", rawtext.count(\"\\n\"))\n",
    "    return rawtext\n",
    "\n",
    "raw_text = get_some_text()\n",
    "print(\"Some text: \", raw_text[:49])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using mps backend\n",
      "Running on :  mps\n",
      "Total characters in the story:  20479\n",
      "Total Lines in raw text:  164\n",
      "Some text:  I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2c7227e79afbcad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.637921Z",
     "start_time": "2025-02-10T00:26:59.634906Z"
    }
   },
   "source": [
    "# Now we have to tokenize the text. The best way to do that is to use a pre-build tokennizer, but first we will try some \n",
    "# basic python regular expressions to do the same things\n",
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "#\n",
    "print(len(preprocessed))\n",
    "print(preprocessed[:30])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b9dc98b584bc6d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.690210Z",
     "start_time": "2025-02-10T00:26:59.687454Z"
    }
   },
   "source": [
    "# Now we need to generate token IDs\n",
    "# Now let us create a list of all unique tokens and sort them alphabetically to determine the vocabulary size\n",
    "all_uniq_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_uniq_words)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "\n",
    "# Now that we know the vocabulary size, lets enumerate and assign some numbers to them\n",
    "vocab = {token:integer for integer,token in enumerate(all_uniq_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1130\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b49e9060996c9f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.709848Z",
     "start_time": "2025-02-10T00:26:59.706195Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV1 import SimpleTokenizerV1\n",
    "\n",
    "# Now we want to apply this vocabulary to convert new text to generate token id\n",
    "# When we want to convert the outputs of an LLM from numbers back into text, we need a way to turn token IDs into text. \n",
    "# For this, we can create an inverse version of the vocabulary that maps token IDs back to the corresponding text tokens.\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted you know,\" \n",
    "        Mrs Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 1126, 596, 5, 1, 67, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted you know,\" Mrs Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "92b6519fe1741db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.772835Z",
     "start_time": "2025-02-10T00:26:59.770045Z"
    }
   },
   "source": [
    "all_tokens = sorted(list(set(preprocessed))) # Make preprocessed a list so we can extend it\n",
    "all_tokens.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
    "# redo the vocab population\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d03ae607c2d20268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:26:59.931733Z",
     "start_time": "2025-02-10T00:26:59.927529Z"
    }
   },
   "source": [
    "# Print the last 5 vocab items\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|unk|>', 1130)\n",
      "('<|endoftext|>', 1131)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "dcdf224cd056d26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.056020Z",
     "start_time": "2025-02-10T00:27:00.052588Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV2 import SimpleTokenizerV2\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984, 722, 988, 1130, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e4e4738351ee6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.127479Z",
     "start_time": "2025-02-10T00:27:00.114893Z"
    }
   },
   "source": [
    "### Byte Pair Encoding \n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"Tiktoken version: \", version(\"tiktoken\"))\n",
    "#print(\"Tiktoken version: \", tiktoken.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ac57b0bafdc676f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.332702Z",
     "start_time": "2025-02-10T00:27:00.151130Z"
    }
   },
   "source": [
    "#### This is the tokenizer using the GPT2 tokenization model\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Encoded: {integers}\")\n",
    "strings = tokenizer.decode(integers)\n",
    "print(f\"Decoded: {strings}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Decoded: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2a6a5225d4fab946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.361037Z",
     "start_time": "2025-02-10T00:27:00.358678Z"
    }
   },
   "source": [
    "print(tokenizer.encode(\"Akwirw ier\"))\n",
    "print(tokenizer.decode(tokenizer.encode(\"Akwirw ier\")))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1ab2edd9fb1ca03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.433445Z",
     "start_time": "2025-02-10T00:27:00.429127Z"
    }
   },
   "source": [
    "# Let's now do Data Sampling with a sliding window\n",
    "# 1. Let's tokenize the entire story with BPE tokenizer first\n",
    "\n",
    "encoded_text = tokenizer.encode(raw_text)\n",
    "print(len(encoded_text))\n",
    "enc_sample = encoded_text[50:]\n",
    "\n",
    "# Now Let's start by defining x and y where x has input tokens and y the output tokens shifted by 1\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "# print(f\"x: {x}\")\n",
    "# print(f\"y:      {y}\")\n",
    "\n",
    "\n",
    "#####\n",
    "# Next word prediction tasks can now be created by \n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    # print(f\"context input: {context} --> desired prediction: {desired}\")\n",
    "    # Now we create the input output target pairs\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "62094a4513e01008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.493609Z",
     "start_time": "2025-02-10T00:27:00.491530Z"
    }
   },
   "source": [
    "# from Dataloader import Dataloader\n",
    "# \n",
    "# dataloader = Dataloader(batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "# dataloader = dataloader.get_instance(file_path, text_enc='utf-8', mode='r')\n",
    "# if dataloader is not None:\n",
    "#     data_iter = iter(dataloader)\n",
    "#     inputs, targets = next(data_iter)\n",
    "#     print(\"Loaded text data...\\n\")\n",
    "#     print(\"Inputs: \\n\", inputs)\n",
    "#     print(\"\\nTargets: \\n\", targets)\n",
    "# else: \n",
    "#     print(\"Failed loading \", dataloader)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "fa0c4b5f389cdc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.705509Z",
     "start_time": "2025-02-10T00:27:00.558863Z"
    }
   },
   "source": [
    "import torch.nn\n",
    "from src.chapter02.Dataloader import Dataloader\n",
    "file_path = \"../data/the-verdict.txt\"\n",
    "\n",
    "####\n",
    "# Finally we need to create the embeddings for the tokens\n",
    "# If we have a batch size of 8 with 4 tokens each it'll be an 8 x 4 x 256 tensor\n",
    "max_length = 4  \n",
    "\n",
    "mydataloader = Dataloader(batch_size=8, max_length=max_length, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "dataloader = mydataloader.create_dataloader_v1(txt=raw_text)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "# print(\"Input Token IDs:\\n\", inputs)\n",
    "# print(\"Input tensor shape: \", inputs.shape) \n",
    "\n",
    "# Now since self-attentions are position agnostic, we should add some positional data.\n",
    "# Absolute and relative positional data can be added. So let's create embeddings with say 256 dimensions\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "# context_length = 1024\n",
    "\n",
    "## Now lets embed the input tensors\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token embeddings shape: \", token_embeddings.shape) #8x4x256\n",
    "\n",
    "\n",
    "# For a GPT model’s absolute position embedding approach, we just need to create another embedding \n",
    "# layer that has the same embedding dimension as the token_embedding_ layer:\n",
    "context_length = max_length     #context is length of positions we care about for attention\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embeddings Shape: \", pos_embeddings.shape) # 4x256\n",
    "#\n",
    "# Add the positional embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Position Merged Input Embeddings Shape: \", input_embeddings.shape)\n",
    "#\n",
    "# Now lets look at the dataloader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    token_embeddings = token_embedding_layer(inputs)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "    break\n",
    "#\n",
    "print(\"Batch Embeddings Shape: \", input_embeddings.shape)\n",
    "    \n",
    "print(\"Input tensor \", x)\n",
    "print(\"Target tensor\", y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape:  torch.Size([8, 4, 256])\n",
      "Positional Embeddings Shape:  torch.Size([4, 256])\n",
      "Position Merged Input Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Batch Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Input tensor  [290, 4920, 2241, 287]\n",
      "Target tensor [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "95c2c3a6eb3eea50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.718879Z",
     "start_time": "2025-02-10T00:27:00.714920Z"
    }
   },
   "source": [
    "# Chapter 3 - Attention\n",
    "#\n",
    "import torch\n",
    "\n",
    "# In self-attention our goal is to calculate context vector z(i) for each \n",
    "# element x(i) of the input sequence. Consider the following input sequence \n",
    "#\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "# inputs.to(device)\n",
    "print(\"Input sequence shape: \", inputs.shape)\n",
    "# \n",
    "# Now calculate weights for attention\n",
    "# Assume query is the second word \"journey\" or inputs[1] \n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "print(f\"Query is the 2nd word 'journey': {query}\")\n",
    "#\n",
    "attention_scores_2 = torch.empty(inputs.shape[0])\n",
    "# attention_scores_2.to(device)\n",
    "for idx, x_i in enumerate(inputs):\n",
    "    attention_scores_2[idx] = torch.dot(x_i, query)\n",
    "#    print(f\"Sequence Element [{idx}], attention_score: {attention_scores_2}\")\n",
    "print(f\"Final value of attention_score_2: {attention_scores_2}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape:  torch.Size([6, 3])\n",
      "Query is the 2nd word 'journey': tensor([0.5500, 0.8700, 0.6600])\n",
      "Final value of attention_score_2: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "53ede1deb7d5678e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.766518Z",
     "start_time": "2025-02-10T00:27:00.761309Z"
    }
   },
   "source": [
    "\n",
    "## Note: For all elements if we were to calculate attention it'd be a O(n^2) operation\n",
    "# NOW we normalize the attention weights, so they sum up to 1\n",
    "attention_weights_2_tmp = attention_scores_2 / attention_scores_2.sum()\n",
    "# attention_weights_2_tmp.to(device)\n",
    "print(\"Normalized attention weights:\", attention_weights_2_tmp)\n",
    "print(\"Sum of attention weights:\", attention_weights_2_tmp.sum())\n",
    "\n",
    "## Generally we normalize using the softmax to do the normalization\n",
    "\n",
    "# # define a softmax function\n",
    "def softmax_naive(tensor_x):\n",
    "    return torch.exp(tensor_x) / torch.exp(tensor_x).sum(dim=0, keepdim=True)\n",
    "# \n",
    "\n",
    "attention_scores_2_naive = softmax_naive(attention_scores_2)\n",
    "# attention_scores_2_naive.to(device)\n",
    "\n",
    "print(\"Attention weights naive:\", attention_scores_2_naive)\n",
    "print (\"Naive Sum: \", attention_scores_2_naive.sum())\n",
    "# \n",
    "# Generally we normalize using the torch.softmax() to do the normalization\n",
    "# Softmax ensures its always positive and always adds up to 1\n",
    "#\n",
    "attention_weights_2_torch_softmax = torch.softmax(attention_scores_2, dim=0)\n",
    "# attention_weights_2_torch_softmax.to(device)\n",
    "print(\"Attention weights torch softmax:\", attention_weights_2_torch_softmax)\n",
    "# print(\"Attention weights torch softmax Sum: \", attention_weights_2_torch_softmax.sum())\n",
    "\n",
    "# Now that we have calculated the normalized attention weights, we are ready for the final step.\n",
    "# Calculate the context vector z(2) by multiplying the embedded input tokens x(i), \n",
    "# with the corresponding normalized attention weights and then summing the resultant vectors\n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "#\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "# context_vec_2.to(device)\n",
    "#\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += (attention_weights_2_torch_softmax[i] * x_i)\n",
    "print(\"Context vector z2: \", context_vec_2)\n",
    "\n",
    "#\n",
    "# Now in similar fashion lets calculate attention scores for all the input sequences \n",
    "attention_scores = torch.empty(inputs.shape[0],inputs.shape[0])\n",
    "# attention_scores.to(device)\n",
    "print(\"\\nAttention Scores matrix shape: \", attention_scores.shape)\n",
    "#\n",
    "# Using for loops\n",
    "#\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attention_scores[i, j] = torch.dot(x_i, x_j)\n",
    "# #\n",
    "#print(attention_scores)\n",
    "#\n",
    "# Using matrix multiplication we can do it faster\n",
    "#\n",
    "attention_scores_m = inputs @ inputs.T\n",
    "# attention_scores_m.to(device)\n",
    "#print(\"Normalized attention scores \\n\", attention_scores_m)\n",
    "\n",
    "# Just as before lets normalize the rows, so they sum up to 1\n",
    "# NOTE: Here dim = -1 means we are applying the softmax along the last dimension of the attention_scores_m tensor\n",
    "#\n",
    "attention_weights = torch.softmax(attention_scores_m, dim=-1)\n",
    "# attention_weights.to(device)\n",
    "#print(\"Normalized ATTENTION weights \\n\", attention_weights)\n",
    "# print(\"Softmax Sums:\\n\", attention_weights.sum(dim=-1))\n",
    "\n",
    "# FINAL STEP\n",
    "# Now let's calculate the context vectors for all the input by multiplying the input with attention weights\n",
    "all_context_vectors = attention_weights @ inputs # Matrix multiplication\n",
    "# all_context_vectors.to(device)\n",
    "#print(\"Context vector for the entire sequence\\n\", all_context_vectors)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum of attention weights: tensor(1.0000)\n",
      "Attention weights naive: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Naive Sum:  tensor(1.)\n",
      "Attention weights torch softmax: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Context vector z2:  tensor([0.4419, 0.6515, 0.5683])\n",
      "\n",
      "Attention Scores matrix shape:  torch.Size([6, 6])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "fa980b537b01e646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.855689Z",
     "start_time": "2025-02-10T00:27:00.849583Z"
    }
   },
   "source": [
    "\n",
    "###\n",
    "### 3.4.1 Using weighted matrix\n",
    "###\n",
    "#\n",
    "# Computing the attention weights step by step\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "x_2 = inputs[1]\n",
    "# x_2.to(device)\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(\"x_2: \", x_2)\n",
    "# Now let's initialize 3 weighted matrices Wq, Wk and Wv\n",
    "# Setting requires_grad = False, to reduce clutter, but for model training this should be set to True\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "#\n",
    "# Next we compute the query, key and value vectors\n",
    "# Note the output is a 2 dimenstional vector because we set dout to 2\n",
    "#\n",
    "# W_query.to(device)\n",
    "# W_key.to(device)\n",
    "# W_value.to(device)\n",
    "#\n",
    "# Now the dot product with the input\n",
    "#\n",
    "query_2 = x_2 @ W_query\n",
    "key_2   = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "#\n",
    "# query_2.to(device)\n",
    "# key_2.to(device)\n",
    "# value_2.to(device)\n",
    "#\n",
    "print(\"Query 2: \", query_2)\n",
    "print(\"Key 2:   \", key_2)\n",
    "print(\"Value 2: \", value_2)\n",
    "#\n",
    "print(\"\\n\")\n",
    "#\n",
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "# keys.to(device)\n",
    "# values.to(device)\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "\n",
    "keys_2 = keys[1]\n",
    "\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "# attn_score_22.to(device)\n",
    "# attn_score_22 = query_2 @ keys_2\n",
    "print(\"Attention (dot) score 22:\", attn_score_22)\n",
    "\n",
    "# Generalizing across all inputs\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "# attn_scores_2.to(device)\n",
    "print(\"Attention \\\\@ Scores 2: \", attn_scores_2)\n",
    "# Check the second element is same as previously calculated attention score\n",
    "#\n",
    "# We compute the attention weights by scaling the attention scores and using the softmax function. \n",
    "# However, now we scale the attention scores by dividing them by the square root of the embedding \n",
    "# dimension of the keys\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1]**0.5, dim=-1)\n",
    "# attn_weights_2.to(device)\n",
    "print(\"attn_weights_2: \", attn_weights_2)\n",
    "\n",
    "# The reason for the normalization by square root of embedding dimension size is to improve the training performance by avoiding small gradients. \n",
    "# For instance, when scaling up the embedding dimension, which is typically > 1,000 for GPT-like LLMs, large dot products can result in \n",
    "# very small gradients during backpropagation (due to the softmax function applied to them). \n",
    "# As dot products increase, the softmax function behaves more like a step function, resulting in gradients nearing zero. \n",
    "# These small gradients can drastically slow down learning or cause training to stagnate.\n",
    "#\n",
    "# The scaling by the square root of the embedding dimension is the reason why this self-attention mechanism is also called scaled-dot product attention.\n",
    "# Similar to when we computed the context vector as a weighted sum over the input vectors \n",
    "# we now compute the context vector as a weighted sum over the value vectors. \n",
    "# Here, the attention weights serve as a weighting factor that weighs the respective importance of each value vector\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "# context_vec_2.to(device)\n",
    "print(\"context_vec_2: \", context_vec_2)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2:  tensor([0.5500, 0.8700, 0.6600])\n",
      "Query 2:  tensor([0.4306, 1.4551])\n",
      "Key 2:    tensor([0.4433, 1.1419])\n",
      "Value 2:  tensor([0.3951, 1.0037])\n",
      "\n",
      "\n",
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "Attention (dot) score 22: tensor(1.8524)\n",
      "Attention \\@ Scores 2:  tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "attn_weights_2:  tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "context_vec_2:  tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "2ca52ea3a908fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:00.989205Z",
     "start_time": "2025-02-10T00:27:00.980465Z"
    }
   },
   "source": [
    "from src.chapter03.SelfAttention_v2 import SelfAttention_v2\n",
    "\n",
    "torch.manual_seed(789)\n",
    "self_attn_v2 = SelfAttention_v2(d_in, d_out)\n",
    "#print(\"Context vectors from SelfAtten_v2: \\n\", self_attn_v2(inputs))\n",
    "\n",
    "# Note since the input contains 6 embedding vectors, the output also has 6 rows of context vectors\n",
    "\n",
    "\n",
    "# Causal Attention \n",
    "# First we apply softmax to the attention scores then mask with 0 above the diagonal and then normalize the rows to 1\n",
    "#\n",
    "queries = self_attn_v2.W_query(inputs)\n",
    "# queries.to(device)\n",
    "\n",
    "keys = self_attn_v2.W_key(inputs)\n",
    "# keys.to(device)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "# attn_scores.to(device)\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "# attn_weights.to(device)\n",
    "#print(\"Attention Wrights: \\n\",attn_weights)\n",
    "\n",
    "# Now mask the values above diagonal as 0 using the tril() function\n",
    "#\n",
    "context_length = attn_scores.shape[0]\n",
    "#\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "#print(\"Mask Simple: \\n\", mask_simple)\n",
    "#\n",
    "# Now simply multiply them to prevent the look ahead \n",
    "#\n",
    "masked_attention_weights = attn_weights * mask_simple\n",
    "# masked_attention_weights.to(device)\n",
    "#print(\"Masked attention weights: \\n\", masked_attention_weights)\n",
    "\n",
    "#\n",
    "# Now re-normalize to make sure rows add up to 1. To do this we divide each element by sum of each row\n",
    "#\n",
    "row_sums = masked_attention_weights.sum(dim=-1, keepdim=True)\n",
    "#print(\"row_sums: \\n\", row_sums)\n",
    "masked_simple_norm = masked_attention_weights / row_sums\n",
    "print(\"Masked & re-normalized weights: \\n\", masked_simple_norm)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using 'mps:0' backend\n",
      "Masked & re-normalized weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f3a442b3d9b7413a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.160071Z",
     "start_time": "2025-02-10T00:27:01.155922Z"
    }
   },
   "source": [
    "# A more efficient way to obtain masked attention weights is to mask the attention scores with \n",
    "# negative infinity before applying softmax function. (e^negative infinity -> 0)\n",
    "# We can implement this masking by replacing values above the diagonal with 1 and then replacing them \n",
    "# with negative infinity\n",
    "#\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "# mask.to(device)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "# masked.to(device)\n",
    "print(\"Masked attention weights: \\n\", masked)\n",
    "#\n",
    "# Now apply the softmax function \n",
    "#\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\"Softmax'd Attention weights: \\n\", attn_weights)\n",
    "\n",
    "# Now we can use these modified attention weights to calculate the context vector\n",
    "#\n",
    "context_vec = attn_weights @ values\n",
    "print(\"context_vec: \\n\", context_vec)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: \n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "Softmax'd Attention weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "context_vec: \n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.2795, 0.9361],\n",
      "        [0.3133, 0.9508],\n",
      "        [0.2994, 0.8595],\n",
      "        [0.2702, 0.7554],\n",
      "        [0.2772, 0.7618]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "d6b38e5f420f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.302360Z",
     "start_time": "2025-02-10T00:27:01.297639Z"
    }
   },
   "source": [
    "# Masking additional weights with dropout\n",
    "# Drop out in the attention mechanism is applied at 2 specific times: \n",
    "# 1. After calculating the attention weights\n",
    "# 2. After applying the attention weights to value vectors\n",
    "# Here we will apply the dropout mask after computing the attention weights\n",
    "#\n",
    "# Lets use a dropout rate of 50% meaning half the attention weights will be masked out. \n",
    "# Normally it's a much lower rate like 0.1 or 0.2\n",
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))\n",
    "#\n",
    "# Since we are applying 50% dropout, to compensate for reduction in active elements\n",
    "# we are going to scale up the values of remaining elements by a factor of 1/0.5 = 2\n",
    "# This scaling is crucial to maintain the balance of the attention weights\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "print(\"Dropped out attention weights: \\n\", dropout(attn_weights))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "Dropped out attention weights: \n",
      " tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "50701dd69a456857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.430393Z",
     "start_time": "2025-02-10T00:27:01.425077Z"
    }
   },
   "source": [
    "from src.chapter03.CausalAttention import CausalAttention\n",
    "\n",
    "# Let’s ensure that the code can handle batches consisting of more than one input so that \n",
    "# the CausalAttention class supports the batch outputs produced by the data loader\n",
    "# To simulate batch input lets duplicate the input text\n",
    "#\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "# batch.to(device)\n",
    "print(\"batch: \\n\", batch.shape)\n",
    "# print(batch)\n",
    "#\n",
    "# We can now use the CausalAttention class as follows\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_layer = batch.shape[1]\n",
    "causal_attn = CausalAttention(d_in, d_out, context_length, 0.0, False)\n",
    "context_vecs = causal_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: \n",
      " torch.Size([2, 6, 3])\n",
      "context_vecs: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9d8058957dc253b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.564210Z",
     "start_time": "2025-02-10T00:27:01.555237Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttentionWrapper import MultiHeadAttentionWrapper\n",
    "\n",
    "# Multi Head Attention\n",
    "# Now if we use the MultiHeadAttentionWrapper class with two attention heads, and CausalAttention \n",
    "# output dimension d_out = 2, we get a 4 dimensional context vector (d_out * num_heads = 4).\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3, 2\n",
    "multi_head_attn = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0, num_heads=2, qkv_bias=False)\n",
    "context_vecs = multi_head_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs)\n",
    "print(\"context_vecs.shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs: \n",
      " tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: \n",
      " torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "f20088921d8113c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.683559Z",
     "start_time": "2025-02-10T00:27:01.679356Z"
    }
   },
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "# print(a.transpose(2, 3))\n",
    "a.to(device)\n",
    "\n",
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)\n",
    "\n",
    "print(f\"Batched: \\n{a @ a.transpose(2, 3)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n",
      "Batched: \n",
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "df6a05dfc13ebbe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.723073Z",
     "start_time": "2025-02-10T00:27:01.718865Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "print(\"Batch Shape: \\n\", batch.shape)\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"Context vector shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: \n",
      " torch.Size([2, 6, 3])\n",
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "Context vector shape: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "3f958161a85ca549",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Chapter 4: Implementing GPT from Scratch to generate text\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "id": "16f34621162871e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:01.813034Z",
     "start_time": "2025-02-10T00:27:01.810980Z"
    }
   },
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "5ac1cbf145ad6daf",
   "metadata": {},
   "source": [
    "\n",
    "## Here is the proposed architecture and order of implementation\n",
    "![image](../data/4-3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "75010152b67235a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:02.759709Z",
     "start_time": "2025-02-10T00:27:02.147322Z"
    }
   },
   "source": [
    "from src.chapter04.DummyGPTModel import DummyGPTModel\n",
    "import tiktoken\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "#\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.clear()\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)).to(device))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)).to(device))\n",
    "batch = torch.stack(batch, dim=0).to(device)\n",
    "batch.to(device)\n",
    "print(\"Input Batch: \\n\", batch)\n",
    "print(\"Input batch shape: \\n\", batch.shape)\n",
    "#\n",
    "# Next, we initialize a new 124-million-parameter DummyGPTModel instance \n",
    "# and feed it the tokenized batch\n",
    "#\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "logits = model(batch)\n",
    "print(\"Output shape: \\n\", logits.shape)\n",
    "#print(logits)\n",
    "#                      \n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Batch: \n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Input batch shape: \n",
      " torch.Size([2, 4])\n",
      "Output shape: \n",
      " torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "c06060ecd0f8f8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:02.769589Z",
     "start_time": "2025-02-10T00:27:02.764548Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Let’s now implement LAYER Normalization to improve the stability and efficiency of the training.\n",
    "# The main idea behind LAYER Normalization is to adjust the activations (outputs) of a deep\n",
    "# neural network layer to have a mean of 0 and a variance of 1\n",
    "#\n",
    "# This adjustment speeds up the convergence.\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "#\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Layer: \\n\",out)\n",
    "#\n",
    "# The NN Layer contains the non-linear activation ReLU which 0's out the negative values\n",
    "# \n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Variance: \", var)\n",
    "print(\"\\n\")\n",
    "#\n",
    "# Next, let’s apply layer normalization to the layer outputs we obtained earlier. \n",
    "# The operation consists of subtracting the mean and dividing by the square root \n",
    "# of the variance (also known as the standard deviation):\n",
    "#\n",
    "eps = 1e-5\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "# Dim = -1 indicates statistics along the last dimention\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Normalized Layer Outputs: \\n\", out_norm)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: \n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n",
      "\n",
      "\n",
      "Normalized Layer Outputs: \n",
      " tensor([[6.1585e-01, 1.4126e+00, -8.7188e-01, 5.8723e-01, -8.7188e-01, -8.7188e-01],\n",
      "        [-1.8865e-02, 1.1211e-01, -1.0876e+00, 1.5173e+00, 5.6474e-01, -1.0876e+00]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000e+00],\n",
      "        [1.0000e+00]], grad_fn=<VarBackward0>)\n",
      "-------------------------\n",
      "\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "a39e430a037896f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:02.848391Z",
     "start_time": "2025-02-10T00:27:02.844873Z"
    }
   },
   "source": [
    "from src.chapter04.LayerNorm import LayerNorm\n",
    "\n",
    "# Previously we used unbiased = False in our variance calculation. This doesn't \n",
    "# apply Bessel's correction where divisor is n-1 instead of n. But this is \n",
    "# compatible with GPT-2\n",
    "\n",
    "ln = LayerNorm(emb_dim = 5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "3130c2c83093ee01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.400313Z",
     "start_time": "2025-02-10T00:27:03.048976Z"
    }
   },
   "source": [
    "# Let us see how the GELU (Gaussian Error Linear Unit) stacks up against \n",
    "# # RELU (REctified Linear Unit)\n",
    "from src.chapter04.GELU import GELU\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "e496e641f9044a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.430703Z",
     "start_time": "2025-02-10T00:27:03.410339Z"
    }
   },
   "source": [
    "from src.chapter04.SimpleFeedForward import SimpleFeedForward\n",
    "\n",
    "# As we can see the smoothness of the GELU can lead to better optimization properties during training\n",
    "# as it allows more nuanced finer adjustments to models parameters. In contrast, RELU has a sharp corner\n",
    "# that can make adjustments difficult for very deep networks.\n",
    "#\n",
    "# Next we look at implementing a feed forward network with GELU activations\n",
    "# See SimpleFeedForward.py\n",
    "#\n",
    "sff = SimpleFeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = sff(x)\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "98a59bc5db854fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.473920Z",
     "start_time": "2025-02-10T00:27:03.466115Z"
    }
   },
   "source": [
    "from src.chapter04.ExampleDeepNeuralNetwork import ExampleDeepNeuralNetwork\n",
    "\n",
    "# Next we implement Shortcut Connections\n",
    "# Each layer will be initialized such that it accepts an example with three input \n",
    "# values and returns three output values.\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "# model.to(device)\n",
    "\n",
    "# Next lets print the gradients\n",
    "def print_gradients(nnmodel, input_x):\n",
    "    output = nnmodel(input_x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    loss.backward()\n",
    "    for name, param in nnmodel.named_parameters():\n",
    "        # print(name, \" = \", param)\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "#\n",
    "# Now Lets use this function to print the gradients calculated by loss.backward()\n",
    "print_gradients(model_without_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "4bfdfab7cb5bcc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.665459Z",
     "start_time": "2025-02-10T00:27:03.652216Z"
    }
   },
   "source": [
    "# As you can see above gradients become tiny aka Vanishing from Layer4 to Layer1\n",
    "# Let’s now instantiate a model with skip connections and see how it compares:\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "# model.to(device)\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "a229081ed60e29b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.799515Z",
     "start_time": "2025-02-10T00:27:03.797757Z"
    }
   },
   "source": [
    "# Note here the gradient doesn't approach a vanishingly small value during backprop.\n",
    "# In conclusion, shortcut connections are important for overcoming the limitations posed \n",
    "# by the vanishing gradient problem in deep neural networks."
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "2df6d339f0570629",
   "metadata": {},
   "source": [
    "#### Next, we’ll connect all the previously covered concepts (layer normalization, GELU activations, feed forward module, and shortcut connections) in a transformer  block, which is the final building block we need to code the GPT architecture.\n",
    "\n",
    "![image](../data/transformer_wiring.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd526dd3047ba477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:03.916504Z",
     "start_time": "2025-02-10T00:27:03.872016Z"
    }
   },
   "source": [
    "# See TransformerBlock.py for the basic sequence and feedforward details\n",
    "from src.chapter04.TransformerBlock import TransformerBlock\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "tr_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "out = tr_block(x)\n",
    "#\n",
    "print(\"Input Shape:  \", x.shape)\n",
    "print(\"Output Shape: \", out.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:   torch.Size([2, 4, 768])\n",
      "Output Shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "8c3e76bf70259f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:05.498105Z",
     "start_time": "2025-02-10T00:27:04.411466Z"
    }
   },
   "source": [
    "from src.chapter04.GPTModel import GPTModel\n",
    "# Let us wire up the actual GPT Model we wrote now\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "print(\"Input batch: \", batch)\n",
    "out = model(batch)\n",
    "print(\"Output shape: \", out.shape)\n",
    "# print(\"Out: \\n\", out)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Output shape:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "af55c75851ac7e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:05.560086Z",
     "start_time": "2025-02-10T00:27:05.557597Z"
    }
   },
   "source": [
    "# Note above the output tensor has the shape [2, 4, 50257], since we passed in two input texts (the two sentences) \n",
    "# with four tokens each. The last dimension, 50257, corresponds to the vocabulary size of the tokenizer.\n",
    "#\n",
    "# To capture the total number of Parameters for a model use numel parameter value\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "ba624b8ce1a7e0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "1a31524b0cdc6ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:05.795813Z",
     "start_time": "2025-02-10T00:27:05.793824Z"
    }
   },
   "source": [
    "# Weight Tying: The model reuses weights from the token embedding layer in its output layer\n",
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
    "# As we can see both shapes are same"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "197e0a5f1199aada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:05.854108Z",
     "start_time": "2025-02-10T00:27:05.851494Z"
    }
   },
   "source": [
    "# The token embedding and output layers are very large due to the 50,257 rows in the tokenizer’s vocabulary. \n",
    "# If we remove the output layer parameter count from the total GPT-2 model count :\n",
    "total_params_gptmodel = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of trainable parameters considering weight tying: \"\n",
    "      f\"{total_params_gptmodel:,}\")\n",
    "\n",
    "# Memory Requirement\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "82b6b3cc8d05feb4",
   "metadata": {},
   "source": [
    "# Generating text \n",
    "#### We will now write code to generate text from the predicted tensors by the GPTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da3f91bddda842d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:06.485544Z",
     "start_time": "2025-02-10T00:27:05.967722Z"
    }
   },
   "source": [
    "# Generates one token at a time to {max_new_tokens}\n",
    "# while taking last {context_size} elements as input.\n",
    "# Then it feeds those to the supplied language model to get the predicted logits.\n",
    "# Then it converts them to probability using softmax().\n",
    "# Then it does greedy decoding i.e. gets the token with highest probability\n",
    "# using argmax(). Then it concatenates the next token to tokenids list\n",
    "# and returns the generated sequence.\n",
    "def generate_text_simple(input_model, tokenids, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        token_cond = tokenids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = input_model(token_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probabs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probabs, dim=-1, keepdim=True)\n",
    "        tokenids = torch.cat((tokenids, next_token), dim=1)\n",
    "    return tokenids\n",
    "\n",
    "#    \n",
    "#  Try it with a sample sentence  \n",
    "#    \n",
    "start_context = \"Hello, I am \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "#\n",
    "encoded_tensor = torch.tensor(encoded).to(device).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape: \", encoded_tensor.shape)\n",
    "#\n",
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716, 220]\n",
      "encoded_tensor.shape:  torch.Size([1, 5])\n",
      "Output: tensor([[15496,    11,   314,   716,   220, 24464, 41953, 29279,  2648, 48441,\n",
      "         33499]], device='mps:0')\n",
      "Output length: 11\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "ab7699859ab25da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:06.526509Z",
     "start_time": "2025-02-10T00:27:06.524252Z"
    }
   },
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am opia synagogue1983 shareuin citations\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "7397b4b87caf10c6",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on unlabeled data\n",
    "#### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39970739c5f593",
   "metadata": {},
   "source": [
    "#### NOTE: Our goal during training is to get the average log probability as close to 0 as possible by updating the model’s weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:06.878126Z",
     "start_time": "2025-02-10T00:27:06.706989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How to calculate loss and relatively randomize next word prediction\n",
    "#\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]]).to(device)   #  \"I really like\"\n",
    "#\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]).to(device)  #  \" really like chocolate\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(f\"probas: {probas.shape}\")\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Utility function text to token\n",
    "def text_to_token_ids(txt, tokenizr):\n",
    "    encoded_txt = tokenizr.encode(txt, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tnsr = torch.tensor(encoded_txt).to(device).unsqueeze(0)\n",
    "    return encoded_tnsr\n",
    "\n",
    "# Utility function token to text\n",
    "def token_ids_to_text(tokenids, tokenizr):\n",
    "    flat = tokenids.squeeze(0)\n",
    "    return tokenizr.decode(flat.tolist())\n",
    "\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 2: \", target_probas_2)\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token,\n",
    "# which involves increasing its probability relative to other tokens.\n",
    "\n",
    "# Loss of probabilities for the two batches are\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log probabilities for both batches are: \\n\", log_probas)\n",
    "\n",
    "# Next, we combine the log probabilities into a single score by computing\n",
    "# the average\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(f\"Average log probability: {avg_log_probas}\")\n",
    "\n",
    "# However, in deep learning, the common practice isn’t to push the average log probability\n",
    "# up to 0 but rather to bring the negative average log probability down to 0. The negative\n",
    "# average log probability is simply the average log probability multiplied by –1\n",
    "neg_avg_log_probabs = avg_log_probas * -1\n",
    "print(f\"Negative of average log probability: {neg_avg_log_probabs}\")\n",
    "\n",
    "# In deep learning, the term for turning this negative value, –10.7940, into 10.7940,\n",
    "# is known as the cross entropy loss.\n"
   ],
   "id": "21d8324b6eace0d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probas: torch.Size([2, 3, 50257])\n",
      "Token IDs: tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]], device='mps:0')\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n",
      "Softmax scores for Text 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05], device='mps:0')\n",
      "Softmax scores for Text 2:  tensor([4.2794e-05, 1.6248e-05, 1.1586e-05], device='mps:0')\n",
      "Log probabilities for both batches are: \n",
      " tensor([-1.0660e+01, -1.0794e+01, -1.1353e+01, -1.0059e+01, -1.1028e+01, -1.1366e+01],\n",
      "       device='mps:0')\n",
      "Average log probability: -10.876513481140137\n",
      "Negative of average log probability: 10.876513481140137\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "62d971c360d51b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:08.281284Z",
     "start_time": "2025-02-10T00:27:06.978870Z"
    }
   },
   "source": [
    "GPT_CONFIG_124M_2 = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "d0465f554d8c18b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:08.377605Z",
     "start_time": "2025-02-10T00:27:08.359463Z"
    }
   },
   "source": [
    "print(\"Logits shape:\", logits.shape) # batch size, num of tokens, vocab size\n",
    "print(\"Targets shape:\", targets.shape) # batch size, num of tokens\n",
    "\n",
    "# For the cross_entropy loss function in PyTorch, we want to flatten these \n",
    "# tensors by combining them over the batch dimension:\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "# Now we can call CE from torch to calculate the loss\n",
    "celoss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(f\"Cross Entropy loss: {celoss}\")\n",
    "\n",
    "# Perplexity measures how well the probability distribution predicted by the model \n",
    "# matches the actual distribution of the words in the dataset. Similar to the loss, \n",
    "# a lower perplexity means the model predictions are closer to the actual distribution.\n",
    "perplexity = torch.exp(celoss)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross Entropy loss: 10.876513481140137\n",
      "Perplexity: 52918.7734375\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "9d0758479b082989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:27:09.144617Z",
     "start_time": "2025-02-10T00:27:08.668839Z"
    }
   },
   "source": [
    "from src.chapter02.Dataloader import Dataloader\n",
    "# To implement the data splitting and loading, we first define a train_ratio\n",
    "# to use 90% of the data for training and the remaining 10% as validation data \n",
    "# for model evaluation during training\n",
    "torch.manual_seed(123)\n",
    "# \n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n",
    "# \n",
    "train_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(train_data)\n",
    "# \n",
    "val_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(val_data)\n",
    "# \n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "# \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "#     \n",
    "# Calculate per batch loss \n",
    "# Use CrossEntropy\n",
    "#\n",
    "# def calculate_batch_loss(input_batch, target_batch, gpt_model_batch, device):\n",
    "#     batch_logits = gpt_model_batch(input_batch.to(device))\n",
    "#     batch_logits = batch_logits[:, -1, :]  # Get the last token\n",
    "#     target_batch = target_batch.squeeze().to(device)\n",
    "#     print(f\"Logits Shape: {batch_logits.shape} Target shape: {target_batch.shape}\")# Ensure correct shape\n",
    "#     print(f\"Target dtype: {target_batch.dtype}\")\n",
    "#     loss = torch.nn.functional.cross_entropy(batch_logits, target_batch)\n",
    "#     return loss\n",
    "\n",
    "def calculate_batch_loss(input_batch, target_batch, gpt_model_batch, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    batch_logits = gpt_model_batch(input_batch)  # Forward pass\n",
    "    batch_logits = batch_logits[:, -1, :] # Get last token logits\n",
    "\n",
    "    # Select last token only, otherwise the cross_entropy complains\n",
    "    target_batch = target_batch[:, -1]\n",
    "    target_batch = target_batch.squeeze().long()  # Ensure correct shape and type\n",
    "\n",
    "    # print(f\"Logits Shape: {batch_logits.shape}\")  # Should be [8, 50257]\n",
    "    # print(f\"Target Shape: {target_batch.shape}\")  # Should be [8]\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(batch_logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "# \n",
    "# Calculate loss across batches\n",
    "# \n",
    "def calculate_loss_loader(data_loader, gmodel, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for n, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if n < num_batches:\n",
    "            loss = calculate_batch_loss(input_batch, target_batch, gmodel, device)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_loss / num_batches\n",
    "#\n",
    "#\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "#\n",
    "print(\"Default Training loss:\", train_loss)\n",
    "print(\"Default Validation loss:\", val_loss)\n",
    "# \n",
    "# Model Evaluation\n",
    "# Calculate both training and validation losses and return\n",
    "#\n",
    "def evaluate_model(eval_model, training_loader, validn_loader, eval_device, eval_iter):\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "        training_loss = calculate_loss_loader(\n",
    "            training_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "        validn_loss = calculate_loss_loader(\n",
    "            validn_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "    eval_model.train()\n",
    "    return training_loss, validn_loss\n",
    "#\n",
    "# A convenience function that we use to track whether the model improves during the training. \n",
    "# The generate_and_print_sample() function takes a text snippet (start_context) as input, \n",
    "# converts it into token IDs, and feeds it to the LLM to generate a text sample response\n",
    "# using the generate_text_simple function\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            input_model=model, \n",
    "            tokenids=encoded,\n",
    "            max_new_tokens=50, \n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "#\n",
    "# Now we implement the model training flow \n",
    "#\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, total_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    # \n",
    "    for epoch in range(num_epochs):\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # print(\"Input: \", input_batch.shape, \"Target: \", target_batch.shape)\n",
    "            optimizer.zero_grad()\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.squeeze().to(device)\n",
    "            #\n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Loss Update\n",
    "            optimizer.step() # Back propagation\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            #\n",
    "            if global_step % eval_freq == 0:\n",
    "                trn_loss, validn_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                #\n",
    "                train_losses.append(trn_loss)\n",
    "                val_losses.append(validn_loss)\n",
    "                total_tokens_seen.append(tokens_seen)\n",
    "                #\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {trn_loss:.5f}, \"\n",
    "                      f\"Val loss {validn_loss:.5f}\"\n",
    "                )\n",
    "        # End inner for\n",
    "        # After each epoch try a sample\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    # End outer for\n",
    "    return train_losses, val_losses, total_tokens_seen\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Default Training loss: 10.952750205993652\n",
      "Default Validation loss: 10.471922874450684\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "9f203bec3d737b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:23.366592Z",
     "start_time": "2025-02-10T00:27:09.149533Z"
    }
   },
   "source": [
    "#\n",
    "# Training Loop\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "#\n",
    "#\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "model_file_path= \"../models/GPTModel.pth\"\n",
    "num_epochs = 8\n",
    "train_losses, val_losses, tokens_seen = [], [], []\n",
    "epochs_tensor = None\n",
    "#\n",
    "# Create model\n",
    "#\n",
    "model = GPTModel(GPT_CONFIG_124M_2)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "#\n",
    "if not os.path.exists(model_file_path):\n",
    "    train_losses, val_losses, tokens_seen = (\n",
    "        train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                           num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "                           start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    "                           )\n",
    "    )\n",
    "    if epochs_tensor is None:\n",
    "        epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "        plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "else:\n",
    "    print(f\"Model already exists\")\n",
    "    pass"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.56923, Val loss 10.84235\n",
      "Ep 1 (Step 000005): Train loss 10.38818, Val loss 10.82460\n",
      "Every effort moves youplainplainplainplainplainplainplain-- overlap-- overlapTaiTai Ud overlap-- Legislation-- Legislation--TaiTai Ud overlap-- Legislation---- overlap--plainplainplain-- overlap--plain-- overlap---- Legislation---- Legislationplainplain overlap-- overlap\n",
      "Ep 2 (Step 000010): Train loss 8.69421, Val loss 10.93537\n",
      "Ep 2 (Step 000015): Train loss 8.09425, Val loss 11.08759\n",
      "Every effort moves you----------------------------------------------------------------------------------------------------\n",
      "Ep 3 (Step 000020): Train loss 7.83943, Val loss 11.19645\n",
      "Ep 3 (Step 000025): Train loss 6.67996, Val loss 11.05730\n",
      "Every effort moves you----------------------------------------------------------------------------------------------------\n",
      "Ep 4 (Step 000030): Train loss 5.52387, Val loss 10.80744\n",
      "Ep 4 (Step 000035): Train loss 4.30522, Val loss 11.00448\n",
      "Every effort moves you my-- my my my my my-- my-- my my my my my-- my-- my my-- my my my-- my---- my-- my my---- my-- my-- my-- my my my-- my my my-- my--\n",
      "Ep 5 (Step 000040): Train loss 3.83965, Val loss 11.39453\n",
      "Every effort moves you my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my\n",
      "Ep 6 (Step 000045): Train loss 3.46974, Val loss 11.84843\n",
      "Ep 6 (Step 000050): Train loss 3.26223, Val loss 12.17615\n",
      "Every effort moves you my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my my\n",
      "Ep 7 (Step 000055): Train loss 3.21426, Val loss 12.10483\n",
      "Ep 7 (Step 000060): Train loss 3.44946, Val loss 11.56630\n",
      "Every effort moves you,,,,,,,,,,,, my,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 8 (Step 000065): Train loss 3.64141, Val loss 11.43090\n",
      "Ep 8 (Step 000070): Train loss 3.18406, Val loss 12.46639\n",
      "Every effort moves you current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current current\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "acfc02f2040cd8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:26.219858Z",
     "start_time": "2025-02-10T00:28:23.560408Z"
    }
   },
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Now lets look at Temperature Scaling\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "# Assume the model generates the following logits \n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "\n",
    "# We now generally do an argmax of the probabilities \n",
    "probas = torch.softmax(next_token_logits, dim=0).to(device)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(f\"Next token (argmax): {inverse_vocab[next_token_id]}\")\n",
    "#\n",
    "# But we can try replacing argmax with multinomial and get a sampling\n",
    "#\n",
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(f\"Next token (multinomial): {inverse_vocab[next_token_id]}\")\n",
    "# \n",
    "# Let's see if multinomial can produce any other probabilites\n",
    "def print_sampled_tokens(probabs):\n",
    "    torch.manual_seed(123)\n",
    "    # Multinomial Sampling of probabilities instead of max\n",
    "    samples = [torch.multinomial(probabs, num_samples=1).item() for _ in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(samples).to(device))\n",
    "    for cnt, freq in enumerate(sampled_ids):\n",
    "        print(f\"Sampled Freq. {freq} : {inverse_vocab[cnt]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you current current current current current current current current current current current current current current current current current current current current current current current current current\n",
      "Next token (argmax): forward\n",
      "Next token (multinomial): forward\n",
      "Sampled Freq. 72 : closer\n",
      "Sampled Freq. 2 : every\n",
      "Sampled Freq. 0 : effort\n",
      "Sampled Freq. 575 : forward\n",
      "Sampled Freq. 2 : inches\n",
      "Sampled Freq. 0 : moves\n",
      "Sampled Freq. 0 : pizza\n",
      "Sampled Freq. 343 : toward\n",
      "Sampled Freq. 6 : you\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "2edb9cac7f426800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:26.288132Z",
     "start_time": "2025-02-10T00:28:26.223222Z"
    }
   },
   "source": [
    "# We can further control the distribution by a technique called temperature scaling\n",
    "# meaning dividing the logits with a >0 number\n",
    "def softmax_with_temperature(logits, temperature, dim):\n",
    "    scaled_logits = logits / temperature\n",
    "    scaled_probs =  torch.softmax(scaled_logits, dim=dim)\n",
    "    return scaled_probs\n",
    "\n",
    "# Let's check that out\n",
    "temperatures = [1, .01, 5]\n",
    "next_token_logits: Tensor = Tensor.cpu(next_token_logits)\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, float(T), 0) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.5\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, \n",
    "                   scaled_probas[i], \n",
    "                   bar_width, \n",
    "                   label=f'Temperature = {T}'\n",
    "    )\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Words')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "48c5d9214db5c7e3",
   "metadata": {},
   "source": [
    "## Top K sampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "af408748892d4b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:27.035683Z",
     "start_time": "2025-02-10T00:28:26.425011Z"
    }
   },
   "source": [
    "# Previously we implemented a probabilistic sampling approach coupled with \n",
    "# temperature scaling to increase the diversity of the outputs.  This method \n",
    "# allows for the exploring of less likely but potentially more interesting and \n",
    "# creative paths in the generation process.\n",
    "#\n",
    "# Top-k sampling, when combined with probabilistic sampling and temperature \n",
    "# scaling, can improve the text generation results.\n",
    "#\n",
    "# Here we can restrict the sampled tokens to the top-k most likely tokens \n",
    "# and exclude all other tokens from the selection process by masking their \n",
    "# probability scores\n",
    "# \n",
    "top_k = 3\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# \n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"\\nTop Logits: \", top_logits)\n",
    "print(\"Top Positions: \", top_pos)\n",
    "print(f\"Next token logits: {next_token_logits}\\n\")\n",
    "\n",
    "# Pytorch WHERE function to set the logit values of tokens that are below the lowest \n",
    "# logit value within our top-three selection to negative infinity (-inf)\n",
    "#\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New Logits: \", new_logits)\n",
    "\n",
    "# Now apply the softmax\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(f\"top k probabilities: {topk_probas}\")\n",
    "\n",
    "\n",
    "# \n",
    "# We can now apply the temperature scaling and multinomial function for probabilistic \n",
    "# sampling to select the next token among these three non-zero probability scores to \n",
    "# GENERATE THE NEXT TOKEN with more diversity.\n",
    "# \n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k: int=None, eos_id=None):\n",
    "    # print(\"Entering generate()..\")\n",
    "    # print(idx.shape)\n",
    "    for i in range(max_new_tokens):\n",
    "        # print(f\"idx: [{i}]: {idx}\")\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        #     \n",
    "        logits = logits[:, -1, :] # ([1, 50257])\n",
    "        # print(logits.shape)\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val: Tensor = top_logits[:, -1] # Less than the lowest value of top k\n",
    "            # Now mark the minvals with -inf, so softmax becomes 0\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            probs = softmax_with_temperature(logits, temperature, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else: \n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # Next word\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions:  tensor([3, 7, 0])\n",
      "Next token logits: tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "\n",
      "New Logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "top k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
      "Output text:\n",
      " Every effort moves you my little to my to to, current she forehead my\n",
      " ofeven she\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "7e164cfeef1f9707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:30.379803Z",
     "start_time": "2025-02-10T00:28:27.123664Z"
    }
   },
   "source": [
    "# torch.save(model.state_dict(), f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\")\n",
    "MODEL_PATH = f\"../models/{GPT_CONFIG_124M_2['model_name']}.pth\"\n",
    "#\n",
    "if not os.path.exists(model_file_path):\n",
    "    try:\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            },\n",
    "            MODEL_PATH\n",
    "        )\n",
    "        print(f\"Model saved at {MODEL_PATH}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Encountered exception : {e}\")\n",
    "else:\n",
    "    print(f\"Model exists at {MODEL_PATH}, not overwritten\")\n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ../models/GPTModel.pth\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "d0a3f72c8cebc09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:28:32.029675Z",
     "start_time": "2025-02-10T00:28:30.480394Z"
    }
   },
   "source": [
    "# Load the model back\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
    "    loaded_model = GPTModel(GPT_CONFIG_124M_2).to(device)\n",
    "    try:\n",
    "        loaded_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer = torch.optim.AdamW(loaded_model.parameters(),\n",
    "                                     lr=GPT_CONFIG_124M_2[\"lr\"],\n",
    "                                     weight_decay=GPT_CONFIG_124M_2[\"weight_decay\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        print(f\"Model and Optimizer successfully loaded from \\n{MODEL_PATH}\\n\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Encountered exception : {ex}\")\n",
    "\n",
    "    loaded_model.train()\n",
    "    print(\"Model set to train mode\")\n",
    "else:\n",
    "    print(f\"Model not found at {MODEL_PATH}. Nothing to load\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Optimizer successfully loaded from \n",
      "../models/GPTModel.pth\n",
      "\n",
      "Model set to train mode\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "d38b09e853311dec",
   "metadata": {},
   "source": [
    "### OpenAI also shares the weights of larger models: 355M, 774M, and 1558M\n",
    "![Model Architecture Stack](../data/model_arch_stack.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "68e160927f07d23a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:02.261728Z",
     "start_time": "2025-02-10T00:28:56.441162Z"
    }
   },
   "source": [
    "# Load the downloaded GPT Data\n",
    "import os, sys\n",
    "import urllib.request\n",
    "from src.chapter05.gpt_download import download_and_load_gpt2\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "# print(filename)\n",
    "filename = \"./chapter05/\"+filename\n",
    "# print(filename)\n",
    "if not os.path.exists(filename):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit()\n",
    "#\n",
    "settings, gpt_params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"../data/gpt2\")\n",
    "print(f\"\\nParams: {gpt_params.keys()}\")\n",
    "print(f\"Settings: {settings}\")\n",
    "print(f\"Token embedding layer weight tensor dimensions: {gpt_params[\"wte\"].shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model directory: ../data/gpt2/124M\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/vocab.bpe\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Token embedding layer weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "ba48ffe795182755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:03.205400Z",
     "start_time": "2025-02-10T00:29:02.265871Z"
    }
   },
   "source": [
    "\n",
    "# After loading the GPT-2 model weights into Python, we still need to transfer \n",
    "# them from the settings and params dictionaries into our GPTModel instance. \n",
    "# First, we create a dictionary that lists the differences between the \n",
    "# different GPT model sizes\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "model_name=\"gpt2-small (124M)\"\n",
    "#\n",
    "NEW_GPT_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_GPT_CONFIG.update({\"model_name\": model_name})\n",
    "# Update the value ex. {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "NEW_GPT_CONFIG.update(model_configs[model_name])\n",
    "NEW_GPT_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_GPT_CONFIG.update({\"qkv_bias\": True})\n",
    "#\n",
    "print(f\"{model_name}: {model_configs[model_name]}\")\n",
    "print(\"NEW_GPT_CONFIG:\\n\"+\"\".join(f\"\\t{k}: {v}\\n\" for k, v in sorted(NEW_GPT_CONFIG.items())))\n",
    "#\n",
    "newgpt = GPTModel(NEW_GPT_CONFIG).to(device)\n",
    "newgpt.eval()\n",
    "# \n",
    "# Before we assign the loaded openai weights into the model, we will first define \n",
    "# a small assign utility function that checks whether two tensors or arrays \n",
    "# (left and right) have the same dimensions or shape and returns the right tensor \n",
    "# as trainable PyTorch parameters\n",
    "#\n",
    "def assign(left: Tensor, right: Tensor) -> Tensor:\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch Left shape: {left.shape} Right shape: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right).to(device))\n",
    "# \n",
    "print(f\"Params: {gpt_params.keys()}\")\n",
    "# print(f\"Params: {gpt_params}\")\n",
    "print(f\"GPT Parameter Blocks Count: {len(gpt_params[\"blocks\"])}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-small (124M): {'emb_dim': 768, 'n_layers': 12, 'n_heads': 12}\n",
      "NEW_GPT_CONFIG:\n",
      "\tcontext_length: 1024\n",
      "\tdrop_rate: 0.1\n",
      "\temb_dim: 768\n",
      "\tlr: 0.0005\n",
      "\tmodel_name: gpt2-small (124M)\n",
      "\tn_heads: 12\n",
      "\tn_layers: 12\n",
      "\tqkv_bias: True\n",
      "\tvocab_size: 50257\n",
      "\tweight_decay: 0.1\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "GPT Parameter Blocks Count: 12\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "dbc4d3fb2c383826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:15.765154Z",
     "start_time": "2025-02-10T00:29:15.760203Z"
    }
   },
   "source": [
    "#\n",
    "# Load OpenAI GPT2 Weights into our GPTModel code\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].sff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].sff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "c0eeef9e5cadf037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:40.745786Z",
     "start_time": "2025-02-10T00:29:40.619395Z"
    }
   },
   "source": [
    "# Now lets try to load the weights and see\n",
    "newgpt_loaded = False\n",
    "if not newgpt_loaded:\n",
    "    load_weights_into_gpt(newgpt, gpt_params)\n",
    "    newgpt.to(device)\n",
    "    print(\"Loaded weights into newgpt GPTModel..\")\n",
    "    newgpt_loaded = True\n",
    "else:\n",
    "    print(\"GPTModel is already loaded..\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights into newgpt GPTModel..\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "53993f0b2ef4021a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:41.650134Z",
     "start_time": "2025-02-10T00:29:40.895236Z"
    }
   },
   "source": [
    "# Now let's generate using the actual GPT trained weights\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=newgpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_GPT_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more efficient and efficient processes, like in the car's oil and gas operation,\" the study said. To see if that\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "850187dca8e7693f",
   "metadata": {},
   "source": [
    "# Fine-tuning for Classification"
   ]
  },
  {
   "cell_type": "code",
   "id": "533a90b85f4e1468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:29:54.256471Z",
     "start_time": "2025-02-10T00:29:53.970329Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from chapter06 import DownloadDataset\n",
    "# \n",
    "# Download ehtSPAM Dataset\n",
    "# \n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"../data/sms_spam_collection.zip\"\n",
    "extracted_path = \"../data/sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "# \n",
    "DownloadDataset.download_and_unzip_spam_data(url, \n",
    "                                             zip_path, \n",
    "                                             extracted_path, \n",
    "                                             data_file_path)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and unzipping spam dataset...\n",
      "Didnt find existing spam dataset, ...\n",
      "URL:  https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\n",
      "ZIP path:  ../data/sms_spam_collection.zip\n",
      "../data/sms_spam_collection.zip doesnt exist. Downloading...\n",
      "File downloaded at: ../data/sms_spam_collection.zip\n",
      "../data/sms_spam_collection doesn't exist. Extracting...\n",
      "Extracted SPAM dataset successfully...\n",
      "Renaming ../data/sms_spam_collection/SMSSpamCollection to ../data/sms_spam_collection/SMSSpamCollection.tsv\n",
      "File downloaded and saved as ../data/sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "bcc8d30ddb5d1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:30:06.479507Z",
     "start_time": "2025-02-10T00:30:06.470456Z"
    }
   },
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# At this point the spam dataset should have been downloaded at {data_file_path}\n",
    "df: DataFrame = None\n",
    "\n",
    "if data_file_path.exists() and data_file_path.is_file():\n",
    "    df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "   \n",
    "# df.head(10)\n",
    "#Let's take a look at class distributions\n",
    "print(f\"Class counts: {df[\"Label\"].value_counts()}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "eb7fba4d33fca94f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:30:19.094452Z",
     "start_time": "2025-02-10T00:30:19.080596Z"
    }
   },
   "source": [
    "# Considering there are so many more hams than spams we need to create\n",
    "# a somewhat balanced dataset\n",
    "\n",
    "import os\n",
    "\n",
    "def create_balanced_dataset(df: DataFrame) -> DataFrame:\n",
    "    # print(df.shape)\n",
    "    bal_df = df\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    num_ham = df[df[\"Label\"] == \"ham\"].shape[0]\n",
    "    print(f\"Spam and Ham counts: {num_spam}, {num_ham} \\n\")\n",
    "\n",
    "    # If num_spam is a lot less than num_ham\n",
    "    if num_spam < num_ham or num_spam == 0:\n",
    "        ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    if ham_subset is not None:\n",
    "        bal_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return bal_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "# print(f\"Rebalanced dataset \\n {balanced_df[\"Label\"].value_counts()}\")\n",
    "\n",
    "# Now we are going to change the string class labels to ints\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "\n",
    "\n",
    "# This process is similar to converting text into token IDs. However, instead \n",
    "# of using the GPT vocabulary, which consists of more than 50,000 words, we \n",
    "# are dealing with just two token IDs: 0 and 1.\n",
    "# \n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac) # * 0.7\n",
    "    validation_end = train_end + int(len(df) * validation_frac)  # * 0.1\n",
    "    \n",
    "    train_df = df[:train_end] # 70%\n",
    "    valid_df = df[train_end:validation_end] # 10%\n",
    "    test_df = df[validation_end:]   # 20%\n",
    "    \n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "#\n",
    "# Next, we create a random_split function to split the dataset into three parts: \n",
    "# 70% for training, 10% for validation, and 20% for testing\n",
    "#\n",
    "training_df, validation_df, testing_df = random_split(balanced_df, 0.7, 0.1)\n",
    "print(f\"Training dataset \\n {training_df['Label'].value_counts()}\")\n",
    "print(f\"Validation dataset \\n {validation_df['Label'].value_counts()}\")\n",
    "print(f\"Testing dataset \\n {testing_df['Label'].value_counts()}\")\n",
    "# \n",
    "# Save the split files\n",
    "#\n",
    "if not os.path.exists(\"../data/train.csv\"):\n",
    "    training_df.to_csv(\"../data/train.csv\", index=None)\n",
    "    \n",
    "if not os.path.exists(\"../data/validate.csv\"):\n",
    "    validation_df.to_csv(\"../data/validate.csv\", index=None)\n",
    "    \n",
    "if not os.path.exists(\"../data/test.csv\"):    \n",
    "    testing_df.to_csv(\"../data/test.csv\", index=None)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam and Ham counts: 747, 4825 \n",
      "\n",
      "Training dataset \n",
      " Label\n",
      "0    528\n",
      "1    517\n",
      "Name: count, dtype: int64\n",
      "Validation dataset \n",
      " Label\n",
      "1    79\n",
      "0    70\n",
      "Name: count, dtype: int64\n",
      "Testing dataset \n",
      " Label\n",
      "1    151\n",
      "0    149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "75ffdb033fba532f",
   "metadata": {},
   "source": [
    "### 6.3 Setting up PyTorch Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "a13c23eaebccca8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:30:31.628467Z",
     "start_time": "2025-02-10T00:30:31.626294Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "dfb2d42b723f5113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:30:55.304832Z",
     "start_time": "2025-02-10T00:30:55.279383Z"
    }
   },
   "source": [
    "from src.chapter06.SpamDataset import SpamDataset\n",
    "\n",
    "# Since each row of training data has varying length, we are going to padd all \n",
    "# rows to the size of the max length of the longest row using \"<|endoftext|>\" or rather \n",
    "# its token equivalent i.e. 50256\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"../data/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(f\"Max length of training set : {train_dataset.max_length}\\n\")\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"../data/validate.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(f\"Max length of validate set : {val_dataset.max_length}\\n\")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"../data/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(f\"Max length of test set : {test_dataset.max_length}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ../data/train.csv: (1045, 2)\n",
      "Max length of training set : 120\n",
      "\n",
      "Shape of ../data/validate.csv: (149, 2)\n",
      "Max length of validate set : 120\n",
      "\n",
      "Shape of ../data/test.csv: (300, 2)\n",
      "Max length of test set : 120\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "id": "828481d7cb91412c",
   "metadata": {},
   "source": [
    "### NOTE: The difference with text prediction here is that for each sample we have a class label\n",
    "### associated with it using the datasets as inputs, we can now instantiate the data loaders\n",
    "### similarly to when we were working with text data. However, in this case,  the targets\n",
    "### represent class labels rather than the next tokens in the text. For instance, if we\n",
    "### choose a batch size of 8, each batch will consist of eight training examples of length\n",
    "### '120' and the corresponding class label of each example"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a0f692e09c92e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:30:55.554910Z",
     "start_time": "2025-02-10T00:30:55.523297Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"[training] Input batch dimensions:\", input_batch.shape)\n",
    "print(\"[training] Label batch dimensions\", target_batch.shape)\n",
    "\n",
    "# Number of batches in each dataset\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training] Input batch dimensions: torch.Size([8, 120])\n",
      "[training] Label batch dimensions torch.Size([8])\n",
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "177359b3787f5cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:31:11.802219Z",
     "start_time": "2025-02-10T00:31:08.082648Z"
    }
   },
   "source": [
    "from chapter05.gpt_download import download_and_load_gpt2\n",
    "from chapter04.GPTModel import GPTModel\n",
    "\n",
    "#\n",
    "# Now we start initializing our model and load the pretrained weights\n",
    "#\n",
    "#\n",
    "#\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"drop_rate\" : 0.0,\n",
    "    \"qkv_bias\" : True,\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "model_name=\"gpt2-small (124M)\"\n",
    "#\n",
    "BASE_CONFIG.update({\"model_name\": model_name})\n",
    "BASE_CONFIG.update(model_configs[model_name])\n",
    "# print(\"BASE_CONFIG:\\n\"+\"\".join(f\"\\t{k}: {v}\\n\" for k, v in sorted(BASE_CONFIG.items())))\n",
    "#\n",
    "model_size = model_name.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "small_gpt_loaded = False\n",
    "small_gpt_model = None\n",
    "\n",
    "if not small_gpt_loaded:\n",
    "    small_gpt_model = GPTModel(BASE_CONFIG).to(device)\n",
    "    settings, params = download_and_load_gpt2(\n",
    "        model_size=model_size,\n",
    "        models_dir=\"../data/gpt2\"\n",
    "    )\n",
    "    load_weights_into_gpt(small_gpt_model, params)\n",
    "    # small_gpt_model.eval()\n",
    "    print(\"Loaded weights on to small_gpt_model\")\n",
    "else:\n",
    "    print(\"small_gpt_model is already loaded\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model directory: ../data/gpt2/124M\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/vocab.bpe\n",
      "Loaded weights on to small_gpt_model\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "id": "b49206bdd6a269b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:31:24.401083Z",
     "start_time": "2025-02-10T00:31:23.973694Z"
    }
   },
   "source": [
    "# To test after loading the model weights into the GPTModel, we reuse the text generation utility\n",
    "# to generate coherent text\n",
    "#\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=small_gpt_model,\n",
    "    tokenids=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "7e2d6f94b699b652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:31:37.042113Z",
     "start_time": "2025-02-10T00:31:36.503711Z"
    }
   },
   "source": [
    "# Before we train the classifier lets try the model as is\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "#\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=small_gpt_model,\n",
    "    tokenids=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "#\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Clearly the model is unable to answer"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "72d040c09f0a6a96",
   "metadata": {},
   "source": [
    "# Classification finetuning - Adding a Classification Head\n",
    "![Classification Fine Tuning Image](../data/classification_tuning.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "defa84126df77d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:32:01.487304Z",
     "start_time": "2025-02-10T00:32:01.349983Z"
    }
   },
   "source": [
    "#\n",
    "# Essentially we will replace the last Sequential layer or Head which mapped \n",
    "# from 768 dimentions to 50257 vocabulary dimensions with a layer that maps \n",
    "# the 768 dimensions to just 2 i.e. 1 and 0\n",
    "#\n",
    "# print(small_gpt_model)\n",
    "# First freeze the model\n",
    "for param in small_gpt_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Now replace the output layer i.e. out_head with new one\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2 # Spam or Ham\n",
    "\n",
    "# Remember each layer must be on GPU\n",
    "small_gpt_model.out_head = torch.nn.Linear(\n",
    "    in_features = BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features = num_classes\n",
    ").to(device)\n",
    "#\n",
    "# NOTE: This new layer will have the requires_grad set to True by default\n",
    "# that means if we train this model only this layer will be trained.\n",
    "#\n",
    "# While this is sufficient, as per Sebastian the accuracy improves if we\n",
    "# also train the last transformer block and the last LayerNorm module.\n",
    "#\n",
    "# So Set the requires_grad for the last transformer block\n",
    "for param in small_gpt_model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Set the requires_grad for the last LayerNorm\n",
    "for param in small_gpt_model.final_norm.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# To test it we can feed it an example text\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0).to(device)\n",
    "#\n",
    "print(\"Inputs: \", inputs)\n",
    "print(\"Inputs dimensions: \", inputs.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "     outputs = small_gpt_model(inputs)\n",
    "#\n",
    "print(\"Outputs dimensions: \", outputs.shape)\n",
    "assert(outputs.shape[-1] == num_classes) # Number of output classes\n",
    "print(\"Outputs: \\n\", outputs)\n",
    "# Number of Output rows now correspond to input token count which is 4 in this case\n",
    "# but the embeddings dimension is only 2 instead of 50257 because of the new \n",
    "# output head\n",
    "\n",
    "# We don’t need to fine-tune all four output rows; instead, we can focus on a \n",
    "# single output token. In particular, we will focus on the last row corresponding \n",
    "# to the last output token BECAUSE LAST TOKEN IS THE ONLY ONE WITH ALL THE ATTENTION OF \n",
    "# ALL OF ITS PREVIOUS TOKENS\n",
    "print(\"Last output token:\", outputs[:, -1, :])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  tensor([[5211,  345,  423,  640]], device='mps:0')\n",
      "Inputs dimensions:  torch.Size([1, 4])\n",
      "Outputs dimensions:  torch.Size([1, 4, 2])\n",
      "Outputs: \n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]], device='mps:0')\n",
      "Last output token: tensor([[-3.5983,  3.9902]], device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "f2aafc8bf0654f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:32:03.405928Z",
     "start_time": "2025-02-10T00:32:01.633938Z"
    }
   },
   "source": [
    "# Before we finetune the model we need to implement the model evaluation functions\n",
    "# Similar to our previous approach we take the next token id generated, calculate \n",
    "# probabilities and use argmax to get the highest probability. Only here its in 2\n",
    "# instead of 50257 dimensions\n",
    "# print(f\"Last output token: {outputs[:, -1, :]}\")\n",
    "\n",
    "# Now we can get the class label\n",
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(f\"Class Label: {label.item()} \\n\")\n",
    "\n",
    "# This concept can be used to design an accuracy loader\n",
    "def calc_accuracy_loader(data_loader, small_gpt_model, device, num_batches=None):\n",
    "    small_gpt_model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = small_gpt_model(input_batch)[:, -1, :]\n",
    "\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += ((predicted_labels == target_batch).sum().item())\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "#\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "small_gpt_model.to(device)\n",
    "#\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, small_gpt_model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, small_gpt_model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, small_gpt_model, device, num_batches=10\n",
    ")\n",
    "#\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Label: 1 \n",
      "\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "89c11a1d6d0f813c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:32:16.613367Z",
     "start_time": "2025-02-10T00:32:15.713361Z"
    }
   },
   "source": [
    "# As we can see the prediction accuracy is almost random i.e. 50%\n",
    "# \n",
    "# Before we fine tune the model we need to describe the loss function\n",
    "# Our objective is to maximize the spam classification accuracy of the \n",
    "# model, which means that the preceding code should output the correct \n",
    "# class labels: 0 for non-spam and 1 for spam.\n",
    "# \n",
    "# Because classification accuracy is not a differentiable function, we \n",
    "# can use cross-entropy loss as a proxy to maximize accuracy\n",
    "\n",
    "def calc_batch_loss(input_batch, target_batch, gpt_model_batch, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = gpt_model_batch(input_batch)\n",
    "    logits = logits[:, -1, :]\n",
    "    # print(logits.shape, target_batch.shape) # Print\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "# Now to calculate loss for all the batches using the above function\n",
    "def calc_all_batch_loss(data_loader, GptModel, device, num_batches=None) -> float:\n",
    "    total_loss: float = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # print(f\"Input shape {input_batch.shape}, Target shape {target_batch.shape}\")\n",
    "        if i < num_batches:\n",
    "            loss = calc_batch_loss(\n",
    "                input_batch, target_batch, GptModel, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Similar to calculating the training accuracy, we now compute \n",
    "# the initial loss for each data set\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_all_batch_loss(\n",
    "        train_loader, small_gpt_model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_all_batch_loss(val_loader, small_gpt_model, device, num_batches=5)\n",
    "    test_loss = calc_all_batch_loss(test_loader, small_gpt_model, device, num_batches=5)\n",
    "#\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n",
    "# "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "63bdb536dc7a9dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:33:49.755813Z",
     "start_time": "2025-02-10T00:32:28.994604Z"
    }
   },
   "source": [
    "#\n",
    "# Now we implement a training function to fine-tune the model\n",
    "# which means adjusting the model to minimize the training loss\n",
    "#\n",
    "def train_classifier_simple(small_gpt_model, \n",
    "                            train_loader, \n",
    "                            val_loader, \n",
    "                            optimizer, \n",
    "                            device, \n",
    "                            num_epochs, \n",
    "                            eval_freq, \n",
    "                            eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        small_gpt_model.train()               # Sets model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()       # reset the loss gradients\n",
    "            loss = calc_batch_loss(\n",
    "                input_batch, target_batch, small_gpt_model, device\n",
    "            )\n",
    "            loss.backward()     # calculate loss gradients\n",
    "            optimizer.step()    # backprop updates model weights\n",
    "            examples_seen += input_batch.shape[0] # Tracks examples instead of tokens\n",
    "            global_step += 1\n",
    "            # Optional Evaluation Step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_classifier_model(\n",
    "                    small_gpt_model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, small_gpt_model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, small_gpt_model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "def evaluate_classifier_model(small_gpt_model, train_loader, val_loader, device, eval_iter):\n",
    "    small_gpt_model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_all_batch_loss(\n",
    "            train_loader, small_gpt_model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_all_batch_loss(\n",
    "            val_loader, small_gpt_model, device, num_batches=eval_iter\n",
    "        )\n",
    "    small_gpt_model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# Now we initialize the optimizer \n",
    "import time\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "start_time = time.time()\n",
    "cls_optimizer = torch.optim.AdamW(small_gpt_model.parameters())\n",
    "CLASSIFIER_MODEL_PATH=\"../models/review_classifier.pth\"\n",
    "num_epochs = 5\n",
    "examples_seen = 0\n",
    "training_done:bool = False\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [float], [float]\n",
    "#\n",
    "if not os.path.exists(CLASSIFIER_MODEL_PATH) and not training_done:\n",
    "    print(f\"Classifier Model doesnt exist at {CLASSIFIER_MODEL_PATH}, Training ...\\n\")\n",
    "    train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "        small_gpt_model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        cls_optimizer,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        eval_freq=50,\n",
    "        eval_iter=5\n",
    "    )\n",
    "    #\n",
    "    end_time = time.time()\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "    training_done = True\n",
    "else:\n",
    "    print(f\"Classifier Model exists at {CLASSIFIER_MODEL_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Model doesnt exist at ../models/review_classifier.pth, Training ...\n",
      "\n",
      "Ep 1 (Step 000000): Train loss 2.281, Val loss 2.021\n",
      "Ep 1 (Step 000050): Train loss 0.170, Val loss 0.188\n",
      "Ep 1 (Step 000100): Train loss 0.123, Val loss 0.056\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 2 (Step 000150): Train loss 0.159, Val loss 0.131\n",
      "Ep 2 (Step 000200): Train loss 0.002, Val loss 0.021\n",
      "Ep 2 (Step 000250): Train loss 0.021, Val loss 0.072\n",
      "Training accuracy: 97.50% | Validation accuracy: 92.50%\n",
      "Ep 3 (Step 000300): Train loss 0.150, Val loss 0.101\n",
      "Ep 3 (Step 000350): Train loss 0.018, Val loss 0.117\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000400): Train loss 0.003, Val loss 0.016\n",
      "Ep 4 (Step 000450): Train loss 0.011, Val loss 0.035\n",
      "Ep 4 (Step 000500): Train loss 0.118, Val loss 0.054\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.089, Val loss 0.011\n",
      "Ep 5 (Step 000600): Train loss 0.041, Val loss 0.012\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 1.35 minutes.\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "2d461d605119d1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:34:14.612968Z",
     "start_time": "2025-02-10T00:34:14.350752Z"
    }
   },
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# Plot the loss function during training\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "if training_done:\n",
    "    epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "    examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "    plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n",
    "else:\n",
    "    print(\"Training already done. No need to plot again, moving on...\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "968fde4292b581cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:34:24.880755Z",
     "start_time": "2025-02-10T00:34:14.712104Z"
    }
   },
   "source": [
    "# Now lets plot the resulting accuracy\n",
    "if training_done:\n",
    "    epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "    examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "    plot_values(\n",
    "        epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "        label=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    # Now we must calculate performance metrics for the training\n",
    "    train_accuracy = calc_accuracy_loader(train_loader, small_gpt_model, device)\n",
    "    val_accuracy = calc_accuracy_loader(val_loader, small_gpt_model, device)\n",
    "    test_accuracy = calc_accuracy_loader(test_loader, small_gpt_model, device)\n",
    "\n",
    "    print(f\"Training accuracy: {train_accuracy*100:.2f} %\")\n",
    "    print(f\"Validation accuracy: {val_accuracy*100:.2f} %\")\n",
    "    print(f\"Test accuracy: {test_accuracy*100:.2f} %\")\n",
    "else:\n",
    "    print(\"Training already done. No need to calculate accuracy...\\n\")\n",
    "    pass"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.71 %\n",
      "Validation accuracy: 98.66 %\n",
      "Test accuracy: 97.33 %\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "a3138646c2deb599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:34:37.762332Z",
     "start_time": "2025-02-10T00:34:37.598773Z"
    }
   },
   "source": [
    "# Now let's classify spam messages\n",
    "def classify_review(text, small_gpt_model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    small_gpt_model.eval()\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = small_gpt_model.pos_emb.weight.shape[1]\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = small_gpt_model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return \"Spam\" if predicted_label == 1 else \"Not Spam\"\n",
    "\n",
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "#\n",
    "print(f\"{classify_review(\n",
    "    text_1, small_gpt_model, tokenizer, device, max_length=train_dataset.max_length\n",
    ")} : {text_1}\")\n",
    "\n",
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(f\"{classify_review(\n",
    "    text_2, small_gpt_model, tokenizer, device, max_length=train_dataset.max_length\n",
    ")}: {text_2}\")\n",
    "# Now let's try classifying all the test dataset\n",
    "# df = test_dataset.data[\"Text\"]\n",
    "# i = 0\n",
    "# for text in df.values:\n",
    "#     i+=1\n",
    "#     print(f\"{i}: \"\n",
    "#           f\"{classify_review(text, small_gpt_model, tokenizer, device, max_length=test_dataset.max_length)} \"\n",
    "#           f\": {text}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam : You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\n",
      "Not Spam: Hey, just wanted to check if we're still on for dinner tonight? Let me know!\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "99208e2db11a0271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:34:51.123400Z",
     "start_time": "2025-02-10T00:34:50.038757Z"
    }
   },
   "source": [
    "# Save the model\n",
    "cls_model_path=\"../models/review_classifier.pth\"\n",
    "# cls_model_path=\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/review_classifier.pth\"\n",
    "if not os.path.exists(cls_model_path):\n",
    "    torch.save(small_gpt_model.state_dict(), cls_model_path)\n",
    "    print(f\"Saved model at {cls_model_path}\")\n",
    "else:\n",
    "    print(f\"Model exists at {cls_model_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model at ../models/review_classifier.pth\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "117ef11dd9ff2827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:35:03.923058Z",
     "start_time": "2025-02-10T00:35:03.693761Z"
    }
   },
   "source": [
    "# We can load this model again as well\n",
    "print(cls_model_path)\n",
    "model_loaded = False\n",
    "if os.path.exists(cls_model_path) and not model_loaded:\n",
    "    model_state_dict = torch.load(cls_model_path, map_location=device, weights_only=True)\n",
    "    small_gpt_model.load_state_dict(model_state_dict)\n",
    "    model_loaded = True\n",
    "    print(f\"Model successfully loaded from {cls_model_path} ...\")\n",
    "else:\n",
    "    print(f\"No model exists at {cls_model_path} or the model can not be loaded\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/review_classifier.pth\n",
      "Model successfully loaded from ../models/review_classifier.pth ...\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "id": "c9641da3f77713a3",
   "metadata": {},
   "source": [
    "# Fine-tuning to follow instructions  "
   ]
  },
  {
   "cell_type": "code",
   "id": "80b77746a0024957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:35:34.218352Z",
     "start_time": "2025-02-10T00:35:33.965761Z"
    }
   },
   "source": [
    "from chapter07.GetInstructionDataset import download_and_load_file\n",
    "from chapter07.InstructionDataset import InstructionDataset\n",
    "# 1. Download the dataset (See chapter07/GetInstructionDataset.py)\n",
    "ins_filepath = \"../data/instruction-data.json\"\n",
    "# ins_filepath = \"../data/alpaca_data.json\"\n",
    "insdata = download_and_load_file(ins_filepath)\n",
    "print(\"Example instruction: \\n\",insdata[50],\"\\n\")\n",
    "# print(len(insdata[50])) # 3\n",
    "\n",
    "# 2. Implement the input prompt formatting function ALPACA style\n",
    "def format_input(entry):          # Accepts a dictionary entry\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text\n",
    "\n",
    "# print(type(insdata[50]))\n",
    "model_input = format_input(insdata[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{insdata[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_and_load_file(): Downloading file from https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\n",
      "download_and_load_file(): Writing to ../data/instruction-data.json\n",
      "download_and_load_file(): Returning file content of  ../data/instruction-data.json\n",
      "Example instruction: \n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"} \n",
      "\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "3676e3e06f6cf1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:36:04.585252Z",
     "start_time": "2025-02-10T00:36:04.583090Z"
    }
   },
   "source": [
    "# Note we skip the ###Input if input is empty\n",
    "model_input = format_input(insdata[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{insdata[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "58e45ae8d8348fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:36:34.190121Z",
     "start_time": "2025-02-10T00:36:34.187631Z"
    }
   },
   "source": [
    "# Partitioning the dataset\n",
    "train_portion = int(len(insdata) * 0.80)\n",
    "test_portion = int(len(insdata) * 0.1)\n",
    "val_portion = len(insdata) - train_portion - test_portion\n",
    "\n",
    "ins_train_data = insdata[:train_portion]\n",
    "ins_test_data = insdata[train_portion:train_portion + test_portion]\n",
    "ins_val_data = insdata[train_portion + test_portion:]\n",
    "\n",
    "# print(ins_val_data[0])\n",
    "print(\"Training set length:\", len(ins_train_data))\n",
    "print(\"Validation set length:\", len(ins_val_data))\n",
    "print(\"Test set length:\", len(ins_test_data))\n",
    "\n",
    "# print(ins_train_data[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 880\n",
      "Validation set length: 110\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "id": "7d86901c0c16c3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:37:03.835967Z",
     "start_time": "2025-02-10T00:37:03.833731Z"
    }
   },
   "source": [
    "# Similar to the approach used for classification fine-tuning, we want to accelerate \n",
    "# training by collecting multiple training examples in a batch, which necessitates \n",
    "# padding all inputs to a similar length. As with classification fine-tuning, we \n",
    "# use the <|endoftext|> token as a padding token\n",
    "\n",
    "# Instead of appending the <|endoftext|> tokens to the text inputs, we can append \n",
    "# the Token ID corresponding to <|endoftext|> to the pretokenized inputs directly.\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
    "torch.mps.synchronize()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "4bf32b1bbf58a8ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:38:03.415434Z",
     "start_time": "2025-02-10T00:38:03.413121Z"
    }
   },
   "source": [
    "# Now we develop a custom collate function that we can pass to the data loader.\n",
    "# This custom collate function pads the training examples in each batch to the\n",
    "# same length while allowing different batches to have different lengths\n",
    "#\n",
    "# def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "#     batch_max_length = max(len(item)+1 for item in batch)\n",
    "#     inputs_list = []\n",
    "#     for item in batch:\n",
    "#         new_item = item.copy()\n",
    "#         new_item += [pad_token_id]\n",
    "#\n",
    "#         padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "#         input_item = torch.tensor(padded[:-1])\n",
    "#         inputs_list.append(input_item)\n",
    "#\n",
    "#     inputs_tensor = torch.stack(inputs_list).to(device) # Stack the tensors across dim=0\n",
    "#     return inputs_tensor\n",
    "#\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "#\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(\"Made up Batch: \", batch)\n",
    "# Test for the cusrom_collate function\n",
    "# print(custom_collate_draft_1(batch))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made up Batch:  ([0, 1, 2, 3, 4], [5, 6], [7, 8, 9])\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "e46b93a48cd4f5a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:38:03.491291Z",
     "start_time": "2025-02-10T00:38:03.488003Z"
    }
   },
   "source": [
    "# Above output shows that all inputs have been padded to the length of\n",
    "# the longest input list i.e. inputs_1, containing five token IDs\n",
    "#\n",
    "# However, as we learned earlier, we also need to create batches\n",
    "# with target token IDs corresponding to each batch of input IDs\n",
    "# The target token IDs match the input token IDs but are shifted\n",
    "# one position to the right\n",
    "\n",
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_list, targets_list = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1]) # Take the array except the last token\n",
    "        targets = torch.tensor(padded[1:]) # Shifted one position right from beginning to the last token\n",
    "        inputs_list.append(inputs)\n",
    "        targets_list.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    targets_tensor = torch.stack(targets_list).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(\"Inputs: \\n\", inputs)\n",
    "print(\"Targets: \\n\", targets)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      " tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "Targets: \n",
      " tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "bbb6315c11a51b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:38:33.518690Z",
     "start_time": "2025-02-10T00:38:33.514260Z"
    }
   },
   "source": [
    "# Now we assign a -100 placeholder value to all padding tokens. This\n",
    "# special value allows us to exclude these padding tokens from contributing\n",
    "# to the training loss calculation, ensuring that only meaningful data\n",
    "# influences model learning.\n",
    "#\n",
    "# But we always retain at least one <|end-of-text|>\n",
    "# token to make sure the model knows where to generate the EOT token.\n",
    "# So the final collate function looks like this\n",
    "def custom_collate_fn(batch,\n",
    "                      pad_token_id=50256,\n",
    "                      ignore_index=-100,\n",
    "                      allowed_max_length=None,\n",
    "                      device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_list, targets_list = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # Create a boolean mask for padding tokens like [False, False, False, False, False, True]\n",
    "        mask = (targets == pad_token_id)\n",
    "        # print(\"Mask: \\n\", mask)\n",
    "\n",
    "        # First we mark the non-zero tokens, then remove all dimensions of size 1\n",
    "        # so it returns the indices of the padding tokens in a list like format\n",
    "        # like tensor(4) or tensor([1, 2, 3, 4])\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        # print(\"Indices: \\n\", indices)\n",
    "\n",
    "        # If there are more than one padding tokens sequentially, keep first one\n",
    "        # and replace rest of the non-zero ones with ignore_index i.e. -100 on\n",
    "        # TARGETS TENSOR to remove from Loss calculation during training\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index # ignore_index is -100\n",
    "\n",
    "        # Optionally truncate to max sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_list.append(inputs)\n",
    "        targets_list.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    targets_tensor = torch.stack(targets_list).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "# Test custom collate function\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(\"Collated Inputs Tensor: \\n\", inputs)\n",
    "print(\"\\nCollated Targets Tensor: \\n\", targets)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collated Inputs Tensor: \n",
      " tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "\n",
      "Collated Targets Tensor: \n",
      " tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "5d7c946885fce7b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:39:34.602109Z",
     "start_time": "2025-02-10T00:39:34.598027Z"
    }
   },
   "source": [
    "torch.mps.synchronize()\n",
    "\n",
    "# For demonstration purposes, consider the following example\n",
    "# where each output logit corresponds to a potential token\n",
    "# from our model’s vocabulary. Here’s how we might calculate\n",
    "# the cross entropy loss during training\n",
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],   # Prediction for first token\n",
    "     [-0.5, 1.5]]   # Prediction for second token\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = F.cross_entropy(logits_1, targets_1)\n",
    "print(\"Loss_1: \", loss_1) # tensor(1.1269e+00) or 0.11269 or 0.1127\n",
    "\n",
    "# We can now see if adding any extra tokens will affect\n",
    "# the loss calculation\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = F.cross_entropy(logits_2, targets_2)\n",
    "print(\"Loss_2: \", loss_2)\n",
    "#\n",
    "# Now the loss becomes tensor(7.9359e-01) or 0.79359 or 0.7936\n",
    "# NOTE: So far, we have carried out example calculations using the\n",
    "# cross-entropy loss function in PyTorch, the same loss function we used in\n",
    "# training functions for pre-training and fine-tuning for classification.\n",
    "# However, now if we replace the 3rd token with -100 the loss will be\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = F.cross_entropy(logits_2, targets_3)\n",
    "print(\"Loss_3: \", loss_3)\n",
    "print(\"\\nloss_1 == loss_3:\", loss_1 == loss_3)\n",
    "\n",
    "# NOTE: This is specific to pytorch where the default setting of the cross entropy\n",
    "# function in PyTorch is cross_entropy(..., ignore_index=-100)\n",
    "# which means that the loss function ignores the padding tokens if they are set to -100\n",
    "# However, we would like to keep one 50256 (end-of-text) token ID in the targets tensor\n",
    "# because it helps the LLM learn where to generate the end-of-text tokens"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss_1:  tensor(1.1269)\n",
      "Loss_2:  tensor(0.7936)\n",
      "Loss_3:  tensor(1.1269)\n",
      "\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "d5e44c030b5c3c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:39:34.632638Z",
     "start_time": "2025-02-10T00:39:34.606550Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "# In addition to masking out padding tokens, it is also common to\n",
    "# mask out the TARGET TOKEN IDs that correspond to the instructions.\n",
    "#\n",
    "# By masking out the LLM’s TARGET TOKEN IDs corresponding to the instruction,\n",
    "# the cross entropy loss is only computed for the generated response target IDs.\n",
    "# Thus, the model is trained to focus on generating accurate responses rather\n",
    "# than memorizing instructions, which could help reduce overfitting.\n",
    "# We can try and use the same -100 mask to mask out the TARGET TOKEN IDs\n",
    "#\n",
    "# Next, to reuse the chosen device setting in custom_collate_fn when we plug\n",
    "# it into the PyTorch DataLoader class, we use the partial function from Python’s\n",
    "# functools standard library to create a new version of the function with the device prefilled.\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,     # Set the device to GPU i.e. \"cuda:0\" or \"mps:0\" or \"cpu\"\n",
    "    allowed_max_length=1024         # Truncate to 1024 tokens [default]\n",
    ")\n",
    "#\n",
    "# Now we can use the \"customized_collate_fn\" in the DataLoader\n",
    "#\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "#\n",
    "ins_train_dataset = InstructionDataset(ins_train_data, tokenizer)\n",
    "ins_train_loader = DataLoader(\n",
    "    ins_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "#\n",
    "# print(\"Example from Train loader: \\n\")\n",
    "# i: int = 1\n",
    "# for inputs, targets in ins_train_loader:\n",
    "#     i += 1\n",
    "#     print(f\"[{i}] Inputs Shape: {inputs.shape}, Targets Shape: {targets.shape}\")\n",
    "#\n",
    "ins_val_dataset = InstructionDataset(ins_val_data, tokenizer)\n",
    "ins_val_loader = DataLoader(\n",
    "    ins_val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "#\n",
    "ins_test_dataset = InstructionDataset(ins_test_data, tokenizer)\n",
    "ins_test_loader = DataLoader(\n",
    "    ins_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:40:09.399475Z",
     "start_time": "2025-02-10T00:40:04.813608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Executing this code will initiate the download of the medium-sized GPT model,\n",
    "# which has a storage requirement of approximately 1.42 gigabytes\n",
    "# from chapter05.gpt_download import download_and_load_gpt2\n",
    "torch.mps.synchronize()\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True,         # Query-key-value bias\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "BASE_CONFIG.update({\"model_name\" : CHOOSE_MODEL.split(\" \")[0]})\n",
    "\n",
    "medium_model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=medium_model_size,\n",
    "    models_dir=\"../data/gpt2\"\n",
    ")\n",
    "#\n",
    "# Create model to follow instructions\n",
    "#\n",
    "instr_model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "# Load GPT Medium weights into it\n",
    "load_weights_into_gpt(instr_model, params)\n",
    "\n",
    "# Set it to eval mode\n",
    "instr_model.eval();\n",
    "print(\"Set instr_model to Evaluation mode...\")"
   ],
   "id": "e8ba03bdc57e1be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model directory: ../data/gpt2/355M\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../data/gpt2/355M/vocab.bpe\n",
      "Set instr_model to Evaluation mode...\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:40:44.758479Z",
     "start_time": "2025-02-10T00:40:40.020774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Next we generate the model’s response using the same generate function\n",
    "torch.manual_seed(123)\n",
    "def format_input(entry):        # Accepts a dictionary entry\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text\n",
    "#\n",
    "#\n",
    "input_text = format_input(ins_val_data[0])\n",
    "print(\"Formatted Input: \\n\", input_text, \"\\n==================\\n\")\n",
    "#\n",
    "#\n",
    "token_ids = generate(\n",
    "    model=instr_model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(\"Generated Response Text: \\n\", response_text)\n"
   ],
   "id": "a8bd1ccfd91f7479",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Input: \n",
      " Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain the primary function of the human heart. \n",
      "==================\n",
      "\n",
      "Generated Response Text: \n",
      " ### Response:\n",
      "\n",
      "The heart is a complex organ that is responsible for pumping blood to the brain. The heart pumps blood to the brain through the veins in the\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Fine-tuning the LLM on instruction data",
   "id": "25d1c5dc245bdb6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T00:41:16.890558Z",
     "start_time": "2025-02-10T00:41:14.793131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "#\n",
    "instr_model.to(device)\n",
    "#\n",
    "with torch.no_grad():\n",
    "    ins_train_loss = calculate_loss_loader(ins_train_loader, instr_model, device, num_batches=5)\n",
    "    ins_val_loss = calculate_loss_loader(ins_val_loader, instr_model, device, num_batches=5)\n",
    "#\n",
    "print(\"Training loss:\", ins_train_loss)\n",
    "print(\"Validation loss:\", ins_val_loss)"
   ],
   "id": "cb213296699f454",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.660289001464844\n",
      "Validation loss: 4.551706457138062\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-10T00:41:47.027969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "#\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "ins_optimizer = torch.optim.AdamW(\n",
    "    instr_model.parameters(),\n",
    "    lr=0.00004,\n",
    "    weight_decay=0.05 # instead of 0.1\n",
    ")\n",
    "num_epochs = 3\n",
    "#\n",
    "# Train the instruction following model now\n",
    "#\n",
    "INSTR_MODEL_PATH = \"../models/gpt2-medium355M-sft.pth\"\n",
    "if not os.path.exists(INSTR_MODEL_PATH):\n",
    "    ins_train_losses, ins_val_losses, ins_tokens_seen = train_model_simple(\n",
    "        instr_model,\n",
    "        ins_train_loader,\n",
    "        ins_val_loader,\n",
    "        ins_optimizer,\n",
    "        device,\n",
    "        num_epochs=num_epochs,\n",
    "        eval_freq=5,\n",
    "        eval_iter=5,\n",
    "        start_context=format_input(ins_val_data[0]),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    #\n",
    "    end_time = time.time()\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "    #\n",
    "    # Plot the losses\n",
    "    #\n",
    "    epochs_tensor = torch.linspace(0, num_epochs, len(ins_train_losses))\n",
    "    plot_losses(epochs_tensor, ins_tokens_seen, ins_train_losses, ins_val_losses)\n",
    "else:\n",
    "    print(f\"Training has already been completed for {num_epochs} epochs.\")"
   ],
   "id": "ea8355d274d2912e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.64480, Val loss 1.18125\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Now save the instruction model\n",
    "#\n",
    "ins_model_file_name = f\"../models/{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "if not os.path.exists(ins_model_file_name):\n",
    "    torch.save(model.state_dict(), ins_model_file_name)\n",
    "    print(f\"\\nModel saved as {ins_model_file_name}\\n\")\n",
    "else:\n",
    "    print(f\"Model exists at {ins_model_file_name}\\n\")\n"
   ],
   "id": "39a8e3b75698e8c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in ins_test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=instr_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    model_response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    print(\"Input Text: \", input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {model_response_text.strip()}\\n\")\n",
    "\n",
    "    print(\"-------------------------------------\\n\")"
   ],
   "id": "3230573ca955c154",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "#\n",
    "# Generating test set responses\n",
    "#\n",
    "for i, entry in tqdm(enumerate(ins_test_data), total=len(ins_test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=instr_model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    ins_test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"../data/instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(ins_test_data, file, indent=4)\n",
    "    file.close()\n",
    "\n",
    "print(\"\\nInstruction test data [0]: \\n\", ins_test_data[0])\n",
    "print(\"\\nInstruction test data [1]: \\n\", ins_test_data[1])\n",
    "\n"
   ],
   "id": "2b9190d81f029c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "57196963a55b3388",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
