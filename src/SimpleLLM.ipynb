{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# This is an attempt to learn by building and training an LLM from Scratch  "
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.354622Z",
     "start_time": "2025-01-30T00:53:57.600011Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import urllib.request\n",
    "    \n",
    "# Check which GPU if any is available\n",
    "# torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     x: Tensor = torch.ones(1, device=device)\n",
    "#     print(f\"x = {x} using 'cuda:0' backend\")\n",
    "#     \n",
    "# elif \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x: Tensor = torch.ones(1, device=device)\n",
    "    print(f\"x = {x} using {device} backend\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # x: Tensor = torch.ones(1, device=device)\n",
    " \n",
    "print(device)\n",
    "\n",
    "def get_some_text():\n",
    "    # Now lets load the text data\n",
    "    bookUrl = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"  # Download a text (book)\n",
    "    filepath = \"../data/the-verdict.txt\"\n",
    "    # print(file_path)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        urllib.request.urlretrieve(bookUrl, filepath)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        rawtext = f.read()\n",
    "        \n",
    "    print(\"Total characters in the story: \", len(rawtext))\n",
    "    print(\"Total Lines in raw text: \", rawtext.count(\"\\n\"))\n",
    "    return rawtext\n",
    "\n",
    "raw_text = get_some_text()\n",
    "print(\"Some text: \", raw_text[:49])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using mps backend\n",
      "mps\n",
      "Total characters in the story:  20479\n",
      "Total Lines in raw text:  164\n",
      "Some text:  I HAD always thought Jack Gisburn rather a cheap \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2c7227e79afbcad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.359167Z",
     "start_time": "2025-01-30T00:53:58.355836Z"
    }
   },
   "source": [
    "# Now we have to tokenize the text. The best way to do that is to use a pre-build tokennizer, but first we will try some \n",
    "# basic python regular expressions to do the same things\n",
    "import re\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "#\n",
    "print(len(preprocessed))\n",
    "print(preprocessed[:30])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b9dc98b584bc6d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.362618Z",
     "start_time": "2025-01-30T00:53:58.359952Z"
    }
   },
   "source": [
    "# Now we need to generate token IDs\n",
    "# Now let us create a list of all unique tokens and sort them alphabetically to determine the vocabulary size\n",
    "all_uniq_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_uniq_words)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "\n",
    "# Now that we know the vocabulary size, lets enumerate and assign some numbers to them\n",
    "vocab = {token:integer for integer,token in enumerate(all_uniq_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  1130\n",
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b49e9060996c9f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.367832Z",
     "start_time": "2025-01-30T00:53:58.364733Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV1 import SimpleTokenizerV1\n",
    "\n",
    "# Now we want to apply this vocabulary to convert new text to generate token id\n",
    "# When we want to convert the outputs of an LLM from numbers back into text, we need a way to turn token IDs into text. \n",
    "# For this, we can create an inverse version of the vocabulary that maps token IDs back to the corresponding text tokens.\n",
    "\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted you know,\" \n",
    "        Mrs Gisburn said with pardonable pride.\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 1126, 596, 5, 1, 67, 38, 851, 1108, 754, 793, 7]\n",
      "\" It' s the last he painted you know,\" Mrs Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "92b6519fe1741db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.371135Z",
     "start_time": "2025-01-30T00:53:58.368509Z"
    }
   },
   "source": [
    "all_tokens = sorted(list(set(preprocessed))) # Make preprocessed a list so we can extend it\n",
    "all_tokens.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
    "# redo the vocab population\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "d03ae607c2d20268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.373786Z",
     "start_time": "2025-01-30T00:53:58.371668Z"
    }
   },
   "source": [
    "# Print the last 5 vocab items\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|unk|>', 1130)\n",
      "('<|endoftext|>', 1131)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "dcdf224cd056d26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.377373Z",
     "start_time": "2025-01-30T00:53:58.374372Z"
    }
   },
   "source": [
    "from src.chapter02.SimpleTokenizerV2 import SimpleTokenizerV2\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984, 722, 988, 1130, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e4e4738351ee6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.388187Z",
     "start_time": "2025-01-30T00:53:58.378094Z"
    }
   },
   "source": [
    "### Byte Pair Encoding \n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"Tiktoken version: \", version(\"tiktoken\"))\n",
    "#print(\"Tiktoken version: \", tiktoken.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken version:  0.8.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ac57b0bafdc676f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.554523Z",
     "start_time": "2025-01-30T00:53:58.388862Z"
    }
   },
   "source": [
    "#### This is the tokenizer using the GPT2 tokenization model\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(f\"Encoded: {integers}\")\n",
    "strings = tokenizer.decode(integers)\n",
    "print(f\"Decoded: {strings}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n",
      "Decoded: Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "2a6a5225d4fab946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.558686Z",
     "start_time": "2025-01-30T00:53:58.556812Z"
    }
   },
   "source": [
    "print(tokenizer.encode(\"Akwirw ier\"))\n",
    "print(tokenizer.decode(tokenizer.encode(\"Akwirw ier\")))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1ab2edd9fb1ca03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.562899Z",
     "start_time": "2025-01-30T00:53:58.559231Z"
    }
   },
   "source": [
    "# Let's now do Data Sampling with a sliding window\n",
    "# 1. Let's tokenize the entire story with BPE tokenizer first\n",
    "\n",
    "encoded_text = tokenizer.encode(raw_text)\n",
    "print(len(encoded_text))\n",
    "enc_sample = encoded_text[50:]\n",
    "\n",
    "# Now Let's start by defining x and y where x has input tokens and y the output tokens shifted by 1\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "# print(f\"x: {x}\")\n",
    "# print(f\"y:      {y}\")\n",
    "\n",
    "\n",
    "#####\n",
    "# Next word prediction tasks can now be created by \n",
    "for i in range(1, context_size + 1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    # print(f\"context input: {context} --> desired prediction: {desired}\")\n",
    "    # Now we create the input output target pairs\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "62094a4513e01008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.565060Z",
     "start_time": "2025-01-30T00:53:58.563433Z"
    }
   },
   "source": [
    "# from Dataloader import Dataloader\n",
    "# \n",
    "# dataloader = Dataloader(batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "# dataloader = dataloader.get_instance(file_path, text_enc='utf-8', mode='r')\n",
    "# if dataloader is not None:\n",
    "#     data_iter = iter(dataloader)\n",
    "#     inputs, targets = next(data_iter)\n",
    "#     print(\"Loaded text data...\\n\")\n",
    "#     print(\"Inputs: \\n\", inputs)\n",
    "#     print(\"\\nTargets: \\n\", targets)\n",
    "# else: \n",
    "#     print(\"Failed loading \", dataloader)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "fa0c4b5f389cdc4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.711714Z",
     "start_time": "2025-01-30T00:53:58.565652Z"
    }
   },
   "source": [
    "import torch.nn\n",
    "from src.chapter02.Dataloader import Dataloader\n",
    "file_path = \"../data/the-verdict.txt\"\n",
    "\n",
    "####\n",
    "# Finally we need to create the embeddings for the tokens\n",
    "# If we have a batch size of 8 with 4 tokens each it'll be an 8 x 4 x 256 tensor\n",
    "max_length = 4  \n",
    "\n",
    "mydataloader = Dataloader(batch_size=8, max_length=max_length, stride=4, shuffle=False, drop_last=True, num_workers=0)\n",
    "dataloader = mydataloader.create_dataloader_v1(txt=raw_text)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "# print(\"Input Token IDs:\\n\", inputs)\n",
    "# print(\"Input tensor shape: \", inputs.shape) \n",
    "\n",
    "# Now since self-attentions are position agnostic, we should add some positional data.\n",
    "# Absolute and relative positional data can be added. So let's create embeddings with say 256 dimensions\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "# context_length = 1024\n",
    "\n",
    "## Now lets embed the input tensors\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token embeddings shape: \", token_embeddings.shape) #8x4x256\n",
    "\n",
    "\n",
    "# For a GPT model’s absolute position embedding approach, we just need to create another embedding \n",
    "# layer that has the same embedding dimension as the token_embedding_ layer:\n",
    "context_length = max_length     #context is length of positions we care about for attention\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embeddings Shape: \", pos_embeddings.shape) # 4x256\n",
    "#\n",
    "# Add the positional embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Position Merged Input Embeddings Shape: \", input_embeddings.shape)\n",
    "#\n",
    "# Now lets look at the dataloader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    token_embeddings = token_embedding_layer(inputs)\n",
    "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "    input_embeddings = token_embeddings + pos_embeddings\n",
    "    break\n",
    "#\n",
    "print(\"Batch Embeddings Shape: \", input_embeddings.shape)\n",
    "    \n",
    "print(\"Input tensor \", x)\n",
    "print(\"Target tensor\", y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape:  torch.Size([8, 4, 256])\n",
      "Positional Embeddings Shape:  torch.Size([4, 256])\n",
      "Position Merged Input Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Batch Embeddings Shape:  torch.Size([8, 4, 256])\n",
      "Input tensor  [290, 4920, 2241, 287]\n",
      "Target tensor [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "95c2c3a6eb3eea50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.715749Z",
     "start_time": "2025-01-30T00:53:58.712258Z"
    }
   },
   "source": [
    "# Chapter 3 - Attention\n",
    "#\n",
    "import torch\n",
    "\n",
    "# In self-attention our goal is to calculate context vector z(i) for each \n",
    "# element x(i) of the input sequence. Consider the following input sequence \n",
    "#\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "# inputs.to(device)\n",
    "print(\"Input sequence shape: \", inputs.shape)\n",
    "# \n",
    "# Now calculate weights for attention\n",
    "# Assume query is the second word \"journey\" or inputs[1] \n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "print(f\"Query is the 2nd word 'journey': {query}\")\n",
    "#\n",
    "attention_scores_2 = torch.empty(inputs.shape[0])\n",
    "# attention_scores_2.to(device)\n",
    "for idx, x_i in enumerate(inputs):\n",
    "    attention_scores_2[idx] = torch.dot(x_i, query)\n",
    "#    print(f\"Sequence Element [{idx}], attention_score: {attention_scores_2}\")\n",
    "print(f\"Final value of attention_score_2: {attention_scores_2}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape:  torch.Size([6, 3])\n",
      "Query is the 2nd word 'journey': tensor([0.5500, 0.8700, 0.6600])\n",
      "Final value of attention_score_2: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "53ede1deb7d5678e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.721620Z",
     "start_time": "2025-01-30T00:53:58.716314Z"
    }
   },
   "source": [
    "\n",
    "## Note: For all elements if we were to calculate attention it'd be a O(n^2) operation\n",
    "# NOW we normalize the attention weights, so they sum up to 1\n",
    "attention_weights_2_tmp = attention_scores_2 / attention_scores_2.sum()\n",
    "# attention_weights_2_tmp.to(device)\n",
    "print(\"Normalized attention weights:\", attention_weights_2_tmp)\n",
    "print(\"Sum of attention weights:\", attention_weights_2_tmp.sum())\n",
    "\n",
    "## Generally we normalize using the softmax to do the normalization\n",
    "\n",
    "# # define a softmax function\n",
    "def softmax_naive(tensor_x):\n",
    "    return torch.exp(tensor_x) / torch.exp(tensor_x).sum(dim=0, keepdim=True)\n",
    "# \n",
    "\n",
    "attention_scores_2_naive = softmax_naive(attention_scores_2)\n",
    "# attention_scores_2_naive.to(device)\n",
    "\n",
    "print(\"Attention weights naive:\", attention_scores_2_naive)\n",
    "print (\"Naive Sum: \", attention_scores_2_naive.sum())\n",
    "# \n",
    "# Generally we normalize using the torch.softmax() to do the normalization\n",
    "# Softmax ensures its always positive and always adds up to 1\n",
    "#\n",
    "attention_weights_2_torch_softmax = torch.softmax(attention_scores_2, dim=0)\n",
    "# attention_weights_2_torch_softmax.to(device)\n",
    "print(\"Attention weights torch softmax:\", attention_weights_2_torch_softmax)\n",
    "# print(\"Attention weights torch softmax Sum: \", attention_weights_2_torch_softmax.sum())\n",
    "\n",
    "# Now that we have calculated the normalized attention weights, we are ready for the final step.\n",
    "# Calculate the context vector z(2) by multiplying the embedded input tokens x(i), \n",
    "# with the corresponding normalized attention weights and then summing the resultant vectors\n",
    "#\n",
    "query = inputs[1]\n",
    "# query.to(device)\n",
    "#\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "# context_vec_2.to(device)\n",
    "#\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += (attention_weights_2_torch_softmax[i] * x_i)\n",
    "print(\"Context vector z2: \", context_vec_2)\n",
    "\n",
    "#\n",
    "# Now in similar fashion lets calculate attention scores for all the input sequences \n",
    "attention_scores = torch.empty(inputs.shape[0],inputs.shape[0])\n",
    "# attention_scores.to(device)\n",
    "print(\"\\nAttention Scores matrix shape: \", attention_scores.shape)\n",
    "#\n",
    "# Using for loops\n",
    "#\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attention_scores[i, j] = torch.dot(x_i, x_j)\n",
    "# #\n",
    "#print(attention_scores)\n",
    "#\n",
    "# Using matrix multiplication we can do it faster\n",
    "#\n",
    "attention_scores_m = inputs @ inputs.T\n",
    "# attention_scores_m.to(device)\n",
    "#print(\"Normalized attention scores \\n\", attention_scores_m)\n",
    "\n",
    "# Just as before lets normalize the rows, so they sum up to 1\n",
    "# NOTE: Here dim = -1 means we are applying the softmax along the last dimension of the attention_scores_m tensor\n",
    "#\n",
    "attention_weights = torch.softmax(attention_scores_m, dim=-1)\n",
    "# attention_weights.to(device)\n",
    "#print(\"Normalized ATTENTION weights \\n\", attention_weights)\n",
    "# print(\"Softmax Sums:\\n\", attention_weights.sum(dim=-1))\n",
    "\n",
    "# FINAL STEP\n",
    "# Now let's calculate the context vectors for all the input by multiplying the input with attention weights\n",
    "all_context_vectors = attention_weights @ inputs # Matrix multiplication\n",
    "# all_context_vectors.to(device)\n",
    "#print(\"Context vector for the entire sequence\\n\", all_context_vectors)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum of attention weights: tensor(1.0000)\n",
      "Attention weights naive: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Naive Sum:  tensor(1.)\n",
      "Attention weights torch softmax: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Context vector z2:  tensor([0.4419, 0.6515, 0.5683])\n",
      "\n",
      "Attention Scores matrix shape:  torch.Size([6, 6])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "fa980b537b01e646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.728455Z",
     "start_time": "2025-01-30T00:53:58.722401Z"
    }
   },
   "source": [
    "\n",
    "###\n",
    "### 3.4.1 Using weighted matrix\n",
    "###\n",
    "#\n",
    "# Computing the attention weights step by step\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "x_2 = inputs[1]\n",
    "# x_2.to(device)\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(\"x_2: \", x_2)\n",
    "# Now let's initialize 3 weighted matrices Wq, Wk and Wv\n",
    "# Setting requires_grad = False, to reduce clutter, but for model training this should be set to True\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "#\n",
    "# Next we compute the query, key and value vectors\n",
    "# Note the output is a 2 dimenstional vector because we set dout to 2\n",
    "#\n",
    "# W_query.to(device)\n",
    "# W_key.to(device)\n",
    "# W_value.to(device)\n",
    "#\n",
    "# Now the dot product with the input\n",
    "#\n",
    "query_2 = x_2 @ W_query\n",
    "key_2   = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "#\n",
    "# query_2.to(device)\n",
    "# key_2.to(device)\n",
    "# value_2.to(device)\n",
    "#\n",
    "print(\"Query 2: \", query_2)\n",
    "print(\"Key 2:   \", key_2)\n",
    "print(\"Value 2: \", value_2)\n",
    "#\n",
    "print(\"\\n\")\n",
    "#\n",
    "\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "# keys.to(device)\n",
    "# values.to(device)\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n",
    "\n",
    "keys_2 = keys[1]\n",
    "\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "# attn_score_22.to(device)\n",
    "# attn_score_22 = query_2 @ keys_2\n",
    "print(\"Attention (dot) score 22:\", attn_score_22)\n",
    "\n",
    "# Generalizing across all inputs\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "# attn_scores_2.to(device)\n",
    "print(\"Attention \\\\@ Scores 2: \", attn_scores_2)\n",
    "# Check the second element is same as previously calculated attention score\n",
    "#\n",
    "# We compute the attention weights by scaling the attention scores and using the softmax function. \n",
    "# However, now we scale the attention scores by dividing them by the square root of the embedding \n",
    "# dimension of the keys\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1]**0.5, dim=-1)\n",
    "# attn_weights_2.to(device)\n",
    "print(\"attn_weights_2: \", attn_weights_2)\n",
    "\n",
    "# The reason for the normalization by square root of embedding dimension size is to improve the training performance by avoiding small gradients. \n",
    "# For instance, when scaling up the embedding dimension, which is typically > 1,000 for GPT-like LLMs, large dot products can result in \n",
    "# very small gradients during backpropagation (due to the softmax function applied to them). \n",
    "# As dot products increase, the softmax function behaves more like a step function, resulting in gradients nearing zero. \n",
    "# These small gradients can drastically slow down learning or cause training to stagnate.\n",
    "#\n",
    "# The scaling by the square root of the embedding dimension is the reason why this self-attention mechanism is also called scaled-dot product attention.\n",
    "# Similar to when we computed the context vector as a weighted sum over the input vectors \n",
    "# we now compute the context vector as a weighted sum over the value vectors. \n",
    "# Here, the attention weights serve as a weighting factor that weighs the respective importance of each value vector\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "# context_vec_2.to(device)\n",
    "print(\"context_vec_2: \", context_vec_2)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_2:  tensor([0.5500, 0.8700, 0.6600])\n",
      "Query 2:  tensor([0.4306, 1.4551])\n",
      "Key 2:    tensor([0.4433, 1.1419])\n",
      "Value 2:  tensor([0.3951, 1.0037])\n",
      "\n",
      "\n",
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n",
      "Attention (dot) score 22: tensor(1.8524)\n",
      "Attention \\@ Scores 2:  tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "attn_weights_2:  tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "context_vec_2:  tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "2ca52ea3a908fe20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.736830Z",
     "start_time": "2025-01-30T00:53:58.729192Z"
    }
   },
   "source": [
    "from src.chapter03.SelfAttention_v2 import SelfAttention_v2\n",
    "\n",
    "torch.manual_seed(789)\n",
    "self_attn_v2 = SelfAttention_v2(d_in, d_out)\n",
    "#print(\"Context vectors from SelfAtten_v2: \\n\", self_attn_v2(inputs))\n",
    "\n",
    "# Note since the input contains 6 embedding vectors, the output also has 6 rows of context vectors\n",
    "\n",
    "\n",
    "# Causal Attention \n",
    "# First we apply softmax to the attention scores then mask with 0 above the diagonal and then normalize the rows to 1\n",
    "#\n",
    "queries = self_attn_v2.W_query(inputs)\n",
    "# queries.to(device)\n",
    "\n",
    "keys = self_attn_v2.W_key(inputs)\n",
    "# keys.to(device)\n",
    "\n",
    "attn_scores = queries @ keys.T\n",
    "# attn_scores.to(device)\n",
    "\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "# attn_weights.to(device)\n",
    "#print(\"Attention Wrights: \\n\",attn_weights)\n",
    "\n",
    "# Now mask the values above diagonal as 0 using the tril() function\n",
    "#\n",
    "context_length = attn_scores.shape[0]\n",
    "#\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "#print(\"Mask Simple: \\n\", mask_simple)\n",
    "#\n",
    "# Now simply multiply them to prevent the look ahead \n",
    "#\n",
    "masked_attention_weights = attn_weights * mask_simple\n",
    "# masked_attention_weights.to(device)\n",
    "#print(\"Masked attention weights: \\n\", masked_attention_weights)\n",
    "\n",
    "#\n",
    "# Now re-normalize to make sure rows add up to 1. To do this we divide each element by sum of each row\n",
    "#\n",
    "row_sums = masked_attention_weights.sum(dim=-1, keepdim=True)\n",
    "#print(\"row_sums: \\n\", row_sums)\n",
    "masked_simple_norm = masked_attention_weights / row_sums\n",
    "print(\"Masked & re-normalized weights: \\n\", masked_simple_norm)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1.], device='mps:0') using 'mps:0' backend\n",
      "Masked & re-normalized weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "f3a442b3d9b7413a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.741343Z",
     "start_time": "2025-01-30T00:53:58.737558Z"
    }
   },
   "source": [
    "# A more efficient way to obtain masked attention weights is to mask the attention scores with \n",
    "# negative infinity before applying softmax function. (e^negative infinity -> 0)\n",
    "# We can implement this masking by replacing values above the diagonal with 1 and then replacing them \n",
    "# with negative infinity\n",
    "#\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "# mask.to(device)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "# masked.to(device)\n",
    "print(\"Masked attention weights: \\n\", masked)\n",
    "#\n",
    "# Now apply the softmax function \n",
    "#\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(\"Softmax'd Attention weights: \\n\", attn_weights)\n",
    "\n",
    "# Now we can use these modified attention weights to calculate the context vector\n",
    "#\n",
    "context_vec = attn_weights @ values\n",
    "print(\"context_vec: \\n\", context_vec)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention weights: \n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "Softmax'd Attention weights: \n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "context_vec: \n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.2795, 0.9361],\n",
      "        [0.3133, 0.9508],\n",
      "        [0.2994, 0.8595],\n",
      "        [0.2702, 0.7554],\n",
      "        [0.2772, 0.7618]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "d6b38e5f420f6067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.746378Z",
     "start_time": "2025-01-30T00:53:58.742231Z"
    }
   },
   "source": [
    "# Masking additional weights with dropout\n",
    "# Drop out in the attention mechanism is applied at 2 specific times: \n",
    "# 1. After calculating the attention weights\n",
    "# 2. After applying the attention weights to value vectors\n",
    "# Here we will apply the dropout mask after computing the attention weights\n",
    "#\n",
    "# Lets use a dropout rate of 50% meaning half the attention weights will be masked out. \n",
    "# Normally it's a much lower rate like 0.1 or 0.2\n",
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))\n",
    "#\n",
    "# Since we are applying 50% dropout, to compensate for reduction in active elements\n",
    "# we are going to scale up the values of remaining elements by a factor of 1/0.5 = 2\n",
    "# This scaling is crucial to maintain the balance of the attention weights\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "print(\"Dropped out attention weights: \\n\", dropout(attn_weights))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "Dropped out attention weights: \n",
      " tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "50701dd69a456857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.751059Z",
     "start_time": "2025-01-30T00:53:58.747010Z"
    }
   },
   "source": [
    "from src.chapter03.CausalAttention import CausalAttention\n",
    "\n",
    "# Let’s ensure that the code can handle batches consisting of more than one input so that \n",
    "# the CausalAttention class supports the batch outputs produced by the data loader\n",
    "# To simulate batch input lets duplicate the input text\n",
    "#\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "# batch.to(device)\n",
    "print(\"batch: \\n\", batch.shape)\n",
    "# print(batch)\n",
    "#\n",
    "# We can now use the CausalAttention class as follows\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_layer = batch.shape[1]\n",
    "causal_attn = CausalAttention(d_in, d_out, context_length, 0.0, False)\n",
    "context_vecs = causal_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: \n",
      " torch.Size([2, 6, 3])\n",
      "context_vecs: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9d8058957dc253b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.756013Z",
     "start_time": "2025-01-30T00:53:58.751716Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttentionWrapper import MultiHeadAttentionWrapper\n",
    "\n",
    "# Multi Head Attention\n",
    "# Now if we use the MultiHeadAttentionWrapper class with two attention heads, and CausalAttention \n",
    "# output dimension d_out = 2, we get a 4 dimensional context vector (d_out * num_heads = 4).\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3, 2\n",
    "multi_head_attn = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0, num_heads=2, qkv_bias=False)\n",
    "context_vecs = multi_head_attn(batch)\n",
    "print(\"context_vecs: \\n\", context_vecs)\n",
    "print(\"context_vecs.shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs: \n",
      " tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: \n",
      " torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "f20088921d8113c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.760321Z",
     "start_time": "2025-01-30T00:53:58.756820Z"
    }
   },
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])\n",
    "# print(a.transpose(2, 3))\n",
    "a.to(device)\n",
    "\n",
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)\n",
    "\n",
    "print(f\"Batched: \\n{a @ a.transpose(2, 3)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n",
      "Batched: \n",
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "df6a05dfc13ebbe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.765342Z",
     "start_time": "2025-01-30T00:53:58.761060Z"
    }
   },
   "source": [
    "from src.chapter03.MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "print(\"Batch Shape: \\n\", batch.shape)\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"Context vector shape: \\n\", context_vecs.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: \n",
      " torch.Size([2, 6, 3])\n",
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "Context vector shape: \n",
      " torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "3f958161a85ca549",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Chapter 4: Implementing GPT from Scratch to generate text\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:58.768086Z",
     "start_time": "2025-01-30T00:53:58.766038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}"
   ],
   "id": "16f34621162871e9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "5ac1cbf145ad6daf",
   "metadata": {},
   "source": [
    "## Here is the proposed architecture and order of implementation\n",
    "![image](../data/4-3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "75010152b67235a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.381558Z",
     "start_time": "2025-01-30T00:53:58.768593Z"
    }
   },
   "source": [
    "from src.chapter04.DummyGPTModel import DummyGPTModel\n",
    "import tiktoken\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "#\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.clear()\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)).to(device))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)).to(device))\n",
    "batch = torch.stack(batch, dim=0).to(device)\n",
    "batch.to(device)\n",
    "print(\"Input Batch: \\n\", batch)\n",
    "print(\"Input batch shape: \\n\", batch.shape)\n",
    "#\n",
    "# Next, we initialize a new 124-million-parameter DummyGPTModel instance \n",
    "# and feed it the tokenized batch\n",
    "#\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "logits = model(batch)\n",
    "print(\"Output shape: \\n\", logits.shape)\n",
    "#print(logits)\n",
    "#                      \n",
    "#"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Batch: \n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Input batch shape: \n",
      " torch.Size([2, 4])\n",
      "Output shape: \n",
      " torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "c06060ecd0f8f8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.387335Z",
     "start_time": "2025-01-30T00:53:59.382233Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Let’s now implement LAYER Normalization to improve the stability and efficiency of the training.\n",
    "# The main idea behind LAYER Normalization is to adjust the activations (outputs) of a deep\n",
    "# neural network layer to have a mean of 0 and a variance of 1\n",
    "#\n",
    "# This adjustment speeds up the convergence.\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "#\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(\"Layer: \\n\",out)\n",
    "#\n",
    "# The NN Layer contains the non-linear activation ReLU which 0's out the negative values\n",
    "# \n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Variance: \", var)\n",
    "print(\"\\n\")\n",
    "#\n",
    "# Next, let’s apply layer normalization to the layer outputs we obtained earlier. \n",
    "# The operation consists of subtracting the mean and dividing by the square root \n",
    "# of the variance (also known as the standard deviation):\n",
    "#\n",
    "eps = 1e-5\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "# Dim = -1 indicates statistics along the last dimention\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "print(\"Normalized Layer Outputs: \\n\", out_norm)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: \n",
      " tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Mean:  tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:  tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n",
      "\n",
      "\n",
      "Normalized Layer Outputs: \n",
      " tensor([[6.1585e-01, 1.4126e+00, -8.7188e-01, 5.8723e-01, -8.7188e-01, -8.7188e-01],\n",
      "        [-1.8865e-02, 1.1211e-01, -1.0876e+00, 1.5173e+00, 5.6474e-01, -1.0876e+00]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000e+00],\n",
      "        [1.0000e+00]], grad_fn=<VarBackward0>)\n",
      "-------------------------\n",
      "\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "a39e430a037896f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.390999Z",
     "start_time": "2025-01-30T00:53:59.387868Z"
    }
   },
   "source": [
    "from src.chapter04.LayerNorm import LayerNorm\n",
    "\n",
    "# Previously we used unbiased = False in our variance calculation. This doesn't \n",
    "# apply Bessel's correction where divisor is n-1 instead of n. But this is \n",
    "# compatible with GPT-2\n",
    "\n",
    "ln = LayerNorm(emb_dim = 5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean: \\n\", mean)\n",
    "print(\"Variance: \\n\", var)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: \n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "3130c2c83093ee01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.707878Z",
     "start_time": "2025-01-30T00:53:59.394510Z"
    }
   },
   "source": [
    "# Let us see how the GELU (Gaussian Error Linear Unit) stacks up against \n",
    "# # RELU (REctified Linear Unit)\n",
    "from src.chapter04.GELU import GELU\n",
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "e496e641f9044a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.727834Z",
     "start_time": "2025-01-30T00:53:59.708460Z"
    }
   },
   "source": [
    "from src.chapter04.SimpleFeedForward import SimpleFeedForward\n",
    "\n",
    "# As we can see the smoothness of the GELU can lead to better optimization properties during training\n",
    "# as it allows more nuanced finer adjustments to models parameters. In contrast, RELU has a sharp corner\n",
    "# that can make adjustments difficult for very deep networks.\n",
    "#\n",
    "# Next we look at implementing a feed forward network with GELU activations\n",
    "# See SimpleFeedForward.py\n",
    "#\n",
    "sff = SimpleFeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = sff(x)\n",
    "print(out.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "98a59bc5db854fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.734970Z",
     "start_time": "2025-01-30T00:53:59.728616Z"
    }
   },
   "source": [
    "from src.chapter04.ExampleDeepNeuralNetwork import ExampleDeepNeuralNetwork\n",
    "\n",
    "# Next we implement Shortcut Connections\n",
    "# Each layer will be initialized such that it accepts an example with three input \n",
    "# values and returns three output values.\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "# model.to(device)\n",
    "\n",
    "# Next lets print the gradients\n",
    "def print_gradients(nnmodel, input_x):\n",
    "    output = nnmodel(input_x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    loss.backward()\n",
    "    for name, param in nnmodel.named_parameters():\n",
    "        # print(name, \" = \", param)\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "#\n",
    "# Now Lets use this function to print the gradients calculated by loss.backward()\n",
    "print_gradients(model_without_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "4bfdfab7cb5bcc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.749744Z",
     "start_time": "2025-01-30T00:53:59.735887Z"
    }
   },
   "source": [
    "# As you can see above gradients become tiny aka Vanishing from Layer4 to Layer1\n",
    "# Let’s now instantiate a model with skip connections and see how it compares:\n",
    "torch.manual_seed(123)\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "# model.to(device)\n",
    "print_gradients(model_with_shortcut, sample_input)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "a229081ed60e29b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.752353Z",
     "start_time": "2025-01-30T00:53:59.750486Z"
    }
   },
   "source": [
    "# Note here the gradient doesn't approach a vanishingly small value during backprop.\n",
    "# In conclusion, shortcut connections are important for overcoming the limitations posed \n",
    "# by the vanishing gradient problem in deep neural networks."
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "2df6d339f0570629",
   "metadata": {},
   "source": [
    "#### Next, we’ll connect all the previously covered concepts (layer normalization, GELU activations, feed forward module, and shortcut connections) in a transformer  block, which is the final building block we need to code the GPT architecture.\n",
    "\n",
    "![image](../data/transformer_wiring.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cd526dd3047ba477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:53:59.802763Z",
     "start_time": "2025-01-30T00:53:59.753137Z"
    }
   },
   "source": [
    "# See TransformerBlock.py for the basic sequence and feedforward details\n",
    "from src.chapter04.TransformerBlock import TransformerBlock\n",
    "\n",
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "tr_block = TransformerBlock(GPT_CONFIG_124M)\n",
    "out = tr_block(x)\n",
    "#\n",
    "print(\"Input Shape:  \", x.shape)\n",
    "print(\"Output Shape: \", out.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:   torch.Size([2, 4, 768])\n",
      "Output Shape:  torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "8c3e76bf70259f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:00.903678Z",
     "start_time": "2025-01-30T00:53:59.803746Z"
    }
   },
   "source": [
    "from src.chapter04.GPTModel import GPTModel \n",
    "\n",
    "# Let us wire up the actual GPT Model we wrote now\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "print(\"Input batch: \", batch)\n",
    "out = model(batch)\n",
    "print(\"Output shape: \", out.shape)\n",
    "# print(\"Out: \\n\", out)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:  tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]], device='mps:0')\n",
      "Output shape:  torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "af55c75851ac7e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:00.906876Z",
     "start_time": "2025-01-30T00:54:00.904707Z"
    }
   },
   "source": [
    "# Note above the output tensor has the shape [2, 4, 50257], since we passed in two input texts (the two sentences) \n",
    "# with four tokens each. The last dimension, 50257, corresponds to the vocabulary size of the tokenizer.\n",
    "#\n",
    "# To capture the total number of Parameters for a model use numel parameter value\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "ba624b8ce1a7e0a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "1a31524b0cdc6ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:00.909334Z",
     "start_time": "2025-01-30T00:54:00.907413Z"
    }
   },
   "source": [
    "# Weight Tying: The model reuses weights from the token embedding layer in its output layer\n",
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
    "# As we can see both shapes are same"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "197e0a5f1199aada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:00.912081Z",
     "start_time": "2025-01-30T00:54:00.910101Z"
    }
   },
   "source": [
    "# The token embedding and output layers are very large due to the 50,257 rows in the tokenizer’s vocabulary. \n",
    "# If we remove the output layer parameter count from the total GPT-2 model count :\n",
    "total_params_gptmodel = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Total number of trainable parameters considering weight tying: \"\n",
    "      f\"{total_params_gptmodel:,}\")\n",
    "\n",
    "# Memory Requirement\n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "82b6b3cc8d05feb4",
   "metadata": {},
   "source": [
    "# Generating text \n",
    "#### We will now write code to generate text from the predicted tensors by the GPTModel\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7da3f91bddda842d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:01.028980Z",
     "start_time": "2025-01-30T00:54:00.912614Z"
    }
   },
   "source": [
    "def generate_text_simple(input_model, tokenids, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        token_cond = tokenids[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = input_model(token_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "        probabs = torch.softmax(logits, dim=-1)\n",
    "        next_token = torch.argmax(probabs, dim=-1, keepdim=True)\n",
    "        tokenids = torch.cat((tokenids, next_token), dim=1)\n",
    "\n",
    "        return tokenids\n",
    "#    \n",
    "#  Try it with a sample sentence  \n",
    "#    \n",
    "start_context = \"Hello, I am \"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "#\n",
    "encoded_tensor = torch.tensor(encoded).to(device).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape: \", encoded_tensor.shape)\n",
    "#\n",
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716, 220]\n",
      "encoded_tensor.shape:  torch.Size([1, 5])\n",
      "Output: tensor([[15496,    11,   314,   716,   220, 24464]], device='mps:0')\n",
      "Output length: 6\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "ab7699859ab25da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:01.032192Z",
     "start_time": "2025-01-30T00:54:01.029873Z"
    }
   },
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am opia\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "7397b4b87caf10c6",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on unlabeled data\n",
    "#### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "id": "21d8324b6eace0d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:01.222340Z",
     "start_time": "2025-01-30T00:54:01.032950Z"
    }
   },
   "source": [
    "# How to calculate loss and relatively randomize next word prediction\n",
    "#\n",
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]]).to(device)   #  \"I really like\"\n",
    "#\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]).to(device)  #  \" really like chocolate\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(f\"probas: {probas.shape}\")\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "# Utility function\n",
    "def text_to_token_ids(txt, tokenizr):\n",
    "    encoded_txt = tokenizr.encode(txt, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tnsr = torch.tensor(encoded_txt).to(device).unsqueeze(0)\n",
    "    return encoded_tnsr\n",
    "\n",
    "# Utility function\n",
    "def token_ids_to_text(tokenids, tokenizr):\n",
    "    flat = tokenids.squeeze(0)\n",
    "    return tokenizr.decode(flat.tolist())\n",
    "\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Softmax scores for Text 2: \", target_probas_2)\n",
    "\n",
    "# The goal of training an LLM is to maximize the likelihood of the correct token, \n",
    "# which involves increasing its probability relative to other tokens. \n",
    "\n",
    "# Loss of probabilities for the two batches are\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"Log probabilities for both batches are: \\n\", log_probas)\n",
    "\n",
    "# Next, we combine the log probabilities into a single score by computing \n",
    "# the average\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(f\"Average log probability: {avg_log_probas}\")\n",
    "\n",
    "# However, in deep learning, the common practice isn’t to push the average log probability \n",
    "# up to 0 but rather to bring the negative average log probability down to 0. The negative \n",
    "# average log probability is simply the average log probability multiplied by –1\n",
    "neg_avg_log_probabs = avg_log_probas * -1\n",
    "print(f\"Negative of average log probability: {neg_avg_log_probabs}\")\n",
    "\n",
    "# In deep learning, the term for turning this negative value, –10.7940, into 10.7940, \n",
    "# is known as the cross entropy loss.\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probas: torch.Size([2, 3, 50257])\n",
      "Token IDs: tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]], device='mps:0')\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n",
      "Softmax scores for Text 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05], device='mps:0')\n",
      "Softmax scores for Text 2:  tensor([4.2794e-05, 1.6248e-05, 1.1586e-05], device='mps:0')\n",
      "Log probabilities for both batches are: \n",
      " tensor([-1.0660e+01, -1.0794e+01, -1.1353e+01, -1.0059e+01, -1.1028e+01, -1.1366e+01],\n",
      "       device='mps:0')\n",
      "Average log probability: -10.876513481140137\n",
      "Negative of average log probability: 10.876513481140137\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "2e39970739c5f593",
   "metadata": {},
   "source": [
    "#### NOTE: Our goal during training is to get the average log probability as close to 0 as possible by updating the model’s weights"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:02.166619Z",
     "start_time": "2025-01-30T00:54:01.223518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M_2 = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "    \"model_name\": \"GPTModel\",\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 0.1\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(torch.device(\"mps\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ],
   "id": "62d971c360d51b5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Ae\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "d0465f554d8c18b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:02.185143Z",
     "start_time": "2025-01-30T00:54:02.167293Z"
    }
   },
   "source": [
    "print(\"Logits shape:\", logits.shape) # batch size, num of tokens, vocab size\n",
    "print(\"Targets shape:\", targets.shape) # batch size, num of tokens\n",
    "\n",
    "# For the cross_entropy loss function in PyTorch, we want to flatten these \n",
    "# tensors by combining them over the batch dimension:\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "# Now we can call CE from torch to calculate the loss\n",
    "celoss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(f\"Cross Entropy loss: {celoss}\")\n",
    "\n",
    "# Perplexity measures how well the probability distribution predicted by the model \n",
    "# matches the actual distribution of the words in the dataset. Similar to the loss, \n",
    "# a lower perplexity means the model predictions are closer to the actual distribution.\n",
    "perplexity = torch.exp(celoss)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross Entropy loss: 10.876513481140137\n",
      "Perplexity: 52918.7734375\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "9d0758479b082989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:54:02.715629Z",
     "start_time": "2025-01-30T00:54:02.185723Z"
    }
   },
   "source": [
    "from src.chapter02.Dataloader import Dataloader\n",
    "import torch.nn.functional as F\n",
    "# To implement the data splitting and loading, we first define a train_ratio \n",
    "# to use 90% of the data for training and the remaining 10% as validation data \n",
    "# for model evaluation during training\n",
    "torch.manual_seed(123)\n",
    "# \n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(raw_text))\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]\n",
    "# \n",
    "train_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(train_data)\n",
    "# \n",
    "val_loader = Dataloader(\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ").create_dataloader_v1(val_data)\n",
    "# \n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "# \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "#     \n",
    "# Calculate per batch loss \n",
    "# Use CrossEntropy\n",
    "# \n",
    "def calculate_batch_loss(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)      \n",
    "    batch_logits = model(input_batch)\n",
    "    batch_loss = F.cross_entropy(\n",
    "        batch_logits.flatten(0, 1), \n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    # batch_loss = F.nll_loss(\n",
    "    #     batch_logits.flatten(0, 1), \n",
    "    #     target_batch.flatten()\n",
    "    # )\n",
    "    return batch_loss\n",
    "\n",
    "# \n",
    "# Calculate loss across batches\n",
    "# \n",
    "def calculate_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for n, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if n < num_batches:\n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "# \n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "print(\"Default Training loss:\", train_loss)\n",
    "print(\"Default Validation loss:\", val_loss)\n",
    "# \n",
    "# Model Evaluation\n",
    "#   Calculate both training and validation losses and return\n",
    "#\n",
    "def evaluate_model(eval_model, training_loader, validn_loader, eval_device, eval_iter):\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "        training_loss = calculate_loss_loader(\n",
    "            training_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "        validn_loss = calculate_loss_loader(\n",
    "            validn_loader, eval_model, eval_device, num_batches=eval_iter\n",
    "        )\n",
    "    eval_model.train()\n",
    "    return training_loss, validn_loss\n",
    "\n",
    "# A convenience function that we use to track whether the model improves during the training. \n",
    "# The generate_and_print_sample() function takes a text snippet (start_context) as input, \n",
    "# converts it into token IDs, and feeds it to the LLM to generate a text sample \n",
    "# using the generate_text_simple function\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            input_model=model, \n",
    "            tokenids=encoded,\n",
    "            max_new_tokens=50, \n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# \n",
    "# Now we implement the model training flow \n",
    "#\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    # \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    # \n",
    "    for epoch in range(num_epochs):\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            \n",
    "            loss = calculate_batch_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Back propagation\n",
    "            # Optimizer step function with no closure supplied is below.\n",
    "            # A closure should clear the gradients, compute the loss, and return it.\n",
    "            # For example if it was a Conjugate Grad. optimization method \n",
    "            # We had to pass a closure. A closure is nothing but a function\n",
    "            # for input, target in dataset:\n",
    "            #    def closure():\n",
    "            #        optimizer.zero_grad()\n",
    "            #        output = model(input)\n",
    "            #        loss = loss_fn(output, target)\n",
    "            #        loss.backward()\n",
    "            #        return loss\n",
    "            #    optimizer.step(closure) \n",
    "            # \n",
    "            optimizer.step() \n",
    "            \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                trn_loss, validn_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(trn_loss)\n",
    "                val_losses.append(validn_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {trn_loss:.3f}, \"\n",
    "                      f\"Val loss {validn_loss:.3f}\"\n",
    "                )\n",
    "        # End inner for\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context) # After each epoch\n",
    "    # End outer for\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Default Training loss: 10.988501654730904\n",
      "Default Validation loss: 10.990342140197754\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "9f203bec3d737b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:55:21.283433Z",
     "start_time": "2025-01-30T00:54:02.716441Z"
    }
   },
   "source": [
    "#\n",
    "# Training Loop\n",
    "#\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M_2)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),\n",
    "    lr=0.0004, \n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "# \n",
    "train_losses, val_losses, tokens_seen = (\n",
    "    train_model_simple(model, train_loader, val_loader, optimizer, device, \n",
    "                       num_epochs=num_epochs, eval_freq=5, eval_iter=5, \n",
    "                       start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    "                       )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.333\n",
      "Every effort moves you,\n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you,\n",
      "Ep 3 (Step 000020): Train loss 5.526, Val loss 6.505\n",
      "Ep 3 (Step 000025): Train loss 5.372, Val loss 6.377\n",
      "Every effort moves you,\n",
      "Ep 4 (Step 000030): Train loss 4.838, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.590, Val loss 6.285\n",
      "Every effort moves you of\n",
      "Ep 5 (Step 000040): Train loss 3.888, Val loss 6.131\n",
      "Every effort moves you know\n",
      "Ep 6 (Step 000045): Train loss 3.535, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.965, Val loss 6.123\n",
      "Every effort moves you know\n",
      "Ep 7 (Step 000055): Train loss 2.839, Val loss 6.151\n",
      "Ep 7 (Step 000060): Train loss 2.109, Val loss 6.133\n",
      "Every effort moves you know\n",
      "Ep 8 (Step 000065): Train loss 1.696, Val loss 6.185\n",
      "Ep 8 (Step 000070): Train loss 1.395, Val loss 6.230\n",
      "Every effort moves you?\"\n",
      "Ep 9 (Step 000075): Train loss 1.062, Val loss 6.250\n",
      "Ep 9 (Step 000080): Train loss 0.802, Val loss 6.277\n",
      "Every effort moves you?\"\n",
      "Ep 10 (Step 000085): Train loss 0.571, Val loss 6.370\n",
      "Every effort moves you?\"\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "f525a5e6aafe03d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:55:21.343704Z",
     "start_time": "2025-01-30T00:55:21.284328Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "acfc02f2040cd8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:55:22.994945Z",
     "start_time": "2025-01-30T00:55:21.344384Z"
    }
   },
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    input_model=model,\n",
    "    tokenids=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# Now lets look at Temperature Scaling\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "# Assume the model generates the following logits \n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ").to(device)\n",
    "\n",
    "# We now generally do an argmax of the probabilities \n",
    "probas = torch.softmax(next_token_logits, dim=0).to(device)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(f\"Next token (argmax): {inverse_vocab[next_token_id]}\")\n",
    "#\n",
    "# But we can try replacing argmax with multinomial and get a sampling\n",
    "#\n",
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(f\"Next token (multinomial): {inverse_vocab[next_token_id]}\")\n",
    "# \n",
    "# Let's see if multinomial can produce any other probabilites\n",
    "def print_sampled_tokens(probabs):\n",
    "    torch.manual_seed(123)\n",
    "    # Multinomial Sampling of probabilities instead of max\n",
    "    samples = [torch.multinomial(probabs, num_samples=1).item() for _ in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(samples).to(device))\n",
    "    for cnt, freq in enumerate(sampled_ids):\n",
    "        print(f\"Sampled Freq. {freq} : {inverse_vocab[cnt]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "Next token (argmax): forward\n",
      "Next token (multinomial): forward\n",
      "Sampled Freq. 72 : closer\n",
      "Sampled Freq. 2 : every\n",
      "Sampled Freq. 0 : effort\n",
      "Sampled Freq. 575 : forward\n",
      "Sampled Freq. 2 : inches\n",
      "Sampled Freq. 0 : moves\n",
      "Sampled Freq. 0 : pizza\n",
      "Sampled Freq. 343 : toward\n",
      "Sampled Freq. 6 : you\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "2edb9cac7f426800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T00:55:23.054074Z",
     "start_time": "2025-01-30T00:55:22.995695Z"
    }
   },
   "source": [
    "# We can further control the distribution by a technique called temperature scaling\n",
    "# meaning dividing the logits with a >0 number\n",
    "def softmax_with_temperature(logits, temperature, dim):\n",
    "    scaled_logits = logits / temperature\n",
    "    scaled_probs =  torch.softmax(scaled_logits, dim=dim)\n",
    "    return scaled_probs\n",
    "\n",
    "# Let's check that out\n",
    "temperatures = [1, .01, 5]\n",
    "next_token_logits = Tensor.cpu(next_token_logits)\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, float(T), 0) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.5\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, \n",
    "                   scaled_probas[i], \n",
    "                   bar_width, \n",
    "                   label=f'Temperature = {T}'\n",
    "    )\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xlabel('Words')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "48c5d9214db5c7e3",
   "metadata": {},
   "source": [
    "## Top K sampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "af408748892d4b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:15:18.005989Z",
     "start_time": "2025-01-30T01:15:17.344137Z"
    }
   },
   "source": [
    "# Previously we implemented a probabilistic sampling approach coupled with \n",
    "# temperature scaling to increase the diversity of the outputs.  This method \n",
    "# allows for the exploring of less likely but potentially more interesting and \n",
    "# creative paths in the generation process.\n",
    "#\n",
    "# Top-k sampling, when combined with probabilistic sampling and temperature \n",
    "# scaling, can improve the text generation results.\n",
    "#\n",
    "# Here we can restrict the sampled tokens to the top-k most likely tokens \n",
    "# and exclude all other tokens from the selection process by masking their \n",
    "# probability scores\n",
    "# \n",
    "top_k = 3\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "# \n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top Logits: \", top_logits)\n",
    "print(\"Top Positions: \", top_pos)\n",
    "print(f\"Next token logits: {next_token_logits}\")\n",
    "\n",
    "# Pytorch WHERE function to set the logit values of tokens that are below the lowest \n",
    "# logit value within our top-three selection to negative infinity (-inf)\n",
    "#\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New Logits: \", new_logits)\n",
    "\n",
    "# Now apply the softmax\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(f\"top k probabilities: {topk_probas}\")\n",
    "# \n",
    "# We can now apply the temperature scaling and multinomial function for probabilistic \n",
    "# sampling to select the next token among these three non-zero probability scores to \n",
    "# GENERATE THE NEXT TOKEN with more diversity.\n",
    "# \n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    # print(\"Entering generate()..\")\n",
    "    # print(idx.shape)\n",
    "    for i in range(max_new_tokens):\n",
    "        # print(f\"idx: [{i}]: {idx}\")\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        #     \n",
    "        logits = logits[:, -1, :] # ([1, 50257])\n",
    "        # print(logits.shape)\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1] # Less than the lowest value of top k\n",
    "            # Now mark the minvals with -inf, so softmax becomes 0\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            probs = softmax_with_temperature(logits, temperature, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else: \n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        # Next word\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M_2[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      "Top Positions:  tensor([3, 7, 0])\n",
      "Next token logits: tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
      "         1.7900])\n",
      "New Logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "top k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n",
      "Output text:\n",
      " Every effort moves you get up through my public brush a cheap genius--I told Mrs. G\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:05.931151Z",
     "start_time": "2025-01-30T01:16:02.960285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch.save(model.state_dict(), f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\")\n",
    "MODEL_PATH = f\"/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/{GPT_CONFIG_124M_2['model_name']}.pth\"\n",
    "# \n",
    "try:\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }, \n",
    "        MODEL_PATH\n",
    "    )\n",
    "    print(f\"Model saved at {MODEL_PATH}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Encountered exception : {e}\")\n",
    "    \n",
    "# "
   ],
   "id": "7e164cfeef1f9707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at /Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/GPTModel.pth\n",
      "\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:20.045062Z",
     "start_time": "2025-01-30T01:16:18.477197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model back\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device,weights_only=True)\n",
    "loaded_model = GPTModel(GPT_CONFIG_124M_2).to(device)\n",
    "try:\n",
    "    loaded_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer = torch.optim.AdamW(loaded_model.parameters(), \n",
    "                                 lr=GPT_CONFIG_124M_2[\"lr\"], \n",
    "                                 weight_decay=GPT_CONFIG_124M_2[\"weight_decay\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    print(f\"Model and Optimizer successfully loaded from \\n{MODEL_PATH}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Encountered exception : {e}\")\n",
    "    \n",
    "loaded_model.train()\n",
    "print(\"Model set to train mode\")"
   ],
   "id": "d0a3f72c8cebc09d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Optimizer successfully loaded from \n",
      "/Users/amlanchatterjee/Documents/ws/python/PycharmProjects/SimpleLLMProject/models/GPTModel.pth\n",
      "\n",
      "Model set to train mode\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:34.372219Z",
     "start_time": "2025-01-30T01:16:34.370218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try training the model a couple of times more\n",
    "# epochs = 2\n",
    "# train_ratio = 0.9\n",
    "# # \n",
    "# print(f\"Model is on {next(model.parameters()).device}\")  \n",
    "# train_losses, val_losses, tokens_seen = (\n",
    "#     train_model_simple(\n",
    "#         loaded_model, \n",
    "#         train_loader, \n",
    "#         val_loader, \n",
    "#         optimizer, \n",
    "#         device, \n",
    "#         num_epochs=epochs, \n",
    "#         eval_freq=5, \n",
    "#         eval_iter=5, \n",
    "#         start_context=\"Every effort moves you\", \n",
    "#         tokenizer=tokenizer\n",
    "#     )\n",
    "# )\n",
    "# epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "f6108362246432af",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### OpenAI also shares the weights of larger models: 355M, 774M, and 1558M \n",
    "![image](../data/model_arch_stack.png)\n",
    "\n"
   ],
   "id": "d38b09e853311dec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:36.554233Z",
     "start_time": "2025-01-30T01:16:34.372808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the downloaded GPT Data\n",
    "import urllib.request\n",
    "from src.chapter05.gpt_download import download_and_load_gpt2\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "settings, gpt_params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"../data/gpt2\")\n",
    "print(f\"\\nParams: {gpt_params.keys()}\")\n",
    "print(f\"Settings: {settings}\")\n",
    "print(f\"Token embedding layer weight tensor dimensions: {gpt_params[\"wte\"].shape}\")    \n"
   ],
   "id": "68e160927f07d23a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../data/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../data/gpt2/124M/vocab.bpe\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Token embedding layer weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:37.486342Z",
     "start_time": "2025-01-30T01:16:36.555584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# After loading the GPT-2 model weights into Python, we still need to transfer \n",
    "# them from the settings and params dictionaries into our GPTModel instance. \n",
    "# First, we create a dictionary that lists the differences between the \n",
    "# different GPT model sizes\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "model_name=\"gpt2-small (124M)\"\n",
    "# \n",
    "NEW_GPT_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_GPT_CONFIG.update({\"model_name\": model_name})\n",
    "# Update the value ex. {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "NEW_GPT_CONFIG.update(model_configs[model_name]) \n",
    "\n",
    "NEW_GPT_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_GPT_CONFIG.update({\"qkv_bias\": True})\n",
    "# \n",
    "print(f\"{model_name}: {model_configs[model_name]}\")\n",
    "print(\"NEW_GPT_CONFIG:\\n\"+\"\".join(f\"\\t{k}: {v}\\n\" for k, v in sorted(NEW_GPT_CONFIG.items())))\n",
    "# \n",
    "newgpt = GPTModel(NEW_GPT_CONFIG).to(device)\n",
    "newgpt.eval()\n",
    "# \n",
    "# Before we assign the loaded openai weights into the model, we will first define \n",
    "# a small assign utility function that checks whether two tensors or arrays \n",
    "# (left and right) have the same dimensions or shape and returns the right tensor \n",
    "# as trainable PyTorch parameters\n",
    "def assign(left: Tensor, right: Tensor) -> Tensor:\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch Left shape: {left.shape} Right shape: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right).to(device))\n",
    "# \n",
    "print(f\"Params: {gpt_params.keys()}\")\n",
    "# print(f\"Params: {gpt_params}\")\n",
    "print(f\"GPT Parameter Blocks Count: {len(gpt_params[\"blocks\"])}\")"
   ],
   "id": "ba48ffe795182755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2-small (124M): {'emb_dim': 768, 'n_layers': 12, 'n_heads': 12}\n",
      "NEW_GPT_CONFIG:\n",
      "\tcontext_length: 1024\n",
      "\tdrop_rate: 0.1\n",
      "\temb_dim: 768\n",
      "\tlr: 0.0005\n",
      "\tmodel_name: gpt2-small (124M)\n",
      "\tn_heads: 12\n",
      "\tn_layers: 12\n",
      "\tqkv_bias: True\n",
      "\tvocab_size: 50257\n",
      "\tweight_decay: 0.1\n",
      "\n",
      "Params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "GPT Parameter Blocks Count: 12\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:37.492227Z",
     "start_time": "2025-01-30T01:16:37.487116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# Load OpenAI Weights into our GPTModel code\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].sff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].sff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].sff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].sff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    "
   ],
   "id": "dbc4d3fb2c383826",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:37.606699Z",
     "start_time": "2025-01-30T01:16:37.492808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now lets try to load the weights and see\n",
    "load_weights_into_gpt(newgpt, gpt_params)\n",
    "newgpt.to(device)\n",
    "print(\"Loaded weights into GPTModel\")"
   ],
   "id": "c0eeef9e5cadf037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights into GPTModel\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:16:38.453694Z",
     "start_time": "2025-01-30T01:16:37.607545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now lets generate\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=newgpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_GPT_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "53993f0b2ef4021a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more efficient and efficient processes, like in the car's oil and gas operation,\" the study said. To see if that\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "68541d175335de06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
